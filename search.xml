<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Tensor Flow Session Run]]></title>
      <url>/2018/07/27/Tensor-Flow-Session-Run/</url>
      <content type="html"><![CDATA[<p><a href="https://www.tensorflow.org/api_docs/python/tf/Session" target="_blank" rel="noopener">Origianl TensorFlow.Session</a></p>
<img src="/2018/07/27/Tensor-Flow-Session-Run/1.png">
<h1 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h1><p>一个TensorFLow代码可以氛围两个部分，<strong>定义</strong>和<strong>运行</strong>，我们通过tf.matmul()以及tf.constant()方法定义了graph，而不会立即执行，为了让Tensor流动起来我们创建一个Session，调用run方法。（在执行完毕后将其用close方法关闭）</p>
<p>TensorFlow的run方法的参数如下：<em>run( fetches, feed_dict=None, options=None, run_metadata=None )</em></p>
<h2 id="feteches"><a href="#feteches" class="headerlink" title="feteches"></a>feteches</h2><p>fetches表示了计算图中的一个node，每当我们调用run方法的时候，TensorFlow找到这个node所依赖的所有操作，并且计算出这个node的值。</p>
<h2 id="feed-dict"><a href="#feed-dict" class="headerlink" title="feed_dict"></a>feed_dict</h2><img src="/2018/07/27/Tensor-Flow-Session-Run/2.png">
<p>feed_dict的作用是替换前部分中的某一个tensor的值，我们可以通过使用feed_dict来设置graph的输入量</p>
<h1 id="Placeholder"><a href="#Placeholder" class="headerlink" title="Placeholder"></a>Placeholder</h1><p>此处a并不是一个tensor而是一个placeholder，我们需要定义他的type和shape，但是毋需赋予他具体的值，而在后面的graph中我们可以把placeholder当成一个普通的tensor对象使用，并且只需要一个feed_dict的方法把具体的值提供给placeholder，达到了给graph提供input的目的。</p>
<h1 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h1><img src="/2018/07/27/Tensor-Flow-Session-Run/3.png">
<p>和之前不可改变的对象相比，我们可以通过tf.Variable()方法来建立一个变量，在机器学习中这个变量往往是我们需要优化的值，比如说weight w或者bias b，变量可以和Placeholder进行计算并且得到一个model，然后我们通过Optimize这个model来得到我们的目标模型。</p>
]]></content>
      
        
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Computer Security - Web&Network]]></title>
      <url>/2018/06/30/Computer-Security-Web-Network/</url>
      <content type="html"><![CDATA[<h1 id="Web-Application-Security"><a href="#Web-Application-Security" class="headerlink" title="Web Application Security"></a>Web Application Security</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>3 Tier Web Application Architecture: HTTP Client -&gt; HTTP Server -&gt; Application Server (Business logic) -&gt; Database Server</p>
<p>Untrustworthy Client: The golden rule of web application security is that <strong>the client is never trust worthy</strong>.</p>
<p>Conflicting requirements:</p>
<ol>
<li>Functional Requirement: we need to mix code with data(blog comments)</li>
<li>Security Requirement: never mix code with data</li>
</ol>
<h2 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h2><ul>
<li>Whitelisting: Effective but limited.</li>
<li>Blacklisting: Good but not safe enough.</li>
<li>Escaping: Transform some special char into something else.</li>
</ul>
<h2 id="Cross-Site-Scripting-XSS"><a href="#Cross-Site-Scripting-XSS" class="headerlink" title="Cross Site Scripting[XSS]"></a>Cross Site Scripting[XSS]</h2><p>Cross site scripting is a vulnerability by means of which client-side code can be injected in a page.</p>
<blockquote>
<p>Cookie theft or session hijack</p>
<p>Manipulation of a session and execution of fraudulent transaction</p>
<p>Snooping on private information</p>
<p>Effectively bypasses the same-origin policy</p>
<p>Drive by Download</p>
</blockquote>
<ol>
<li>Stored XSS: The attacker input is stored on the target server, such as in a database, in a message forum, visitor log, comment field, etc.存储型XSS，又称持久型XSS，他和反射型XSS最大的不同就是，攻击脚本将被永久地存放在目标服务器的数据库和文件中。这种攻击多见于论坛，攻击者在发帖的过程中，将恶意脚本连同正常信息一起注入到帖子的内容之中。随着帖子被论坛服务器存储下来，恶意脚本也永久地被存放在论坛服务器的后端存储器中。当其它用户浏览这个被注入了恶意脚本的帖子的时候，恶意脚本则会在他们的浏览器中得到执行，从而受到了攻击。比如用<code>&lt;script&gt;</code>镶嵌恶意脚本在某帖子，浏览者均会中招。可以看到，存储型XSS的攻击方式能够将恶意代码永久地嵌入一个页面当中，所有访问这个页面的用户都将成为受害者。如果我们能够谨慎对待不明链接，那么反射型的XSS攻击将没有多大作为，而存储型XSS则不同，由于它注入的往往是一些我们所信任的页面，因此无论我们多么小心，都难免会受到攻击。可以说，存储型XSS更具有隐蔽性，带来的危害也更大，除非服务器能完全阻止注入，否则任何人都很有可能受到攻击。</li>
<li>Reflected XSS:反射型XSS，又称非持久型XSS。之所以称为反射型XSS，则是因为这种攻击方式的注入代码是从目标服务器通过错误信息、搜索结果等等方式“反射”回来的。而称为非持久型XSS，则是因为这种攻击方式具有一次性。攻击者通过电子邮件等方式将包含注入脚本的恶意链接发送给受害者，当受害者点击该链接时，注入脚本被传输到目标服务器上，然后服务器将注入脚本“反射”到受害者的浏览器上，从而在该浏览器上执行了这段脚本。比如攻击者将如下链接发送给受害者： <code>http://www.targetserver.com/search.asp?input=&lt;script&gt;alert(document.cookie);&lt;/script&gt;</code>当受害者点击这个链接的时候，注入的脚本被当作搜索的关键词发送到目标服务器的search.asp页面中，则在搜索结果的返回页面中，这段脚本将被当作搜索的关键词而嵌入。这样，当用户得到搜索结果页面后，这段脚本也得到了执行。这就是反射型XSS攻击的原理，可以看到，攻击者巧妙地通过反射型XSS的攻击方式，达到了在受害者的浏览器上执行脚本的目的。由于代码注入的是一个动态产生的页面而不是永久的页面，因此这种攻击方式只在点击链接的时候才产生作用，这也是它被称为非持久型XSS的原因。</li>
<li>DOM Based XSS:通常这个页面作为用户欢迎页面, 例如:<code>http://www.vulnerable.site/welcome.html?name=Joe</code>,然而，如下的一个请求: <code>http://www.vulnerable.site/welcome.html?name=&lt;script&gt;alert(document.cookie)&lt;/script&gt;</code>将产生xss条件。让我们看看为什么：受害者的浏览器接收到这个链接，发送HTTP请求到www.vulnerable.site并且接受到上面的HTML页。受害者的浏览器开始解析这个HTML为DOM，DOM包含一个对象叫document，document里面有个URL属性，这个属性里填充着当前页面的URL。当解析器到达javascript代码，它会执行它并且修改你的HTML页面。倘若代码中引用了document.URL，那么，这部分字符串将会在解析时嵌入到HTML中，然后立即解析，同时，javascript代码会找到(alert(…))并且在同一个页面执行它，这就产生了xss的条件。\</li>
</ol>
<pre><code>SXSS
&lt;script&gt;
   alert(&#39;JavaScript Executed&#39;);
&lt;/script&gt;
</code></pre><pre><code>DBXSS
&lt;script&gt;
    document.write(&quot;&lt;b&gt;Current URL&lt;/b&gt; : &quot; + document.baseURI);
&lt;/script&gt;
</code></pre><blockquote>
<p>Same Origin Policy: all client-side code (e.g., JavaScript) loaded from origin A should only be able to access data from origin A[Origin = <protocol, host,="" port="">]</protocol,></p>
</blockquote>
<h2 id="Solution-of-XSS"><a href="#Solution-of-XSS" class="headerlink" title="Solution of XSS"></a>Solution of XSS</h2><h3 id="Blacklisting-BAD"><a href="#Blacklisting-BAD" class="headerlink" title="Blacklisting: BAD"></a>Blacklisting: BAD</h3><h3 id="Escaping"><a href="#Escaping" class="headerlink" title="Escaping"></a>Escaping</h3><h3 id="CSP"><a href="#CSP" class="headerlink" title="CSP"></a>CSP</h3><h2 id="SQL-Injection"><a href="#SQL-Injection" class="headerlink" title="SQL Injection"></a>SQL Injection</h2><pre><code>SELECT * FROM Users WHERE username=&#39;cesare&#39; AND password=&#39;secret;)&#39;;
</code></pre><p>But in SQL ‘–’ means comment! We could have username as <strong>cesare’;–</strong></p>
<pre><code>SELECT * FROM Users WHERE username=&#39;cesare&#39;;--&#39; AND password=&#39;&#39;;
</code></pre><p>Or even without a user name, we insert into username of <strong>‘ OR ‘1’=’1’;–</strong></p>
<pre><code>SELECT * FROM Users WHERE username=&#39;&#39; OR &#39;1&#39;=&#39;1&#39;;--&#39; AND password=&#39;&#39;;
</code></pre><p>Even Retrive more!</p>
<pre><code>SELECT name, phone, address FROM Users WHERE Id=&#39;&#39; UNION ALL SELECT name, creditCardNumber,CCV2 from CreditCardTable;--&#39;;
</code></pre><p>Or Insert! Here in the username we fill in <strong>cesare’, ‘30L’)–</strong></p>
<pre><code>INSERT INTO results VALUES (NULL, &#39;cesare&#39;, &#39;30L&#39;)--&#39;, &#39;18&#39;)
</code></pre><h2 id="Solution-of-SQL-Injection"><a href="#Solution-of-SQL-Injection" class="headerlink" title="Solution of SQL Injection"></a>Solution of SQL Injection</h2><h3 id="Filering-could-be-a-bad-for-the-password-field"><a href="#Filering-could-be-a-bad-for-the-password-field" class="headerlink" title="Filering: could be a bad for the password field"></a>Filering: could be a bad for the password field</h3><h2 id="URL-Tampering"><a href="#URL-Tampering" class="headerlink" title="URL Tampering"></a>URL Tampering</h2><p>Do the hacking by changing the url. Like insert a path in the url.</p>
<h2 id="Password-Security"><a href="#Password-Security" class="headerlink" title="Password Security"></a>Password Security</h2><h2 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h2><p>Cookies Store the client information.</p>
<blockquote>
<p>Original Idea: Site Customization</p>
<p>Abuse: Privacy Violations</p>
<p>Dangeous Idea: User Authentication and sessions</p>
</blockquote>
<img src="/2018/06/30/Computer-Security-Web-Network/1.png">
<p>Since HTTP is stateless, hijacking can occur:</p>
<ul>
<li>By stealing a cookie with an XSS attack </li>
<li>By brute forcing a weak session id parameter</li>
</ul>
<h2 id="Cross-Site-Request-Forgery-CSRF"><a href="#Cross-Site-Request-Forgery-CSRF" class="headerlink" title="Cross-Site Request Forgery (CSRF)"></a>Cross-Site Request Forgery (CSRF)</h2><p>Forces an user to execute unwanted actions (state-changing action) on a web application in which he is currently authenticated (e.g., with cookies).登录受信任网站A，并在本地生成Cookie。然后在不登出A的情况下，访问危险网站B。There should be state-changing action in the page that needs to be protected against CSRF.</p>
<p>Key Concept: malicious requests (e.g., crafted links) are routed to the vulnerable web application through the victim’s browser: Websites cannot distinguish if the requests coming from authenticated users have been originated by an explicit user interaction or not.</p>
<p>Solution: Use Session tokens, random challenge token, it could associated to user’s session (unique) and regenerated at each request (e.g., for form involving sensitive operations)</p>
<h1 id="Network-Protocal-Attacks"><a href="#Network-Protocal-Attacks" class="headerlink" title="Network Protocal Attacks"></a>Network Protocal Attacks</h1><h2 id="Denial-of-Service-against-availability-service-unavailablt-to-legitimate-users"><a href="#Denial-of-Service-against-availability-service-unavailablt-to-legitimate-users" class="headerlink" title="Denial of Service (against availability): service unavailablt to legitimate users"></a>Denial of Service (against availability): service unavailablt to legitimate users</h2><p>Examples: Killer Packets, SYN Flood, Smurf/multiplication/amplification attacks, Distributed DoS</p>
<h3 id="Killer-Packets"><a href="#Killer-Packets" class="headerlink" title="Killer Packets"></a>Killer Packets</h3><p>Ping of Death-攻击者故意发送大于65535字节的ip数据包给对方。</p>
<p>Teardop-向目标主机发送损坏的IP包，使其难以被目标主机重新组合。只需要几个数据包，就可以使目标主机卡死,蓝屏,重启。</p>
<p>Land Attack-srcIP==dstIP, loop and lock up a TCP/IP stack.</p>
<h3 id="SYN-Flood-Attacks"><a href="#SYN-Flood-Attacks" class="headerlink" title="SYN Flood Attacks"></a>SYN Flood Attacks</h3><p>Attacker generates a high volume of SYN requests with spoofed source address. Many half-open TCP/IP connections fill the queue.</p>
<p><strong>Solution</strong>: SYN-cookies avoid this: reply with SYN+ACK but discard the half-open connection, and wait for a subsequent ACK.</p>
<h3 id="Distributed-DoS"><a href="#Distributed-DoS" class="headerlink" title="Distributed DoS"></a>Distributed DoS</h3><p>Botnet: network of compromised computers, called bots (i.e., infected by malware).</p>
<p>C&amp;C: dedicated command-and-control infrastructure so that the attacker (botmaster) can send commands to the bots.</p>
<p>The attacker sends ICMP packets with spoofed sender (victim) to a broadcast address(并不是像上文中的攻击一样attacker向victim发送攻击包，而是attacker假装是victim发送多个包给很多的host,host回复给victim使victim的bandwidth被填满).<strong>注意Amplification Hell， 对于不同的protocol，很有可能发送的包的大小和ACK包的大小倍数相差很大。</strong></p>
<img src="/2018/06/30/Computer-Security-Web-Network/2.png">
<h2 id="Sniffing-against-confidentiality-abusive-reading-of-network-packets"><a href="#Sniffing-against-confidentiality-abusive-reading-of-network-packets" class="headerlink" title="Sniffing (against confidentiality): abusive reading of network packets"></a>Sniffing (against confidentiality): abusive reading of network packets</h2><p>Solution: Use switched networks as opposed to hub-based networks.</p>
<h2 id="Spoofing-against-integrity-and-authenticity-forging-network-packets"><a href="#Spoofing-against-integrity-and-authenticity-forging-network-packets" class="headerlink" title="Spoofing (against integrity and authenticity): forging network packets"></a>Spoofing (against integrity and authenticity): forging network packets</h2><p>First come, first trusted! An attacker can forge replies easily: lack of authentication.</p>
<h3 id="IP-address-spoofing"><a href="#IP-address-spoofing" class="headerlink" title="IP address spoofing"></a>IP address spoofing</h3><p>The IP source address is not authenticated. Changing it in UDP or ICMP packets is easy. However, the attacker will not see the answers, because they will be sent to the spoofed host (blind spoofing). But if the attacker is on the same network, s(he) can sniff the rest, or use ARP spoofing.</p>
<p>正常的三次握手</p>
<img src="/2018/06/30/Computer-Security-Web-Network/3.png">
<p>被劫持的三次握手</p>
<img src="/2018/06/30/Computer-Security-Web-Network/4.png">
<blockquote>
<p>TCP Session Hijack</p>
<p>Taking over an active TCP session if the attacker (C) can sniff the packets:</p>
<ol>
<li><p>C follows the conversation of A and B recording the sequence numbers.</p>
</li>
<li><p>C somehow disrupts B’s connection (e.g. SYN Flood): B sees only a “random” disruption of service.</p>
</li>
<li><p>C takes over the dialogue with A by spoofing B address and starting with a correct ISN. A suspects nothing.</p>
</li>
</ol>
</blockquote>
<p><strong>The attacker can avoid disrupting B’s session and just inject things in the flow only if s(he) is a man in the middle and can control/resync all the traffic flowing through.</strong></p>
<blockquote>
<p><strong>Man in the middle</strong>: A broad category comprising all the attacks where an attacker can impersonate the server with respect to the client and vice-versa</p>
</blockquote>
<h2 id="Spanning-Tree-Protocol"><a href="#Spanning-Tree-Protocol" class="headerlink" title="Spanning Tree Protocol"></a>Spanning Tree Protocol</h2><p>The STP (802.1d) avoids loops on switched networks by building a spanning tree (ST). Switches decide how to build the ST by exchanging BPDU (bridge protocol data unit) packets to elect the root node. BPDU packets are not authenticated, so, an attacker can change the shape of the tree for sniffing or ARP spoofing purposes.</p>
<h2 id="DNS-Poisoning"><a href="#DNS-Poisoning" class="headerlink" title="DNS Poisoning"></a>DNS Poisoning</h2><p>When a non-authoritative DNS server receives a request to resolve a domain name:</p>
<ul>
<li>If it cached the answer, it answers</li>
<li>If no answer in cache: Recursion - resolves the name on behalf of the client OR Iterative - gives the authoritative DNS address.</li>
</ul>
<p>How to Poison the Cache?</p>
<ol>
<li>The attacker makes a recursive query to the victim DNS server: it will contact the authoritative server.</li>
<li>The attacker spoofs the answer impersonating the authoritative DNS server. And the server will trust it</li>
</ol>
<h2 id="DHCP-Poisoning"><a href="#DHCP-Poisoning" class="headerlink" title="DHCP Poisoning"></a>DHCP Poisoning</h2><p>The attacker can intercept requests, be the first to answer, and client will believe that answer. It’s a denial of service attack, an attacker sends forged DHCP requests to the server and leases all the available IP’s thus the legitimate clients will not get an IP assigned; or the Attacker may send bogus request/replies luring the client to connect to attacker’s machine instead of valid DHCP server. It happens because the DHCP protocol does not support authentication, the client must blindly believe any DHCP offer that it sees; thus, an arbitrary client can race (and win) against the real DHCP Server.</p>
<h2 id="ICMP-Redirect"><a href="#ICMP-Redirect" class="headerlink" title="ICMP Redirect"></a>ICMP Redirect</h2><p>Tells an host that a better route exists for a given destination, and gives the gateway for that route.</p>
<p>The attacker can forge an ICMP redirect packet to elect his/her computer as the gateway.</p>
<h1 id="Secure-Network-Architectures"><a href="#Secure-Network-Architectures" class="headerlink" title="Secure Network Architectures"></a>Secure Network Architectures</h1><h2 id="Firewall"><a href="#Firewall" class="headerlink" title="Firewall"></a>Firewall</h2><p>Firewall is network access control system that verifies all the packets(traffic) flowing through it. It has to be the ONLY point between a network and outside network. It has two functions usually: <strong>IP Packet Filtering</strong>, <strong>Network Address Translation</strong>.</p>
<p>It may be powerless against insider attacks and unchecked path.</p>
<p>Firewall itself is a computer, but most times it is only an embedded appliance with just a firmware. </p>
<blockquote>
<p>Network layer firewall</p>
<p>Packet filters</p>
<p>Stateful packet filters</p>
<p>Application layer firewall</p>
<p>Circuit level firewall</p>
<p>Application proxies</p>
</blockquote>
<h2 id="Packet-Filters"><a href="#Packet-Filters" class="headerlink" title="Packet Filters"></a>Packet Filters</h2><p>Packet by packet processing. Decodes the IP header - <em>SRC and DST IP/port, Protocol Type, IP options</em>.</p>
<p>It is stateless and cannot track TCP connections, but it could sets a set of rules in the packet processing (block/allow/log).</p>
<h2 id="Stateful-Dynamic-Packet-Filters"><a href="#Stateful-Dynamic-Packet-Filters" class="headerlink" title="Stateful(Dynamic) Packet Filters"></a>Stateful(Dynamic) Packet Filters</h2><p>Include network packet filters, plus <strong>1. track the TCP state machine</strong>, <strong>2. track connections without adding response rule</strong>.</p>
<p>It could logging and accounting on connections. </p>
<h2 id="Session-Handling"><a href="#Session-Handling" class="headerlink" title="Session Handling"></a>Session Handling</h2><p>A session is an atomic transport layer exchange of application data between 2 hosts(TCP/UDP). It is fundamental for NAT.</p>
<h2 id="NAT-Session-Initialization"><a href="#NAT-Session-Initialization" class="headerlink" title="NAT Session Initialization"></a>NAT Session Initialization</h2><img src="/2018/06/30/Computer-Security-Web-Network/5.png">
<img src="/2018/06/30/Computer-Security-Web-Network/6.png">
<img src="/2018/06/30/Computer-Security-Web-Network/7.png">
<h2 id="Circuit-Firewalls"><a href="#Circuit-Firewalls" class="headerlink" title="Circuit Firewalls"></a>Circuit Firewalls</h2><p>Client connects to a specific TCP port on the firewall, which then connects to the address and port of the desired server (not transparent!). (EG: SOCKS)</p>
<h2 id="Application-Proxies"><a href="#Application-Proxies" class="headerlink" title="Application Proxies"></a>Application Proxies</h2><p>Same as circuit firewalls, but at application layer.</p>
<p>Inspect, validate, manipulate protocol application data (e.g., rewrite HTTP frames).</p>
<img src="/2018/06/30/Computer-Security-Web-Network/8.png">
<h2 id="Dual-Multi-Zone-Architectures"><a href="#Dual-Multi-Zone-Architectures" class="headerlink" title="Dual/Multi Zone Architectures"></a>Dual/Multi Zone Architectures</h2><p><strong>Problem</strong>: if we mix externally accessible servers with internal clients, we lower the security of the internal network.</p>
<p><strong>Solution</strong>: we allow external access to the accessible servers, but not to the internal network.</p>
<p><strong>General idea</strong>: split the network by privileges levels. Firewalls to regulate access.</p>
<p>DMZ - demilitarized zone: On the DMZ no critical or irreplaceable data. The DMZ is almost as risky as the Internet.</p>
<img src="/2018/06/30/Computer-Security-Web-Network/9.png">
<h2 id="Virtual-Private-Network-VPN"><a href="#Virtual-Private-Network-VPN" class="headerlink" title="Virtual Private Network: VPN"></a>Virtual Private Network: VPN</h2><p><strong>Target</strong>: Ensure CIA to data transmitted over a public network (i.e., the Internet).</p>
<p><strong>Solution: VPN</strong>, an encrypted overlay connection over a (public) network.</p>
<img src="/2018/06/30/Computer-Security-Web-Network/10.png">
<blockquote>
<p>TWO MODES OF VPN</p>
<p>Full tunnelling: Every packet goes through the tunnel/ Traffic multiplication, could be inefficient/ Single point of control and application of all security policies as if the client were in the corporate network.</p>
<p>Split tunnelling: Traffic to the corporate network: in VPN/ traffic to the Internet: directly to ISP/ More efficient, less control./ Just similar to the case of the PC connected via 3G.</p>
</blockquote>
<h1 id="Network-Security-SSL-and-SET"><a href="#Network-Security-SSL-and-SET" class="headerlink" title="Network Security: SSL and SET"></a>Network Security: SSL and SET</h1><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>Problems of remoteness</strong>: Trust factor between parties/Use of sensitive data/Atomicity of transaction</p>
<p><strong>Internet protocol problems</strong>: Authentication//Confidentiality/Transparence and critical mass problem</p>
<h2 id="HTTP-over-SSL-Secure-Socket-Layer-or-HTTPS"><a href="#HTTP-over-SSL-Secure-Socket-Layer-or-HTTPS" class="headerlink" title="HTTP over SSL (Secure Socket Layer), or HTTPS"></a>HTTP over SSL (Secure Socket Layer), or HTTPS</h2><p>Communication confidentiality and integrity/Mutual authentication/No guarantees on data usage/No strict authentication of client (in practice)</p>
<h3 id="SSL"><a href="#SSL" class="headerlink" title="SSL"></a>SSL</h3><p>SSL enforces: Confidentiality and integrity of the communications/Server authentication/Client authentication (optionally)/Uses both symmetric and asymmetric cryptography for performance reasons</p>
<img src="/2018/06/30/Computer-Security-Web-Network/11.png">
<p><strong>SSL is by design resistant to MITM!</strong></p>
<p>PROS: Protects transmissions: Confidentiality/Integrity/Ensures authentication of server/client (optionally)</p>
<p>CONS: No protection before or after transmission on server/client (e.g. trojan)/By abuser (e.g. non-honest merchant)/Relies on PKI/Not foolproof</p>
<h2 id="SET-Secure-Electronic-Transaction"><a href="#SET-Secure-Electronic-Transaction" class="headerlink" title="SET (Secure Electronic Transaction)"></a>SET (Secure Electronic Transaction)</h2><p>Guarantees on data usage and transaction security enforcement/Missing critical mass support. Uses the concept of a dual signature(将两条消息hash各自hash成一个digest，然后将两个digest hash成一个digest来确保两条消息都没有被修改过).</p>
<p>Approach</p>
<ol>
<li>Customer browses website and decides on what to purchase</li>
<li>Customer sends order and payment information, which includes 2 parts in one message: <em>a. Purchase Order – this part is for merchant</em>,<em>b. Card Information – this part is for merchant’s bank only.</em></li>
<li>Merchant forwards card information (part b) to their bank</li>
<li>Merchant’s bank checks with Issuer for payment authorization</li>
<li>Issuer send authorization to Merchant’s bank</li>
<li>Merchant’s bank send authorization to merchant</li>
<li>Merchant completes the order and sends confirmation to the customer</li>
<li>Merchant captures the transaction from their bank</li>
<li>Issuer prints credit card bill (invoice) to customer</li>
</ol>
<img src="/2018/06/30/Computer-Security-Web-Network/12.png">
<p>hash 1: hash of order information</p>
<p>hash 2: hash of pay instruction</p>
]]></content>
      
        
        <tags>
            
            <tag> Computer Securit </tag>
            
            <tag> Web Application </tag>
            
            <tag> Network Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Advanced Computer Architectures]]></title>
      <url>/2018/05/16/Advanced-Computer-Architectures/</url>
      <content type="html"><![CDATA[<p>A note for the course of <em>Advanced Computer Architectures</em>.</p>
<h1 id="L00-Intro"><a href="#L00-Intro" class="headerlink" title="L00 Intro"></a>L00 Intro</h1><h1 id="L01-Pipelining-Basic-Concepts"><a href="#L01-Pipelining-Basic-Concepts" class="headerlink" title="L01 Pipelining: Basic Concepts"></a>L01 Pipelining: Basic Concepts</h1><h2 id="MIPS"><a href="#MIPS" class="headerlink" title="MIPS"></a>MIPS</h2><ul>
<li>ALU Instructions: add $s1, $s2, $s3</li>
<li>Load/Store Instructions: lw/sw $s1 offset($s2)</li>
<li>Branch Instructions: beq/bne $s1, $s2, L1</li>
</ul>
<p>R-Format for Instructions</p>
<img src="/2018/05/16/Advanced-Computer-Architectures/1.png">
<p>Phase of execution of MIPS Instructions:</p>
<ol>
<li>Instruction Fetch</li>
<li>Instruction Decode and Register Read</li>
<li>Execution</li>
<li>Memory Access</li>
<li>Write Back Cycle</li>
</ol>
<p>Different type of Instructions(R/I/J) may require different execution phase. In an ALU R-Instruction, there is no needs for the memory access.</p>
<h2 id="Pipelining"><a href="#Pipelining" class="headerlink" title="Pipelining"></a>Pipelining</h2><p><strong>Basic idea</strong>: The execution of an instruction is divided into different phases (pipelines stages), requiring a fraction of the time necessary to complete the instruction.</p>
<blockquote>
<p><strong>The pipeline stages must besynchronized</strong>: the duration of a clock cycle is defined by the time requested by the slower stage of the pipeline.The goal is to balance the length of each pipeline stage.</p>
<p>一个MIPS Instruction可能需要8ns，但是为了在宏观上实现pipelining，我们把5个阶段分开，并且将最长事件的阶段作为一个clock cycle，虽然每一个Instruction花费的时间变多了，但是由于pipelining，整体的output提高了。</p>
</blockquote>
<img src="/2018/05/16/Advanced-Computer-Architectures/2.png">
<h2 id="Pipeline-Hazards"><a href="#Pipeline-Hazards" class="headerlink" title="Pipeline Hazards"></a>Pipeline Hazards</h2><ol>
<li>Structural Hazards: Use the same resource from different instructions simultaneously</li>
<li>Data Hazards: Attempt to use a result before it is ready</li>
<li>Control Hazards: Attempt to make a decision on the next instruction to execute before the condition is evaluated.</li>
</ol>
<blockquote>
<p>No s-hazards in MIPS<br>While d-hazard in very possible (RAW)<br>WAW/WAR occur more easily when instructions are executed out-of-order.</p>
</blockquote>
<p>Data Hazards Solution:</p>
<ol>
<li>Insertion of nop</li>
<li>Rescheduling to avoid correlating instruction too close</li>
<li>Insertion of stalls</li>
<li>data forward or bypassing (uses temporary results stored in the pipeline registers instead of waiting for the write back of results in the RF)</li>
</ol>
<blockquote>
<p>The differnce between nop and stalls is that nop is an instruction, while stalls is only stalled for one clk</p>
<p>Forwarding Paths<br>EX/EX path<br>MEM/EX path<br>MEM/ID path<br>MEM/MEM path (for load/stores)</p>
<p>To avoid the read/write RF in one clk, we assume the RF read occurs in the second half of clock cycle and the RF write in the first half of clock cycle.</p>
</blockquote>
<h2 id="Performance-Metrics-in-Pipelining"><a href="#Performance-Metrics-in-Pipelining" class="headerlink" title="Performance Metrics in Pipelining"></a>Performance Metrics in Pipelining</h2><p>IC = Instruction Cound</p>
<p>Clk Cycles = IC + #Stalls + 4</p>
<p>CPI = Clk Cycles/IC</p>
<p>MIPS = f<sub>clock</sub>/(CPI*10<sup>6</sup>)</p>
<p>The ideal CPI on a pipelined processor would be 1, but stalls cause the pipeline performance to degrade form the ideal performance.</p>
<h1 id="L02-Branch-Prediction-Techiniques"><a href="#L02-Branch-Prediction-Techiniques" class="headerlink" title="L02 Branch Prediction Techiniques"></a>L02 Branch Prediction Techiniques</h1><p>Control hazards: Attempt to make a decision on the next instruction to fetch before the branch condition is evaluated.</p>
<h2 id="Branch-Hazards-Solution"><a href="#Branch-Hazards-Solution" class="headerlink" title="Branch Hazards Solution"></a>Branch Hazards Solution</h2><p><strong>Conservative Assumption</strong>: stall the pipeline until the branch decision is taken, and then fetch the correct instruction.</p>
<p><strong>Conservative Assumption with Forwarding</strong></p>
<p><strong>Early Evaluation of the PC</strong>: get the result of the branch prediction in the end of ID state.</p>
<h2 id="Branch-Prediction-Techniques"><a href="#Branch-Prediction-Techniques" class="headerlink" title="Branch Prediction Techniques"></a>Branch Prediction Techniques</h2><h3 id="Static-Branch-Prediction-Techniques"><a href="#Static-Branch-Prediction-Techniques" class="headerlink" title="Static Branch Prediction Techniques"></a>Static Branch Prediction Techniques</h3><p>The actions for a branch are fixed for each branch during the entire execution. The actions are fixed at compile time.</p>
<ol>
<li>Branch Always Not Taken: if the branch is actually taken, make the fetched instruction a nop.</li>
<li>Branch Always Taken</li>
<li>Backward Taken Forward Not Taken: backward-going branches are predicted as taken, while forward-going branches are predicted as not taken.</li>
<li>Profile-Driven Prediction</li>
<li>Delayed Branch: The MIPS compiler always schedules a branch independent instruction after the branch. (there are 4 ways in Delayed Branch: From Before/From Target/From fall-throuogh/From After)</li>
</ol>
<h3 id="Dynamic-Branch-Prediction-Techniques"><a href="#Dynamic-Branch-Prediction-Techniques" class="headerlink" title="Dynamic Branch Prediction Techniques"></a>Dynamic Branch Prediction Techniques</h3><p>The decision causing the branch prediction can dynamically change during the program execution.</p>
<p>Schemes:</p>
<blockquote>
<p>Branch Outcome Predictor<br>Branch Target Predictor/Branch Target Buffer</p>
</blockquote>
<ol>
<li>Branch History Table</li>
<li>Correlating Branch Predictor: Branch predictors that use the behavior of other branches to make a prediction are called Correlating Predictors or 2-level Predictors.</li>
<li>Two-level Adaptive Branch Predictor: The first level history is recorded in one (or more) k-bit shift register called Branch History Register (BHR), which records the outcomes of the k most recent branches. The second level history is recorded in one (or more) tables called Pattern History Table (PHT) of two-bit saturating counters.</li>
<li>Branch Target Buffer</li>
</ol>
<h1 id="L03-Instruction-Level-Parallelism-Part-I-Introduction"><a href="#L03-Instruction-Level-Parallelism-Part-I-Introduction" class="headerlink" title="L03 Instruction Level Parallelism Part I - Introduction"></a>L03 Instruction Level Parallelism Part I - Introduction</h1><h2 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h2><ol>
<li>Data Dependencies(True Data Dependences): RAW-data dependence/WAR-anti dependence/WAW-output dependence</li>
<li>Name Dependencies: 2 instructions use the same register or memory location, but there are no flow of data between the instruction associated with that name.</li>
<li>Control Dependencies</li>
</ol>
<h2 id="Multi-cycles-Basic-Assumptions"><a href="#Multi-cycles-Basic-Assumptions" class="headerlink" title="Multi-cycles: Basic Assumptions"></a>Multi-cycles: Basic Assumptions</h2><ul>
<li>We consider single-issue processors.</li>
<li>Instructions are then issued in-order.</li>
<li>Execution stage might require multiple cycles, depending on the operation type.</li>
<li>Memory stage might require multiple cycles access time due to data cache misses.</li>
</ul>
<blockquote>
<p>ILP = Exploit potential overlap of execution among unrelated instructions<br>While overlapping possible only if: NO structural/RAW/WAR/WAW/Control hazards</p>
</blockquote>
<p>In a multiple-issue pipelined processor, the ideal CPI would be CPI ideal &lt; 1. (Dual issue means there are two lanes to execute the two pipeline simutanously)</p>
<p>The <strong>issue width</strong> is the number of instructions that can be issued in a single cycle by a multiple issue processor</p>
<h2 id="Two-Strategies-to-support-ILP-Dynamic-Scheduling-Static-Scheduling"><a href="#Two-Strategies-to-support-ILP-Dynamic-Scheduling-Static-Scheduling" class="headerlink" title="Two Strategies to support ILP: Dynamic Scheduling/Static Scheduling"></a>Two Strategies to support ILP: Dynamic Scheduling/Static Scheduling</h2><p>Hazards due to data dependences that cannot be solved by forwarding cause stalls of the pipeline: no new instructions are fetched nor issued even if they are not data dependent.</p>
<p><strong>Solution</strong>: Allow data independent instructions behind a stall to proceed. (Enables out-of-order execution and completion/commit)</p>
<h3 id="Dynamic-Scheduling-Superscalar-Processor-Expensive"><a href="#Dynamic-Scheduling-Superscalar-Processor-Expensive" class="headerlink" title="Dynamic Scheduling: Superscalar Processor [Expensive]"></a>Dynamic Scheduling: Superscalar Processor [Expensive]</h3><p>Dynamic Scheduling: The hardware reorder dynamically the instruction execution to reduce pipeline stalls while maintaining data flow and exception behavior.</p>
<ul>
<li>Basically: Instructions are fetched and issued in program order (in-order-issue)</li>
<li>Execution begins as soon as operands are available – possibly, out of order execution – note: possible even with pipelined scalar architectures.</li>
<li>Out-of order execution introduces possibility of WAR and WAW data hazards.</li>
<li>Out-of order execution implies out of order completion unless there is a re-order buffer to get in- order completion</li>
</ul>
<h3 id="Static-Scheduling-VLIW"><a href="#Static-Scheduling-VLIW" class="headerlink" title="Static Scheduling: VLIW"></a>Static Scheduling: VLIW</h3><p>VLIW (Very Long Instruction Word) processors expect dependency-free code generated by the compiler</p>
<h1 id="L04-Instruction-Level-Parallelism-Part-II-Scoreboard"><a href="#L04-Instruction-Level-Parallelism-Part-II-Scoreboard" class="headerlink" title="L04 Instruction Level Parallelism Part II - Scoreboard"></a>L04 Instruction Level Parallelism Part II - Scoreboard</h1><blockquote>
<p>Basic Assumptions<br>Single Issue processors<br>IF might fetch either into an IR or into a queue of pending instructions<br>Instructions are then issued from the IR or from the queue<br>EX stage may require multiple cycles<br>MEM stage may require multiple cycles</p>
</blockquote>
<h2 id="Scoreboard-Pipeline-in-order-issue-but-out-of-order-execution-completion"><a href="#Scoreboard-Pipeline-in-order-issue-but-out-of-order-execution-completion" class="headerlink" title="Scoreboard Pipeline: in-order issue but out-of-order execution/completion"></a>Scoreboard Pipeline: in-order issue but out-of-order execution/completion</h2><p>Due to out-of-order completion WAR and WAW hazards can occur.</p>
<p>Scoreboard has 4 stages</p>
<ul>
<li>Issue (decode and check no WAW) [INORDER]</li>
<li>Read Operands (wait until no RAW) } [OUT OF ORDER]</li>
<li>Execution [OUT OF ORDER]</li>
<li>Write result (check no WAR) [OUT OF ORDER]</li>
</ul>
<blockquote>
<p>Optimisations:<br>check for WAW postponed in WRITE Stage instead of in ISSUE Stage<br>forwarding</p>
</blockquote>
<h1 id="L05-Instruction-Level-Parallelism-Part-III-Tomasulo"><a href="#L05-Instruction-Level-Parallelism-Part-III-Tomasulo" class="headerlink" title="L05 Instruction Level Parallelism Part III - Tomasulo"></a>L05 Instruction Level Parallelism Part III - Tomasulo</h1><h2 id="Scheme"><a href="#Scheme" class="headerlink" title="Scheme"></a>Scheme</h2><ul>
<li>ISSUE: [IN ORDER] check for structural hazards in RESERVATION STATIONS (not in FU)</li>
<li>EXECUTION: [OUT OF ORDER] When operands ready (Check for RAW hazards solved)/When FU available (Check for structural hazards in FU)</li>
<li><p>WRITE RESULT: [OUT OF ORDER] Execution completion depends on latency of FUs</p>
</li>
<li><p>REGISTER RENAMING based on Reservation Stations to avoid WAR and WAW hazards</p>
</li>
<li>Results dispatched to RESERVATION STATIONS and to RF through the Common Data Bus</li>
<li>Control is distributed on Reservation Stations</li>
<li>Reservation Stations offer a sort of data forwarding!</li>
</ul>
<h1 id="L06-Instruction-Level-Parallelism-Part-IV-Register-Renaming"><a href="#L06-Instruction-Level-Parallelism-Part-IV-Register-Renaming" class="headerlink" title="L06 Instruction Level Parallelism Part IV - Register Renaming"></a>L06 Instruction Level Parallelism Part IV - Register Renaming</h1><p>Tomasulo: Implicit Register Renaming<br>Explicit Register Renaming</p>
<h2 id="Implicit-Register-Renaming"><a href="#Implicit-Register-Renaming" class="headerlink" title="Implicit Register Renaming"></a>Implicit Register Renaming</h2><p>Register renaming provided by Reservation Stations (which buffer the operands of instructions) to eliminate WAR and WAW hazards</p>
<p>Out-of-order commit really messes up our chance to get precise exceptions!</p>
<h2 id="Explicit-Register-Renaming"><a href="#Explicit-Register-Renaming" class="headerlink" title="Explicit Register Renaming"></a>Explicit Register Renaming</h2><p>Use physical register file that is larger than number of registers specified by the ISA.</p>
<p>对于每一个Function Unit由于其可能具有潜在的WAW等可能性，故我们可以分配一个新的Register给他，比如两个连续的指令:</p>
<blockquote>
<p>DIVD F10 F0 F6<br>ADDD F6 F8 F2<br>由于下面的指令很可能在上面的完成前就完成了，我们为了避免WAR，我们讲ADDD的结果储存在P42中（假设原来的F6是在P32），这就解决了WAR问题。</p>
</blockquote>
<h1 id="L07-Instruction-Level-Parallelism-Part-V-VLIW"><a href="#L07-Instruction-Level-Parallelism-Part-V-VLIW" class="headerlink" title="L07 Instruction Level Parallelism Part V - VLIW"></a>L07 Instruction Level Parallelism Part V - VLIW</h1><p>Single-Issue Processors: Scalar processors that fetch and issue max one operation in each clock cycle.</p>
<p>Multiple-Issue Processors require: Fetching more instructions in a cycle (higher bandwidth from the instruction cache) </p>
<p>Multiple-Issue Processors can be: </p>
<ul>
<li>Dynamically scheduled (issue a varying number of instructions at each clock cycle).</li>
<li>Statically scheduled (issue a fixed number of instructions at each clock cycle).</li>
</ul>
<h2 id="VLIW"><a href="#VLIW" class="headerlink" title="VLIW"></a>VLIW</h2><p>VLIW approach advantages:</p>
<ul>
<li>Simpler hardware because the complexity of the control unit is moved to the compiler</li>
<li>Low power consumption</li>
<li>Good performance through extensive compiler optimization</li>
</ul>
<p>VLIW approach disadvantages:</p>
<ul>
<li>Early VLIWs were quite rigid in the instruction format and they required recompilation of programs for different versions of the hardware</li>
</ul>
<h2 id="Dependencies-1"><a href="#Dependencies-1" class="headerlink" title="Dependencies"></a>Dependencies</h2><ul>
<li><p>RAW Hazards: Scalars/superscalars generate NOPs/stalls or execute successive instructions (dynamic scheduling or instruction reordering)</p>
</li>
<li><p>WAR and WAW Hazards: they are statically solved by the compiler by correctly selecting temporal slots for the operations or by register renaming.</p>
</li>
<li><p>Structural hazards: they are also solved by the compiler.</p>
</li>
<li><p>Control hazards are solved dynamically by the hardware by flushing the execution of instructions due to a mispredicted branch.</p>
</li>
</ul>
<h1 id="L08-VLIW-Code-Scheduling"><a href="#L08-VLIW-Code-Scheduling" class="headerlink" title="L08 VLIW Code Scheduling"></a>L08 VLIW Code Scheduling</h1><h2 id="Dependence-Graph"><a href="#Dependence-Graph" class="headerlink" title="Dependence Graph"></a>Dependence Graph</h2><h2 id="Ready-List"><a href="#Ready-List" class="headerlink" title="Ready List"></a>Ready List</h2><h1 id="L09-Reorder-Buffer"><a href="#L09-Reorder-Buffer" class="headerlink" title="L09 Reorder Buffer"></a>L09 Reorder Buffer</h1><h2 id="ReOrder-Buffer-ROB"><a href="#ReOrder-Buffer-ROB" class="headerlink" title="ReOrder Buffer (ROB)"></a>ReOrder Buffer (ROB)</h2><ul>
<li>Buffer to hold the results of instructions that have finished execution but non committed</li>
<li>Buffer to pass results among instructions that can be speculated</li>
<li>Support out-of-order execution but in-order commit</li>
</ul>
<h2 id="Four-Steps-of-Speculative-Tomasulo-Algorithm"><a href="#Four-Steps-of-Speculative-Tomasulo-Algorithm" class="headerlink" title="Four Steps of Speculative Tomasulo Algorithm"></a>Four Steps of Speculative Tomasulo Algorithm</h2><ol>
<li>Issue — get instruction from FP Op Queue: If reservation station and ROB slot free, issue instr &amp; send operands &amp; ROB no. for destination(this stage sometimes called “dispatch”)</li>
<li>Execution — operate on operands (EX): When both operands ready then execute; if not ready, watch CDB for result; when both operands in reservation station, execute; checks RAW (sometimes called “issue”)</li>
<li>Write result — finish execution (WB) Write on Common Data Bus to all awaiting FUs &amp; ROB; mark reservation station available.</li>
<li>Commit — update register with ROB resultWhen instr. at head of ROB &amp; result present, update register with result (or store to memory) and remove instr from ROB. Mispredicted branch flushes ROB (sometimes called “graduation”)</li>
</ol>
<blockquote>
<p>3 different possible sequences in COMMIT</p>
<ol>
<li>Normal Commit</li>
<li>Store Commit</li>
<li>Instruction is a branch with incorrect prediction</li>
</ol>
</blockquote>
<h1 id="L10-Beyond-ILP-Multithreading"><a href="#L10-Beyond-ILP-Multithreading" class="headerlink" title="L10 Beyond ILP Multithreading"></a>L10 Beyond ILP Multithreading</h1><h1 id="L11-Memory-Hierarchy"><a href="#L11-Memory-Hierarchy" class="headerlink" title="L11 Memory Hierarchy"></a>L11 Memory Hierarchy</h1><h2 id="Main-Goal"><a href="#Main-Goal" class="headerlink" title="Main Goal"></a>Main Goal</h2><p>To increase the performance of a computer through the memory system in order to:</p>
<ul>
<li>Provide the user the illusion to use a memory that is simultaneously large and fast</li>
<li>Provide the data to the processor at high frequency</li>
</ul>
<h2 id="Locality"><a href="#Locality" class="headerlink" title="Locality"></a>Locality</h2><ul>
<li>Temporal Locality: when there is a reference to one memory element, the trend is to refer again to the same memory element soon (i.e., instruction and data reused in loop bodies)</li>
<li>Spatial Locality: when there is a reference to one memory element, the trend is to refer soon at other memory elements whose addresses are close by (i.e., sequence of instructions or accesses to data organized as arrays or matrices)</li>
</ul>
<p>– Exploit temporal locality by keeping the contents of recently accessed locations.<br>– Exploit spatial locality by fetching blocks of data around recently accessed locations.</p>
<p>Levels of memory hierarchy: Registers-&gt;L1 Cache-&gt;L2 Cache-&gt; Main Memory</p>
<h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><p>The memory hierarchy is composed of several levels, but data are copied between two adjacent levels. Let us consider two levels: cache and main memory</p>
<p>The cache level is smaller, faster and more expensive</p>
<p>The minimum chunk of data that can be copied in the cache is the <strong>block</strong> or <strong>cache line</strong>.</p>
<p>Cache hit/miss: whether the requested data is found in the one of the cache blocks</p>
<blockquote>
<p><strong>Hit Rate</strong>: Number of memory accesses that find the data in the upper level with respect to the total number of memory accesses[Hit Rate=#hits/#memory access]<br><strong>Hit Time</strong>: time to access the data in the upper level of the hierarchy, including the time needed to decide if the attempt of access will result in a hit or miss<br><strong>Miss Rate</strong>: number of memory accesses not finding the data in the upper level with respect to the total number of memory accesses[Miss Rate=#misses/#memory accesses]<br><strong>Miss Penalty</strong>: time needed to access the lower level and to replace the block in the upper level<br><strong>Miss Time</strong>: miss time= hit time+ miss penalty[typically hit time《miss penalty]<br><strong>Average Memory Access Time/AMAT</strong>: AMAT = HitRate<em>HitTime+MissRate</em>MissTime<br><strong>Average Memory Access Time/AMAT</strong>: AMAT = HitTime+MissRate*MissPenalty</p>
</blockquote>
<h2 id="Cache-Structure"><a href="#Cache-Structure" class="headerlink" title="Cache Structure"></a>Cache Structure</h2><ol>
<li>Valid bit: indicate if this position contains valid data or not. At the bootstrap, all the entries in the cache are marked as INVALID</li>
<li>Cache Tag: contains the value that uniquelly identifies the memory address corresponding to the stored data.</li>
<li>Cache Data: contains a copy of data (block or cache line)</li>
</ol>
<h2 id="Cache-Architecture"><a href="#Cache-Architecture" class="headerlink" title="Cache Architecture"></a>Cache Architecture</h2><ol>
<li>Direct Mapped Cache</li>
<li>Fully Associative Cache</li>
<li>n-way Set-Associative Cache</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Advanced Computer Architectures </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SVM]]></title>
      <url>/2018/05/06/SVM/</url>
      <content type="html"><![CDATA[<p>This is a note of SVM. The original reading material is <a href="https://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">here</a></p>
<img src="/2018/05/06/SVM/1.png">
<img src="/2018/05/06/SVM/2.png">
<img src="/2018/05/06/SVM/3.png">
<img src="/2018/05/06/SVM/4.png">
<img src="/2018/05/06/SVM/5.png">
<img src="/2018/05/06/SVM/6.png">]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[EyePhone]]></title>
      <url>/2018/05/02/Papers-EyePhone/</url>
      <content type="html"><![CDATA[<p>This blog aims to record some relative information about EYEPHONE.</p>
<h1 id="What’s-EyePhone"><a href="#What’s-EyePhone" class="headerlink" title="What’s EyePhone"></a>What’s EyePhone</h1><p>EyePhone is a personal built project, aims to help blind people with their cellphone to detect the obstacles on the road. EyePhone focus on the common road scenes in the city. It has a quite simple use - “Hold the phone, whenever there is a obstacle in the road, remind the user.”</p>
<blockquote>
<p>Obstacles could have following categrories: Stairs, Bicycle, Street Lights, Cars, Other People, and other obstacles.</p>
</blockquote>
<p>There are some basic idea of how to build this babe:)</p>
<p>Updated at 2018.5.2</p>
<ol>
<li><p><strong>Pure empirical method of CNN</strong>: We trust our CNN methods, and offer tons of data (input: images output: obstacles detected y/n) to train it, and later given specific input it could make a decision.</p>
</li>
<li><p><strong>Combine Machine Learning with Prior Knowledge</strong>: We have some prior knowledge in the obstacle detection, like when something is far it would be small in our sight, while close make it bigger in the sights. </p>
</li>
<li><p><strong>Combine CNN with RNN</strong>: This is a very promising idea while I have no idea of where to start now. I found one interesting fact occasionally, that in a badly scaled picture, sometimes it is hard even for human to find what’s in the picture. While it all the pictures are played fast, it would be easily found! (Imagine watching a badly scaled .gif picture!). So maybe we could combine CNN and RNN and contribute to a better performance. </p>
</li>
</ol>
<p>Updated at 2018.5.7 - Start from detection, and build the distance measure on the experience of object detection</p>
<ol>
<li><p><strong>Analysis based on the high precision images</strong>: use F R-CNN to analysis the position of the obstalces.</p>
</li>
<li><p><strong>Analysis based on the low precision images</strong>: use TPN for the temporal information.</p>
</li>
</ol>
<p>Generally speaking, according to the previous papers, it takes more or less 40 seconds to detect some obstacles in the picture. While here it is more promising to use the method with a low precision image and continous temporal information. It we could combine the knowledge of the conteinous temporal information into some sharing information, it would require a far more less computation.</p>
<p>Updated at 2018.5.10 - Maybe a detection will be good enought to get the Regions of Interests in the picture, and we could only train it to get the ability of distance detection.</p>
<ol>
<li><strong>Analysis based on SS</strong>: use machine learning methods train the model the ability of distance detection, hence there are two conditions we have to reach first. First, we have to make sure Select Search method is good enough to extract all the important information in the picture. Second, this method would have the advantages that it may need less information to train, this scale is handlable in a personal computer, while we have to make sure that we only analysis the RoI of greater weights. (Could we use a neural method to guide the selective search like we do in the AlphaZero?)</li>
</ol>
<h1 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h1><p>In this part, I would noted some useful information I found in some papers and their inspiration on this project. </p>
<h2 id="Paper-Object-Detection-from-Video-Tubelets-with-Convolutional-Neural-Networks"><a href="#Paper-Object-Detection-from-Video-Tubelets-with-Convolutional-Neural-Networks" class="headerlink" title="Paper: Object Detection from Video Tubelets with Convolutional Neural Networks"></a>Paper: Object Detection from Video Tubelets with Convolutional Neural Networks</h2><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S04-07.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO"><a href="#INTRO" class="headerlink" title="INTRO"></a>INTRO</h3><p>Method1: Detect obstacles frame by frame</p>
<p>Method2: Combine Method1 with object tracking</p>
<p>The framework consists of two main modules: 1)a tubelet proposal module that combines object detection and object tracking for tubelet object proposal; 2) a tubelet classification and re-scoring module that performs spatial max-pooling for robust box scoring and temporal convolution for incorporating temporal consistency.</p>
<h3 id="METHOD"><a href="#METHOD" class="headerlink" title="METHOD"></a>METHOD</h3><p>Objects in videos show temporal and spatial consistency. The same object in adjacent frames has similar appearances and locations. Using either (object detectors or object trackers) existing object detection methods or object tracking methods alone cannot effectively solve the VID problem.</p>
<p>The combined model has the discriminative ability from object detectors and the temporal consistency from object trackers. It has 2 following </p>
<ul>
<li>The tubelet proposal module has 3 major steps: </li>
</ul>
<blockquote>
<p>1) image object proposal <strong>(每一帧都进行分析，通过一个算法，将总共可能出现的object的种类从一个很大的类缩减到一个小范围)</strong> </p>
<p>2) object proposal scoring <strong>（对于每个proposal进行分析，根据他们的confidence从几百个proposal进一步削减到几十个proposal）</strong></p>
<p>3) high-confidence object tracking <strong>（对于每一个高confidence的proposal，我们以某一帧为anchor，向前和向后进行track，为了防止track的物体漂移到别的物体或者背景上，当confidence低于某个threshold后停止tracking）</strong>.</p>
</blockquote>
<ul>
<li>Tubelet classification and rescoring has 2 steps: </li>
</ul>
<blockquote>
<p>1) Tubelet box perturbation and max-pooling <strong>（使用这种方法将多个tubelet box进行pooling得到某一帧的boxes）</strong></p>
<p>2) Temporal convolution and re-scoring <strong>（建立一个时序的temporal convolution network 每一个输入x为每一个tubelet box在不同时间【连续输入】的一个三维向量（detection score,tracking score,anchor offset）得到该tubelet box的prediction scores）</strong>.</p>
</blockquote>
<h2 id="Paper-Object-Detection-in-Videos-with-Tubelet-Proposal-Networks"><a href="#Paper-Object-Detection-in-Videos-with-Tubelet-Proposal-Networks" class="headerlink" title="Paper: Object Detection in Videos with Tubelet Proposal Networks"></a>Paper: Object Detection in Videos with Tubelet Proposal Networks</h2><p><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Kang_Object_Detection_in_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO-1"><a href="#INTRO-1" class="headerlink" title="INTRO"></a>INTRO</h3><p>The contribution of this paper is that it propose a new deep learning framework that combines tubelet proposal generation and temporal classification with visual-temporal features. An efficient tubelet proposal generation algorithm is developed to generate tubelet proposals that capture spatiotemporal locations of objects in videos. A temporal LSTM model is adopted for classifying tubelet proposals with both visual features and temporal features. Such high-level temporal features are generally ignored by existing detection systems but are crucial for object detection in videos.</p>
<h3 id="Tubelet-proposal-networks-TPN"><a href="#Tubelet-proposal-networks-TPN" class="headerlink" title="Tubelet proposal networks TPN"></a>Tubelet proposal networks TPN</h3><ul>
<li>Preliminaries on ROI-pooling for regression</li>
</ul>
<p>FAST R-CNN/ROI POOLING</p>
<p>The object of this part is to use ROI-pooling finding the for a <em>t</em>, the corresponding b<sup>i</sup>=(x<sup>i</sup>,y<sup>i</sup>,w<sup>i</sup>,t<sup>i</sup>) denoting the ith box proposal(what could it be!) at time t, where x, y, w and h represent the two coordinates of the box center, width and height of the box proposal.</p>
<ul>
<li>Static object proposals as spatial anchors</li>
</ul>
<p>Let b<sup>i</sup>1 denote a static proposal of interest at time t =1. Particularly, to generate a tubelet proposal starting at b<sup>i</sup>1, visual features within the w-frame temporal window from frame 1 to w are pooled at the same location b<sup>i</sup>1 as r<sup>i</sup>1,r<sup>i</sup>2,…,r<sup>i</sup>w in order to generate the tubelet proposal. We call b<sup>i</sup>1 a “spatial anchor”.</p>
<p>The reason why we are able to pool multi-frame features from the same spatial location for tubelet proposals is that CNN feature maps at higher layers usually have large receptive fields. Even if visual features are pooled from a small bounding box, its visual context is far greater than the bounding box itself. Pooling at the same box locations across time is therefore capable of capturing large possible movements of objects.</p>
<ul>
<li>Supervisions for tubelet proposal generation</li>
</ul>
<p>Our goal is to generate tubelet proposals that have high object recall rates at each frame and can accurately track objects. Based on the pooled visual features r<sup>i</sup>1,r<sup>i</sup>2,…,r<sup>i</sup>w at box locations b<sup>i</sup>t, we train a regression network R(·) that effectively estimates the relative movements w.r.t. the spatial anchors.</p>
<p>Once we obtain such relative movements, the actual box locations of the tubelet could be easily inferred. Our key assumption is that the tubelet proposals should have consistent movement patterns with the ground-truth objects.</p>
<ul>
<li>Initialization for multi-frame regression layer</li>
</ul>
<h2 id="Paper-Fast-R-CNN"><a href="#Paper-Fast-R-CNN" class="headerlink" title="Paper: Fast R-CNN"></a>Paper: Fast R-CNN</h2><p><a href="https://arxiv.org/pdf/1504.08083.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO-2"><a href="#INTRO-2" class="headerlink" title="INTRO"></a>INTRO</h3><p>Object detection is a more challenging task compared with image classification. It has 2 primary challenges:</p>
<p>1) numerous candidate object locations (often called “proposals”) must be processed.<br>2) these candidates provide only rough localization that must be refined to achieve precise localization</p>
<p>While in this paper, based on the work of R-CNN, faster R-CNN has a better performance while at the same time decrease the amout of calculation in the whole process.</p>
<h3 id="R-CNN-Drawback"><a href="#R-CNN-Drawback" class="headerlink" title="R-CNN Drawback"></a>R-CNN Drawback</h3><p>1) Training is a multi-stage pipeline<br>2) Training is expensive in space and time<br>3) Object detection is slow</p>
<p>SPPnet(Spatial pyramid pooling networks) soleve the problem that <strong>R-CNN does not have sharing computation</strong>, it accelerates R-CNN.</p>
<h3 id="FINE-TUNING"><a href="#FINE-TUNING" class="headerlink" title="FINE-TUNING"></a>FINE-TUNING</h3><h3 id="Faster-R-CNN-advantages"><a href="#Faster-R-CNN-advantages" class="headerlink" title="Faster R-CNN advantages"></a>Faster R-CNN advantages</h3><p><a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="noopener">github source</a></p>
<ol>
<li>Higher detection quality (mAP) than R-CNN, SPPnet</li>
<li>Training is single-stage, using a multi-task loss</li>
<li>Training can update all network layers</li>
<li>No disk storage is required for feature caching</li>
</ol>
<h3 id="Faster-R-CNN-architecture"><a href="#Faster-R-CNN-architecture" class="headerlink" title="Faster R-CNN architecture"></a>Faster R-CNN architecture</h3><p>A Fast R-CNN network takes as input an entire image and a set of object proposals. The network first processes the whole image with several convolutional (conv) and max pooling layers to produce a conv feature map. Then, for each object proposal a region of interest (RoI) pooling layer extracts a fixed-length feature vector from the feature map. Each feature vector is fed into a sequence of fully connected (fc) layers that finally branch into two sibling output layers: one that produces softmax probability estimates over K object classes plus a catch-all “background” class and another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes refined bounding-box positions for one of the K classes</p>
<p>对于一个Faster R-CNN来说，输入为<strong>输入图片</strong>和<strong>相关区域（RoI）</strong>，输入图片通过一个CNN进行处理得到一个<strong>卷积特征图（conv feature map）</strong>，而RoI在这张feature map上找到对应的区域，每个相关区域可以被映射到一个固定长度的<strong>特征向量（feature vector）</strong>，这个feature vector会进入下一步的处理（一个fully connected layer），得到两个output：<br>1) softmax probability： K个object分类以及background class的可能性<br>2) per-class bounding box regression offsets： 对每个object class的bounding box位置预测（一个4维向量）</p>
<p>A Fast R-CNN network has two sibling output layers. The first outputs a discrete probability distribution (per RoI), p = (p<sub>0</sub>, . . . , p<sub>K</sub>), over K + 1 categories. As usual, p is computed by a softmax over the K+1 outputs of a fully connected layer. The second sibling layer outputs bounding-box regression offsets, t<sub>k</sub>(t<sup>k</sup><sub>x</sub>,t<sup>k</sup><sub>y</sub>,t<sup>k</sup><sub>w</sub>,t<sup>k</sup><sub>h</sub>) for each of the K object classes, indexed by k.t<sub>k</sub> specifies a scale-invariant translation and log-space height/width shift relative to an object proposal.</p>
<h2 id="Paper-R-CNN-Object-detection"><a href="#Paper-R-CNN-Object-detection" class="headerlink" title="Paper: R-CNN: Object detection"></a>Paper: R-CNN: Object detection</h2><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf?spm=5176.100239.blogcont55892.8.pm8zm1&amp;file=Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" target="_blank" rel="noopener">Click here for the orginal text</a><br><a href="https://blog.csdn.net/shenxiaolu1984/article/details/51066975" target="_blank" rel="noopener">CSDN Relative information</a></p>
<h3 id="INTRO-3"><a href="#INTRO-3" class="headerlink" title="INTRO"></a>INTRO</h3><p>TWO KEY INSIGHTS:</p>
<p>1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects<br>2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost.</p>
<p>Since in this thesis region proposals is combined with CNNs, this method is known as method R-CNN: Regions with CNN features. </p>
<p>TWO CHALLENGE AND THE CONTRIBUTIONS:</p>
<p>1) 速度: 经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上提取特征，进行判断。<br>2) 训练集(the labeled data is scarce and the amount currently available is insufficient for training a large CNN.): 经典的目标检测算法在区域中提取人工设定的特征（Haar，HOG）。本文则需要训练深度网络进行特征提取。可供使用的有两个数据库： <strong>一个较大的识别库（ImageNet ILSVC 2012）</strong>：标定每张图片中物体的类别。一千万图像，1000类。       <strong>一个较小的检测库（PASCAL VOC 2007）</strong>：标定每张图片中，物体的类别和位置。一万图像，20类。本文使用识别库进行预训练，而后用检测库调优参数。最后在检测库上评测。</p>
<p>Combine the object detection and image classification together</p>
<blockquote>
<p>Object detection is what is needed in EyePhone</p>
</blockquote>
<h3 id="Objection-Detection"><a href="#Objection-Detection" class="headerlink" title="Objection Detection"></a>Objection Detection</h3><p>Our object detection system consists of three modules. </p>
<blockquote>
<p>The first generates category-independent region proposals. These proposals define the set of candidate detections available to our detector. </p>
<p>The second module is a large convolutional neural network that extracts a fixed-length feature vector from each region. </p>
<p>The third module is a set of classspecific linear SVMs.</p>
</blockquote>
<p>使用Seletive Search找到region proposals，然后对于每一个region，把他转化成一个固定大小的CNN输入。</p>
<p>对于一个test sample，通过Selective Search得到约2000个region proposals，然后每一个region proposal通过forwad propagation通过一个CNN，在得到每一个region的score之后，我们基于贪心算法，当一个region和另一个region重合，并且那个新的region的score高于某一个threshold，那么选择那个新的region代替两个region。</p>
<h2 id="Paper-Selective-Search"><a href="#Paper-Selective-Search" class="headerlink" title="Paper: Selective Search"></a>Paper: Selective Search</h2><p><a href="https://koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="noopener">Click here for the orginal text</a><br><a href="https://github.com/CesareMJLi/selectivesearch" target="_blank" rel="noopener">Click here for the project</a></p>
<p>由于该篇文章和本工程的相关性，该篇论文的注释将会用中文进行。</p>
<p><strong>Selective search is a algorithm in object detection! (not recognition)</strong></p>
<h3 id="INTRO-分割与穷举"><a href="#INTRO-分割与穷举" class="headerlink" title="INTRO 分割与穷举"></a>INTRO 分割与穷举</h3><p>在图片的物体识别领域，我们发现很难用一种统一的方法对所有的图片进行分类，我们需要考虑纹理，颜色以及这个物体的真实属性（一个轮子是单独的么？还是说这个轮子属于一辆车？），虽然在一张图片中往往其中一个就可以给出一个分类或者探测，但是在宏观上我们需要将多个元素进行考虑，而且还有一个问题是，往往我们用分割的方法（a unique partitioning of the image through a generic algorithm, where there is one part for all object silhouettes in the image.）很难得到一个正确的结论，在很多图片中，它的结构是intrinsic iherachical的，比如一个桌子上有若干个杯子，杯子里放着乒乓球或者羽毛球，我们需要考虑的是一个hierachical的模型。</p>
<p>通常情况下，我们在考虑object recognition的时候往往需要先进行object detection，然而在这篇论文中使用了另一种思路的方法，<strong>to do localisation through the identification of an object</strong>，比如以下这个情景，<em>在一张图片中出现了一个穿西装上衣的人，模型可以识别在西装上面有一张脸，然而为了识别整体的人的概念，我们需要模型对于这个概念有了解（prior recognition）。</em></p>
<p>一个解决方案是穷举法（对于每一个box boundary，它可能包含人/自行车/航空母舰嘛？），显而易见这种方法几乎是computatianal impossible，在这篇文章中提出的selective search的方法结合了segmentation和exhausive search，通过Bottom up segmentation获取图片的结构和每个object的位置【生成对象位置】，通过exhausive search捕捉每一个可能的object的位置信息【捕捉可能的对象的位置】。</p>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><ul>
<li>Exhaustive Search</li>
</ul>
<p>As an object can be located at any position and scale in the image, it is natural to search everywhere [8, 16, 36]. However, the visual search space is huge, making an exhaustive search computationally expensive. This imposes constraints on the evaluation cost per location and/or the number of locations considered. Hence most of these <strong>sliding window techniques</strong> use a coarse search grid and fixed aspect ratios, using weak classifiers and economic image features such as HOG.</p>
<p>While still, HIGH COST! EVEN WITH SOME IMPROVEMENTS, A EXHAUSTIVE SEARCH MAY STILL VISIT OVER 100,000 WINDOWS PER IMAGE.</p>
<p>Instead of a blind exhaustive search or a branch and bound search, we propose selective search. We use the underlying image structure to generate object locations. In contrast to the discussed methods, this yields a completely class-independent set of locations and generating less locations, which means saving a lot of computer power.</p>
<ul>
<li>Segmentation</li>
</ul>
<p>In the previous segmentation research, there are some approaches by segmenting and recognizing objects in parts. They first generate a set of part hypotheses using a grouping method based on Arbelaez. Each part hypothesis is described by both appearance and shape features. Then, an object is recognized and carefully delineated by using its parts, achieving good results for shape recognition.</p>
<p>In their work, the segmentation is hierarchical and yields segments at all scales. However, they use a single grouping strategy whose power of discovering parts or objects is left unevaluated. In this work, we use multiple complementary strategies to deal with as many image conditions as possible.</p>
<h3 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h3><blockquote>
<p>the selective search should fulfill 3 considerations</p>
<p><strong>捕获全部scale上的Objects</strong>：因为一个object可能在一张图片上的任意scale出现，甚至有些objects可能会具有模糊的边界。【通过using a hierachical algorithm解决】</p>
<p><strong>多样化</strong>：不存在一种最好的策略将不同的region进行group。每个区域可能通过颜色，纹理等等形成一个object，所以与其采用一种在大部分情况下都行得通的单一的策略，我们想找到一系列策略来对应全部的情形。</p>
<p><strong>易于计算</strong></p>
</blockquote>
<ul>
<li>Selective Search by Hierarchical Grouping</li>
</ul>
<p>Bottom-up grouping is a popular approach to segmentation, hence we adapt it for selective search. This is a hierarchicalmethods, which means that we could naturally generate locations at all scales by continueing the grouping process until the whole image becomes a single region.</p>
<img src="/2018/05/02/Papers-EyePhone/1.png">
<p>Bottom-up grouping is a popular approach to segmentation, we use this to get the initial regions</p>
<p>输入为一张照片，首先通过the fast method of Felzenszwalb and Huttenlocher创建initial regions R，然后我们使用贪心算法迭代的将regions组合起来，具体的过程为首先，【<em>建立一个空集合S，首先对于每一对region pair，我们计算similarity，然后将他们的相似性放在集合S中</em>】，然后【<em>从S中取出最高的相似性的region pair，将两个融合成为新的region，并且移除与久的region有关的相似性并且计算新的region和它的周围的部分的相似性</em>】，重复第二个步直到S成为空集。</p>
<blockquote>
<p>在计算相似性的时候，我们必须保证新的r的特章必须可以通过原来的r计算得到而不需要回到pixel level重新计算。</p>
</blockquote>
<ul>
<li>Diversification Strategies</li>
</ul>
<p>Create <strong>a set of complementary strategies</strong> whose locations are combined afterwards. Some popular strategies are (1) by using a variety of colour spaces with different invariance properties, (2) by using different similarity measures s<sub>ij</sub>, and (3) by varying our starting regions.</p>
<blockquote>
<p>Complementary Colour Spaces</p>
<p>Complementary Similarity Measures(s<sub>colour</sub>,s<sub>texture</sub>,s<sub>size</sub>,s<sub>fill</sub>)</p>
<p>Complemenetart Starting Regions</p>
</blockquote>
<ul>
<li>Combining Locations</li>
</ul>
<h2 id="Felzenswalb-Algorithm-in-image-segmentation"><a href="#Felzenswalb-Algorithm-in-image-segmentation" class="headerlink" title="Felzenswalb Algorithm in image segmentation"></a>Felzenswalb Algorithm in image segmentation</h2><p><a href="http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf" target="_blank" rel="noopener">Click here for the original paper text</a><br><a href="https://blog.csdn.net/ttransposition/article/details/38024557" target="_blank" rel="noopener">Click here for the Chinese comments</a></p>
<p>本质上这种算法提供了图像分割的一种非AI的解决方法，对于图中的每一个像素进行考虑，设定超参数约束分割的granularity，然后得到一个分割后的图像，该算法的核心是图像中的颜色分布，所以就导致在其眼中分布是一块一块的，不能对一个对象进行有效的分割和识别。</p>
]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> CNN </tag>
            
            <tag> EyePhone </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning V Recurrent Neural Network & Other Methods]]></title>
      <url>/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/</url>
      <content type="html"><![CDATA[<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>循环神经网络(recurrent neural network)或 RNN (Rumelhart et al., 1986c) 是一类用于处理序列数据的神经网络。就像卷积网络是专门用于处理网格化数据 X (如一个图像)的神经网络，循环神经网络是专门用于处理序列 x(1),…,x(τ) 的神 经网络。正如卷积网络可以很容易地扩展到具有很大宽度和高度的图像，以及处理 大小可变的图像，循环网络可以扩展到更长的序列(比不基于序列的特化网络长得多)。大多数循环网络也能处理可变长度的序列。</p>
<h2 id="展开计算图"><a href="#展开计算图" class="headerlink" title="展开计算图"></a>展开计算图</h2><img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/1.png">
<p>当训练循环网络根据过去预测未来时，网络通常要学会使用 h(t) 作为过去序列 (直到 t)与任务相关方面的有损摘要。此摘要一般而言一定是有损的，因为其映射 任意长度的序列 (x(t), x(t−1), x(t−2), . . . , x(2), x(1)) 到一固定长度的向量 h(t)。根据不 同的训练准则，摘要可能选择性地精确保留过去序列的某些方面。例如，如果在统 计语言建模中使用的 RNN，通常给定前一个词预测下一个词，可能没有必要存储时 刻 t 前输入序列中的所有信息;而仅仅存储足够预测句子其余部分的信息。最苛刻 的情况是我们要求 h(t) 足够丰富，并能大致恢复输入序列。</p>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/2.png">
<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><blockquote>
<p>通用设计模式</p>
<p>其中h表示激活函数，其中包含了输入的加权过程，o表示非标准化对数概率，y表示标准化输出</p>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/6.png">
<ol>
<li>每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络</li>
</ol>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/3.png">
<ol>
<li>每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的循环网络</li>
</ol>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/4.png">
<ol>
<li>隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的循环网络</li>
</ol>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/5.png">
</blockquote>
<p>通常情况下设计模式1为最常用的设计模式。</p>
<h3 id="导师驱动过程和输出循环网络（设计模式2）"><a href="#导师驱动过程和输出循环网络（设计模式2）" class="headerlink" title="导师驱动过程和输出循环网络（设计模式2）"></a>导师驱动过程和输出循环网络（设计模式2）</h3><img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/7.png">
<p>这种方式使训练过程可以并行的进行，因为我们不需要每次都将上次的train得到的o输入到下一层，而是将正确的y输入，故很大程度的减小了梯度下降的难度。</p>
<h3 id="神经网络梯度计算"><a href="#神经网络梯度计算" class="headerlink" title="神经网络梯度计算"></a>神经网络梯度计算</h3><h2 id="双向RNN"><a href="#双向RNN" class="headerlink" title="双向RNN"></a>双向RNN</h2><img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/8.png">
<h2 id="基于编码-解码的序列到序列架构"><a href="#基于编码-解码的序列到序列架构" class="headerlink" title="基于编码-解码的序列到序列架构"></a>基于编码-解码的序列到序列架构</h2><p>我们经常将RNN的输入称为”上下文”。我们希望产生此上下文的表示C。这个上下文C可能是一个概括输入序列 X = (x(1) , . . . , x(n)) 的向量或者向量序列。</p>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/9.png">
<h2 id="深度循环网络"><a href="#深度循环网络" class="headerlink" title="深度循环网络"></a>深度循环网络</h2><h2 id="递归神经网络"><a href="#递归神经网络" class="headerlink" title="递归神经网络"></a>递归神经网络</h2><h1 id="实践方法论"><a href="#实践方法论" class="headerlink" title="实践方法论"></a>实践方法论</h1><h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><h2 id="默认基准模型"><a href="#默认基准模型" class="headerlink" title="默认基准模型"></a>默认基准模型</h2><h2 id="更多数据？"><a href="#更多数据？" class="headerlink" title="更多数据？"></a>更多数据？</h2><h2 id="超参数选择"><a href="#超参数选择" class="headerlink" title="超参数选择"></a>超参数选择</h2><h1 id="相关应用"><a href="#相关应用" class="headerlink" title="相关应用"></a>相关应用</h1>]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Recurrent Neural Network </tag>
            
            <tag> RNN </tag>
            
            <tag> Machine Learning Methods </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning IV Optimization & CNN]]></title>
      <url>/2018/04/19/Deep-Learning-IV-Optimization-CNN/</url>
      <content type="html"><![CDATA[<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><p>本章主要关注这一类特定的优化问题:寻找神经网络上的一组参数θ，它能显著地降低代价函数J(θ)，该代价函数通常包括整个训练集上的性能评估和额外的正则化项。</p>
<h2 id="学习和纯优化"><a href="#学习和纯优化" class="headerlink" title="学习和纯优化"></a>学习和纯优化</h2><img src="/2018/04/19/Deep-Learning-IV-Optimization-CNN/1.png">
<p>J<sup>*</sup>这个式子可以这样去理解，(x,y)是关于p<sub>data的分布，L表示Loss Function，计算模型f根据输入x和当前参数θ得到的输出y‘与真实y之前的差，这个式子整体上表示了当前model的loss在真实x～y分布下的期望。</sub></p>
<p>机器学习算法和一般优化算法不同的一点是，机器学习算法的目标函数通常可 以分解为训练样本上的求和。机器学习中的优化算法在计算参数的每一次更新时通 常仅使用整个代价函数中一部分项来估计代价函数的期望值。</p>
<img src="/2018/04/19/Deep-Learning-IV-Optimization-CNN/2.png">
<p>使用整个训练集的优化算法被称为 批量(batch)或 确定性(deterministic)梯 度算法，因为它们会在一个大批量中同时处理所有样本。这个术语可能有点令人困 惑，因为这个词 “批量’’ 也经常被用来描述小批量随机梯度下降算法中用到的小批 量样本。通常，术语 “批量梯度下降’’ 指使用全部训练集，而术语 “批量’’ 单独出现 时指一组样本。例如，我们普遍使用术语 “批量大小’’ 表示小批量的大小。</p>
<p>每次只使用单个样本的优化算法有时被称为 随机(stochastic)或者 在线(on- line)算法。术语 “在线’’ 通常是指从连续产生样本的数据流中抽取样本的情况，而 不是从一个固定大小的训练集中遍历多次采样的情况。</p>
<p>大多数用于深度学习的算法介于以上两者之间，使用一个以上，而又不是全部 的训练样本。传统上，这些会被称为 小批量(minibatch)或 小批量随机(minibatch stochastic)方法，现在通常将它们简单地称为 随机(stochastic)方法。</p>
<h2 id="优化的挑战"><a href="#优化的挑战" class="headerlink" title="优化的挑战"></a>优化的挑战</h2><blockquote>
<p>病态</p>
<p>局部最小值</p>
<p>鞍点</p>
<p>悬崖和梯度爆炸</p>
<p>长期依赖</p>
</blockquote>
<h2 id="随机梯度下降方法"><a href="#随机梯度下降方法" class="headerlink" title="随机梯度下降方法"></a>随机梯度下降方法</h2><pre><code>Require: 学习率 ε&lt;sub&gt;k&lt;/sub&gt;
Require: 初始参数 θ
    while 停止准则未满足 do
        从训练集中采包含 m 个样本 {x(1),...,x(m)} 的小批量，其中 x(i) 对应目标为y(i)。
        计算梯度估计:gˆ ← + 1/m ∇&lt;sub&gt;θ&lt;/sub&gt; ∑ L(f(x(i); θ), y(i))
        应用更新:θ ← θ − εgˆ
    end while
</code></pre><p>SGD 算法中的一个关键参数是学习率。之前，我们介绍的 SGD 使用固定的学 习率。在实践中，有必要随着时间的推移逐渐降低学习率，因此我们将第k步迭代 的学习率记作 ε<sub>k</sub>。</p>
<h2 id="动量方法"><a href="#动量方法" class="headerlink" title="动量方法"></a>动量方法</h2><p>从形式上看，动量算法引入了变量 v 充当速度角色——它代表参数在参数空间 移动的方向和速率。速度被设为负梯度的指数衰减平均。名称 动量(momentum) 来自物理类比，根据牛顿运动定律，负梯度是移动参数空间中粒子的力。动量在物 理学上定义为质量乘以速度。在动量学习算法中，我们假设是单位质量，因此速度 向量 v 也可以看作是粒子的动量。超参数α ∈ [0, 1)决定了之前梯度的贡献衰减得有多快。更新规则如下:</p>
<img src="/2018/04/19/Deep-Learning-IV-Optimization-CNN/3.png">
<p>之前，步长只是梯度范数乘以学习率。现在，步长取决于梯度序列的大小和排 列。当许多连续的梯度指向相同的方向时，步长最大。如果动量算法总是观测到梯 度 g，那么它会在方向 −g 上不停加速，直到达到最终速度。</p>
<h2 id="Nesterov动量"><a href="#Nesterov动量" class="headerlink" title="Nesterov动量"></a>Nesterov动量</h2><h2 id="参数初始化策略"><a href="#参数初始化策略" class="headerlink" title="参数初始化策略"></a>参数初始化策略</h2><h2 id="自适应学习率算法"><a href="#自适应学习率算法" class="headerlink" title="自适应学习率算法"></a>自适应学习率算法</h2><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1>]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> CNN </tag>
            
            <tag> Optimization </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning III Deep Feedforward Network & Regularization]]></title>
      <url>/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/</url>
      <content type="html"><![CDATA[<h1 id="深度前馈网络-Deep-Feedforward-Network"><a href="#深度前馈网络-Deep-Feedforward-Network" class="headerlink" title="深度前馈网络 Deep Feedforward Network"></a>深度前馈网络 Deep Feedforward Network</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>深度前馈网络(deep feedforward network)</strong>,也叫作 前馈神经网络(feedforward neural network)或者 多层感知机(multilayer perceptron, MLP),是典型的深度学习模型。前馈网络的目标是近似某个函数 f<sup>∗</sup>。例如,对于分类器y=f<sup>∗</sup>(x) 将输入 x 映射到一个类别 y。</p>
<p>前馈网络定义了一个映射 y = f(x;θ),并且学习参数 θ 的值,使它能够得到最佳的函数近似。</p>
<p>这种模型被称为 前向(feedforward)的,是因为信息流过 x 的函数,流经用于定义 f 的中间计算过程,最终到达输出 y。在模型的输出和模型本身之间没有 反馈(feedback)连接。当前馈神经网络被扩展成包含反馈连接时,它们被称为 循环神经网络(recurrent neural network),在第十章介绍。</p>
<blockquote>
<p>Example</p>
<p>f(x)=f3(f2(f1(x)))</p>
</blockquote>
<p>这个名字。前馈网络的最后一层被称为<strong>输出层(output layer)</strong>。在神经网络训练的过程中,我们让 f(x) 去匹配 f<sup>∗</sup>(x)的值(也就是真实函数的值)。训练数据为我们提供了在不同训练点上取值的、含有噪声的f<sup>∗</sup>(x) 的近似实例。每个样本 x 都伴随着一个标签 y ≈ f<sup>∗</sup>(x)。</p>
<p>训练样本直接指明了输出层在每一点 x 上必须做什么;它必须产生一个接近 y 的值。但是训练数据并没有直接指明其他层应该怎么做。学习算法必须决定如何使用这些层来产生想要的输出,但是训练数据并没有说每个单独的层应该做什么。相反,学习算法必须决定如何使用这些层来最好地实现f<sup>∗</sup> 的近似。因为训练数据并没有给出这些层中的每一层所需的输出,所以这些层被称为<strong>隐藏层(hidden layer)</strong>。</p>
<p>为了扩展线性模型来表示 x 的非线性函数,我们可以不把线性模型用于 x 本身,而是用在一个变换后的输入φ(x) 上,这里 φ 是一个非线性变换。同样,我们可以使用核技巧,来得到一个基于隐含地使用 φ 映射的非线性学习算法。我们可以认为 φ 提供了一组描述 x 的特征,或者认为它提供了 x 的一个新的表示。</p>
<p>那么如何定义φ？深度学习的策略是去学习φ。在这种方法中,我们有一个模型 y = f(x; θ, w)=φ(x; θ)<sup>⊤</sup>w。我们现在有两种参数:用于从一大类函数中学习φ的参数 θ,以及用于将 φ(x) 映射到所需的输出的参数w</p>
<blockquote>
<p>  注意！φ不是参数</p>
</blockquote>
<h2 id="XOR"><a href="#XOR" class="headerlink" title="XOR"></a>XOR</h2><h2 id="基于梯度学习"><a href="#基于梯度学习" class="headerlink" title="基于梯度学习"></a>基于梯度学习</h2><p>我们到目前为止看到的线性模型和神经网络的最大区别,在于神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸（在多项式函数中的每一个函数都是凸的，如x^2,x^3,…）。这将会导致我们通过迭代的基于梯度的优化只能让代价函数达到一个很小的值而不一定是最小值，而训练算法也依然是基于梯度来使函数下降。</p>
<h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>在大多数情况下,我们的参数模型定义了一个分布p(y|x;θ)并且我们简单地使用最大似然原理。这意味着我们使用训练数据和模型预测间的交叉熵作为代价函数。</p>
<blockquote>
<p>使用最大似然学习条件分布</p>
</blockquote>
<h3 id="输出单元"><a href="#输出单元" class="headerlink" title="输出单元"></a>输出单元</h3><blockquote>
<p>sigmoid function</p>
<p>softmax function</p>
</blockquote>
<h2 id="隐藏单元"><a href="#隐藏单元" class="headerlink" title="隐藏单元"></a>隐藏单元</h2><p>大多数的隐藏单元都可以描述为接受输入向量x，计算仿射变换 z=W<sup>⊤</sup>x+b，然后使用一个逐元素的非线性函数g(z)。大多数隐藏单元的区别 仅仅在于激活函数g(z)的形式</p>
<blockquote>
<p>整流线型单元 g(z)=max{0,z}</p>
<p>logistic sigmoid function/双曲正切激活函数</p>
<p>其他隐藏单元</p>
</blockquote>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h2 id="万能近似性质"><a href="#万能近似性质" class="headerlink" title="万能近似性质"></a>万能近似性质</h2><p>乍一看，我们可能认为学习非线性函数需要为我们想要学习的那种非线性专 门设计一类模型族。幸运的是，具有隐藏层的前馈网络提供了一种万能近似框架。 具体来说， 万能近似定理(universal approximation theorem)(Hornik et al., 1989; Cybenko, 1989) 表明，一个前馈神经网络如果具有线性输出层和至少一层具有任何 一种 ‘‘挤压’’ 性质的激活函数(例如logistic sigmoid激活函数)的隐藏层，只要给予 网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另 一个有限维空间的 Borel 可测函数。</p>
<p>万能近似定理意味着无论我们试图学习什么函数，我们知道一个大的MLP一定能够表示这个函数。然而，我们不能保证训练算法能够学得这个函数。即使MLP能够表示该函数，学习也可能因两个不同的原因而失败。<strong>首先，用于训练的优化算法可能找不到用于期望函数的参数值。其次，训练算法可能由于过拟合而选择了错误的函数</strong>。</p>
<p>具有单层的前馈网络足以表示任何函数，但是网络层可能大得不可实现， 并且可能无法正确地学习和泛化。在很多情况下，使用更深的模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误差。</p>
<h2 id="反向传播和其他微分算法"><a href="#反向传播和其他微分算法" class="headerlink" title="反向传播和其他微分算法"></a>反向传播和其他微分算法</h2><p><a href="https://www.cnblogs.com/charlotte77/p/5629865.html" target="_blank" rel="noopener">相关链接</a></p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>机器学习中的一个核心问题是设计不仅在训练数据上表现好，并且能在新输入 上泛化好的算法。在机器学习中，许多策略显式地被设计来减少测试误差(可能会 以增大训练误差为代价)。这些策略被统称为正则化。我们将在后文看到，深度学 习工作者可以使用许多不同形式的正则化策略。事实上，开发更有效的正则化策略 已成为本领域的主要研究工作之一。</p>
<p>将正则化定义为 ‘‘对学习算法的修改——旨在减少泛化误 差而不是训练误差’’。目前有许多正则化策略。有些策略向机器学习模型添加限制参 数值的额外约束。有些策略向目标函数增加额外项来对参数值进行软约束。如果我 们细心选择，这些额外的约束和惩罚可以改善模型在测试集上的表现。有时侯，这些 约束和惩罚被设计为编码特定类型的先验知识;其他时候，这些约束和惩罚被设计 为偏好简单模型，以便提高泛化能力。有时，惩罚和约束对于确定欠定的问题是必 要的。其他形式的正则化，如被称为集成的方法，则结合多个假说来解释训练数据。</p>
<p>通常情况下，面对一组数据和对应的训练，我们往往需要面对模型的三种情况</p>
<blockquote>
<ol>
<li><p>没有概括真实的数据生成过程–欠拟合/过大的bias</p>
</li>
<li><p>匹配真实的数据生成过程–完美！</p>
</li>
<li><p>除了包含了数据的生成过程，还包含了许多其他的生成过程–Variance主导的过拟合</p>
</li>
</ol>
</blockquote>
<p>正则化的目标是使模型从情况3转化为情况2</p>
<h2 id="参数范数惩罚"><a href="#参数范数惩罚" class="headerlink" title="参数范数惩罚"></a>参数范数惩罚</h2><img src="/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/1.png">
<p>注意，在神经网络中，参数包括每一层仿射变换的权重和偏置，然而我们通常只对权重做惩罚。</p>
<ul>
<li><p>L<sup>2</sup>参数正则化，添加一个正则项Ω(θ)=1/2||w||<sup>2</sup><sub>2，又被成为岭回归（Ridge Regression）</sub></p>
</li>
<li><p>L<sup>1</sup>参数正则化，添加一个正则项Ω(θ)=||w||<sub>1</sub>，即各个参数的绝对值之和，这个方法又被成为Lasso Regression。L<sup>1</sup>参数正则化往往可以产生更加稀疏的解法。</p>
</li>
</ul>
<p>在第 5.6.1 节，我们看到许多正则化策略可以被解释为 MAP 贝叶斯推断，特别<br>是 L2正则化相当于权重是高斯先验的 MAP 贝叶斯推断。对于 L1正则化，用于正则<br>化代价函数的惩罚项 αΩ(w) = α∑ |wi| 与通过 MAP 贝叶斯推断最大化的对数先 i<br>验项是等价的(w∈Rn 并且权重先验是各向同性的拉普拉斯分布(式(3.26)))</p>
<h2 id="作为约束的范数惩罚"><a href="#作为约束的范数惩罚" class="headerlink" title="作为约束的范数惩罚"></a>作为约束的范数惩罚</h2><h2 id="正则化和欠约束问题"><a href="#正则化和欠约束问题" class="headerlink" title="正则化和欠约束问题"></a>正则化和欠约束问题</h2><p>当输入的数据相对与输入特征的维数较少时，我们需要使用该种方法。</p>
<h2 id="数据集增强"><a href="#数据集增强" class="headerlink" title="数据集增强"></a>数据集增强</h2><p>让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。当然，在 实践中，我们拥有的数据量是很有限的。解决这个问题的一种方法是创建假数据并 添加到训练集中。对于一些机器学习任务，创建新的假数据相当简单。</p>
<p>比如，在<a href="https://www.kaggle.com/cesareli/introduction-to-cnn-keras-0-997-top-6" target="_blank" rel="noopener">CNN识别数字</a>的过程中，我们采用了一种方法，对于每一个样本，我们可以考虑将其少量的平移或者旋转，来增强整个系统的泛化性。</p>
<p>在神经网络的输入层注入噪声 (Sietsma and Dow, 1991) 也可以被看作是数据增 强的一种方式。对于许多分类甚至一些回归任务而言，即使小的随机噪声被加到输 入，任务仍应该是能够被解决的。然而，神经网络被证明对噪声不是非常健壮 (Tang and Eliasmith, 2010)。改善神经网络健壮性的方法之一是简单地将随机噪声添加到 输入再进行训练。输入噪声注入是一些无监督学习算法的一部分，如去噪自编码 器(Vincent et al., 2008a)。向隐藏单元施加噪声也是可行的，这可以被看作在多个抽 象层上进行的数据集增强。</p>
<h2 id="噪声鲁棒性"><a href="#噪声鲁棒性" class="headerlink" title="噪声鲁棒性"></a>噪声鲁棒性</h2><p>对于某些模型而言， 向输入添加方差极小的噪声等价于对权重施加范数惩罚 (Bishop, 1995a,b)。在一般情 况下，注入噪声远比简单地收缩参数强大，特别是噪声被添加到隐藏单元时会更加强 大。向隐藏单元添加噪声是值得单独讨论重要的话题;在第 7.12 节所述 Dropout 算 法是这种做法的主要发展方向。</p>
<h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><p>在深度学习的背景下，半监督学习通常指的是学习一个表示 h = f(x)。学习表 示的目的是使相同类中的样本有类似的表示。无监督学习可以为如何在表示空间聚 集样本提供有用线索。在输入空间紧密聚集的样本应该被映射到类似的表示。在许 多情况下，新空间上的线性分类器可以达到较好的泛化 (Belkin and Niyogi, 2002; Chapelle et al., 2003)。这种方法的一个经典变种是使用主成分分析作为分类前(在 投影后的数据上分类)的预处理步骤。</p>
<h2 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h2><p>多任务学习 (Caruana, 1993) 是通过合并几个任务中的样例(可以视为对参数 施加的软约束)来提高泛化的一种方式。正如额外的训练样本能够将模型参数推向 具有更好泛化能力的值一样，当模型的一部分被多个额外的任务共享时，这部分将 被约束为良好的值(如果共享合理)，通常会带来更好的泛化能力。</p>
<p>这种方法将模型中的参数氛围两类</p>
<blockquote>
<ol>
<li><p>具体任务的参数-只能从各自任务的样本中实现比较好的泛化</p>
</li>
<li><p>所有任务共享的通用参数</p>
</li>
</ol>
</blockquote>
<h2 id="提前终止"><a href="#提前终止" class="headerlink" title="提前终止"></a>提前终止</h2><p>当训练有足够的表示能力甚至会过拟合的大模型时，我们经常观察到，训练误 差会随着时间的推移逐渐降低但验证集的误差会再次上升。图 7.3 是这些现象的一个 例子，这种现象几乎一定会出现。</p>
<p>这意味着我们只要返回使验证集误差最低的参数设置，就可以获得验证集误差 更低的模型(并且因此有希望获得更好的测试误差)。在每次验证集误差有所改善后，我们存储模型参数的副本。当训练算法终止时，我们返回这些参数而不是最新的参数。当验证集上的误差在事先指定的循环次数内没有进一步改善时，算法就会终止。</p>
<p>这种策略被称为 提前终止(early stopping)。这可能是深度学习中最常用的正 则化形式。它的流行主要是因为有效性和简单性。</p>
<p>然而这种方法也有两个缺点。</p>
<p>通过提前终止自动选择超参数的第一个显著的代价是 训练期间要定期评估验证集。在理想情况下，这可以并行在与主训练过程分离的机 器上，或独立的 CPU，或独立的 GPU 上完成。如果没有这些额外的资源，可以使用比训练集小的验证集或较不频繁地评估验证集来减小评估代价，较粗略地估算取得最佳的训练时间。</p>
<p>另一个提前终止的额外代价是需要保持最佳的参数副本。这种代价一般是可忽略的，因为可以将它储存在较慢较大的存储器上(例如，在 GPU 内存中训练，但将 最佳参数存储在主存储器或磁盘驱动器上)。由于最佳参数的写入很少发生而且从不在训练过程中读取，这些偶发的慢写入对总训练时间的影响不大。</p>
<p>提前终止需要验证集，这意味着某些训练数据不能被馈送到模型。为了更好地 利用这一额外的数据，我们可以在完成提前终止的首次训练之后，进行额外的训练。 在第二轮，即额外的训练步骤中，所有的训练数据都被包括在内。有两个基本的策略都可以用于第二轮训练过程（具体的策略请见深度学习书中的214页）。</p>
<h2 id="参数绑定和参数共享"><a href="#参数绑定和参数共享" class="headerlink" title="参数绑定和参数共享"></a>参数绑定和参数共享</h2><p>参数范数惩罚是正则化参数使其彼此接近的一种方式，而更流行的方法是使用 约束:强迫某些参数相等。由于我们将各种模型或模型组件解释为共享唯一的一组 参数，这种正则化方法通常被称为 参数共享(parameter sharing)。和正则化参数使 其接近(通过范数惩罚)相比，参数共享的一个显著优点是，只有参数(唯一一个集 合)的子集需要被存储在内存中。对于某些特定模型，如卷积神经网络，这可能可 以显著减少模型所占用的内存。</p>
<h2 id="系数表示"><a href="#系数表示" class="headerlink" title="系数表示"></a>系数表示</h2><p>前文所述的权重衰减直接惩罚模型参数。另一种策略是惩罚神经网络中的激活单元，稀疏化激活单元。这种策略间接地对模型参数施加了复杂惩罚。</p>
<img src="/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/2.png">
<h2 id="Bagging方法"><a href="#Bagging方法" class="headerlink" title="Bagging方法"></a>Bagging方法</h2><p>Bagging(bootstrap aggregating)是通过结合几个模型降低泛化误差的技术 (Breiman, 1994)。主要想法是分别训练几个不同的模型，然后让所有模型表决测 试样例的输出。这是机器学习中常规策略的一个例子，被称为<strong>模型平均(model averaging)</strong>。采用这种策略的技术被称为集成方法。</p>
<p>模型平均(model averaging)奏效的原因是不同的模型通常不会在测试集上产 生完全相同的误差。</p>
<img src="/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/3.png">
<p>在误差完全相关即 c = v 的情况下，均方误差减少到 v，所以模型平均没有任何帮 助。在错误完全不相关即 c = 0 的情况下，该集成平方误差的期望仅为1/k*v。这意味着集成平方误差的期望会随着集成规模增大而线性减小。换言之，平均上，集成至少与它的任何成员表现得一样好，并且如果成员的误差是独立的，集成将显著地比其成员表现得更好。</p>
<p>具体来说，Bagging涉及构造 k 个不同的数据集。每个数据集从原始数据集中重复采样构成，和原始数据集具有相同数量的样例。这意味着，每个数据集以高概率 缺少一些来自原始数据集的例子，还包含若干重复的例子(如果所得训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 2/3 的实例)。模型 i 在数据集 i 上训练。每个数据集所含样本的差异导致了训练模型之间的差异。</p>
<p>神经网络能找到足够多的不同的解，意味着他们可以从模型平均中受益 (即使所 有模型都在同一数据集上训练)。神经网络中随机初始化的差异、小批量的随机选择、 超参数的差异或不同输出的非确定性实现往往足以使得集成中的不同成员具有部分独立的误差。</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><h2 id="对抗训练"><a href="#对抗训练" class="headerlink" title="对抗训练"></a>对抗训练</h2>]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep Feedforward Network </tag>
            
            <tag> Regularization </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[AlphaZero]]></title>
      <url>/2018/04/09/AlphaZero/</url>
      <content type="html"><![CDATA[<p>This is a reading notes based on the thesis <a href="https://www.nature.com/articles/nature24270.pdf" target="_blank" rel="noopener">Mastering the game of Go without human knowledge</a> and <a href="https://arxiv.org/pdf/1712.01815.pdf" target="_blank" rel="noopener">Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</a></p>
<h1 id="Mastering-the-game-of-Go-without-human-knowledge"><a href="#Mastering-the-game-of-Go-without-human-knowledge" class="headerlink" title="Mastering the game of Go without human knowledge"></a>Mastering the game of Go without human knowledge</h1><h2 id="AlphaGo-Fan-AlphaGo-Lee"><a href="#AlphaGo-Fan-AlphaGo-Lee" class="headerlink" title="AlphaGo Fan/AlphaGo Lee"></a>AlphaGo Fan/AlphaGo Lee</h2><p>AlphaGo was the first program to achieve superhuman performance in Go. The published version12, which we refer to as AlphaG Fan, defeated the European champion Fan Hui in October 2015. </p>
<p>AlphaGo Fan used two deep neural networks: a <strong>policy network</strong> that outputs move probabilities and a <strong>value network</strong> that outputs a position evaluation.</p>
<p>The policy network was trained initially by supervised learning to accurately predict human expert moves, and was subsequently refined by policy-gradient reinforcement learning. </p>
<p>The value network was trained to predict the winner of games played by the policy network against itself. </p>
<p>Once trained, these networks were combined with a Monte Carlo tree search (MCTS) to provide a lookahead search, using the policy network to narrow down the search to high-probability moves, and using the value network (in conjunction with Monte Carlo rollouts using a fast rollout policy) to evaluate positions in the tree.</p>
<p>A subsequent version, which we refer to as AlphaGo Lee, used a similar approach, and defeated Lee Sedol, the winner of 18 international titles, in March 2016.</p>
<h2 id="AlphaGo-Zero"><a href="#AlphaGo-Zero" class="headerlink" title="AlphaGo Zero"></a>AlphaGo Zero</h2><p>AlphaGo Zero, differs from AlphaGo Fan and AlphaGo Lee in several important aspects</p>
<blockquote>
<ol>
<li><p>It is trained solely by self-play reinforcement learning, starting from random play, without any supervision or use of human data.</p>
</li>
<li><p>It uses only the black and white stones from the board as input features.</p>
</li>
<li><p>Third, it uses a single neural network, rather than separate policy and value networks. </p>
</li>
<li><p>Finally, it uses a simpler tree search that relies upon<br>this single neural network to evaluate positions and sample moves,<br>without performing any Monte Carlo rollouts</p>
</li>
</ol>
</blockquote>
<h2 id="Reinforcement-learning-in-AlphaGo-Zero"><a href="#Reinforcement-learning-in-AlphaGo-Zero" class="headerlink" title="Reinforcement learning in AlphaGo Zero"></a>Reinforcement learning in AlphaGo Zero</h2><h3 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h3><p>f<sub>θ</sub>(s)=(p,v)</p>
<p>f<sub>θ</sub>: neural network with parameter θ</p>
<p>s: raw board representation, representing current game state</p>
<p>p: vector of move probabilities, represents the probability of selecting <strong>each move/action a</strong>, p<sub>a</sub>=Pr(a|s)</p>
<p>v: scalar evaluation, estimating the probability of current player winning from state s</p>
<blockquote>
<p>Combine the policy network and value network</p>
</blockquote>
<ul>
<li><p>Training:<br>  The neural network in AlphaGo Zero is trained from games of selfplay by a novel reinforcement learning algorithm. </p>
<p>  In each position s, an MCTS search is executed, guided by the neural network f<sub>θ</sub>. The MCTS search <strong>outputs probabilities π of playing each move</strong>.</p>
<blockquote>
<p>Here π is a vector! Stores the Probability for each action a.</p>
</blockquote>
<p>  These search probabilities usually select much stronger moves than the raw move probabilities p of the neural network fθ(s).</p>
<p>  MCTS may therefore be viewed as a powerful <strong>policy improvement operator</strong>. Self-play with search—using the improved MCTS-based policy to select each move, then using the <strong>game winner z</strong> as a sample of the value—may be viewed as a powerful <strong>policy evaluation operator</strong>. </p>
<p>  The main idea of our reinforcement learning algorithm is to use these search operators repeatedly in a policy iteration procedure: the neural network’s parameters are updated to make the move probabilities and value (p,v)= f<sub>θ</sub>(s) more closely match the improved search probabilities and selfplay winner (π, z); these new parameters are used in the next iteration of self-play to make the search even stronger.</p>
<blockquote>
<p>对于每一手（每一个当前状态），进行蒙特卡洛树搜索α<sub>θ</sub>，根节点为当前状态，蒙特卡洛树搜索是一种经验方法，可以根据之前的经验进行选择，我们在每个node s向下蔓延的edge a中选择，每个edge包含【prior probability P(s,a)/visit cound N(s,a)/ action value Q(s,a)】,<strong>在每一个node选择一个最大的（Q+U），当前选择的最大的Q+U不存在一个对应的node时，可以通过神经网络f<sub>θ</sub>生成他的子树（而不是使用Monte Carlo Rollout），产生对应的p和v，然后向root进行back propagate更新树的值（Q等）</strong>，并不断重复以上加粗字体过程，当搜索结束后，可以发挥一个search probabilities π，</p>
</blockquote>
<p>  At each time-step t, an MCTS search π = α<sub>θ of last step</sub>(s<sub>t</sub>) is executed using the previous iteration of neural network, and a move is played by sampling the search probabilities πt.</p>
<p>  A game terminates at step T when both players pass, when the search value drops below a resignation threshold or when the game exceeds a maximum length; the game is then scored to give a final reward of r<sub>T</sub>∈ {−1,+1}. </p>
<p>  The data for each time-step t is stored as (s<sub>t</sub>, π<sub>t</sub>, z<sub>t</sub>), where z<sub>t</sub>= ±r<sub>T</sub> is the game winner from the perspective of the current player at step t. </p>
<p>  In parallel, new network parameters θ<sub>i</sub> are trained from data (s, π, z) sampled uniformly among all time-steps of the last iteration(s) of self-play. The neural network f<sub>θ</sub> is adjusted to <strong>minimize the error between the predicted value v and the self-play winner z</strong>, and to <strong>maximize the similarity of the neural network move probabilities p to the search probabilities π</strong>.</p>
<blockquote>
<p>f<sub>θ</sub>(s)=(p,v)</p>
<p>loss function l = (z-v)<sup>2</sup> - π<sup>T</sup>logp + c||θ||<sup>2</sup></p>
</blockquote>
</li>
</ul>
<h2 id="Empirical-Analysis-of-AlphaGo-Zero-Training"><a href="#Empirical-Analysis-of-AlphaGo-Zero-Training" class="headerlink" title="Empirical Analysis of AlphaGo Zero Training"></a>Empirical Analysis of AlphaGo Zero Training</h2><p>Surprisingly, AlphaGo Zero outperformed AlphaGo Lee after just 36h. In comparison, AlphaGo Lee was trained over several months. </p>
<h2 id="Knowledge-learned-by-AlphaGo-Zero"><a href="#Knowledge-learned-by-AlphaGo-Zero" class="headerlink" title="Knowledge learned by AlphaGo Zero"></a>Knowledge learned by AlphaGo Zero</h2><p>AlphaGo Zero discovered a remarkable level of Go knowledge during its self-play training process. This included not only fundamental elements of human Go knowledge but also non-standard strategies beyond the scope of traditional Go knowledge.</p>
<h2 id="Final-performance-of-AlphaGo-Zero"><a href="#Final-performance-of-AlphaGo-Zero" class="headerlink" title="Final performance of AlphaGo Zero"></a>Final performance of AlphaGo Zero</h2><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><h1 id="Mastering-Chess-and-Shogi-by-Self-Play-with-a-General-Reinforcement-Learning-Algorithm"><a href="#Mastering-Chess-and-Shogi-by-Self-Play-with-a-General-Reinforcement-Learning-Algorithm" class="headerlink" title="Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"></a>Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The AlphaGo Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains, starting from random play, and given no domain knowledge except the game rules.</p>
<p>The AlphaGo Zero algorithm achieved superhuman performance in the game of Go, by representing Go knowledge using <strong>deep convolutional neural networks</strong>, trained solely by reinforcement learning from games of self-play.</p>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>Instead of a handcrafted evaluation function and move ordering heuristics, <strong>AlphaZero</strong> utilises a deep neural network (p, v) = f<sub>θ</sub>(s) with parameters θ. This neural network takes the board position s as an input and outputs a vector of move probabilities p with components p<sub>a</sub> = Pr(a|s) [the probability of each move a under the state s] for each action a, and a scalar value v estimating the expected outcome z from position s, v ≈ E[z|s]. AlphaZero learns these move probabilities and value estimates entirely from selfplay; these are then used to guide its search.</p>
<p>AlphaZero uses a generalpurpose Monte-Carlo tree search (MCTS) algorithm. Each search consists of a series of simulated games of self-play that traverse a tree from root s<sub>root</sub> to leaf. Each simulation proceeds by selecting in each state s a move a with low visit count, high move probability and high value<br>(<em>averaged over the leaf states of simulations that selected a from s</em>) according to the current neural network f<sub>θ</sub>. The search returns a vector π representing a probability distribution over moves, either proportionally or greedily with respect to the visit counts at the root state.</p>
<p>The parameters θ of the deep neural network in AlphaZero are trained by self-play reinforcement learning, starting from randomly initialised parameters θ. Games are played by selecting moves for both players by MCTS, a<sub>t</sub> ∼ π<sub>t</sub>. At the end of the game, the terminal position s<sub>T</sub> is scored according to the rules of the game to compute the game outcome z: −1 for a loss, 0 for a draw, and +1 for a win. The neural network parameters θ are updated so as to minimise the error between the predicted outcome v<sub>t</sub> and the game outcome z, and to maximise the similarity of the policy vector p<sub>t</sub><br>to the search probabilities π<sub>t</sub>. Specifically, the parameters θ are adjusted by gradient descent on a loss function l that sums over mean-squared error and cross-entropy losses respectively</p>
<blockquote>
<p>f<sub>θ</sub>(s)=(p,v)</p>
<p>loss function l = (z-v)<sup>2</sup> - π<sup>T</sup>logp + c||θ||<sup>2</sup></p>
</blockquote>
<p>where c is a parameter controlling the level of L2 weight regularisation. The updated parameters are used in subsequent games of self-play.</p>
<h2 id="Differences-between-AlphaZero-and-AlphaGo-Zero"><a href="#Differences-between-AlphaZero-and-AlphaGo-Zero" class="headerlink" title="Differences between AlphaZero and AlphaGo Zero"></a>Differences between AlphaZero and AlphaGo Zero</h2><ol>
<li><p>AlphaGo Zero estimates and optimises the probability of winning, assuming binary win/loss outcomes. AlphaZero instead estimates and optimises the expected outcome, taking account of draws or potentially other outcomes.</p>
</li>
<li><p>The rules of Go are invariant to rotation and reflection. This fact was exploited in AlphaGo and AlphaGo Zero in several ways.</p>
</li>
<li><p>In AlphaGo Zero, self-play games were generated by the best player from all previous iterations. After each iteration of training, the performance of the new player was measured against the best player; if it won by a margin of 55% then it replaced the best player and self-play games were subsequently generated by this new player. In contrast, AlphaZero simply maintains a single neural network that is updated continually, rather than waiting for an iteration to complete.</p>
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> AlphaGo </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Artificial Neural Network </tag>
            
            <tag> Machine Learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning II Calculation & Basic Methods]]></title>
      <url>/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/</url>
      <content type="html"><![CDATA[<h1 id="Advanced-Mathematics"><a href="#Advanced-Mathematics" class="headerlink" title="Advanced Mathematics"></a>Advanced Mathematics</h1><h2 id="上溢"><a href="#上溢" class="headerlink" title="上溢"></a>上溢</h2><h2 id="下溢"><a href="#下溢" class="headerlink" title="下溢"></a>下溢</h2><h2 id="病态条件"><a href="#病态条件" class="headerlink" title="病态条件"></a>病态条件</h2><h2 id="基于梯度优化"><a href="#基于梯度优化" class="headerlink" title="基于梯度优化"></a>基于梯度优化</h2><h3 id="目标函数-代价函数-损失函数-误差函数"><a href="#目标函数-代价函数-损失函数-误差函数" class="headerlink" title="目标函数/代价函数/损失函数/误差函数"></a>目标函数/代价函数/损失函数/误差函数</h3><h3 id="局部极小点-局部极大点-全局最小点"><a href="#局部极小点-局部极大点-全局最小点" class="headerlink" title="局部极小点/局部极大点/全局最小点"></a>局部极小点/局部极大点/全局最小点</h3><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><h3 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h3><h3 id="Jacobian-Matrix-amp-Hessian-Matrix"><a href="#Jacobian-Matrix-amp-Hessian-Matrix" class="headerlink" title="Jacobian Matrix &amp; Hessian Matrix"></a>Jacobian Matrix &amp; Hessian Matrix</h3><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/1.jpg">
<h3 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h3><p>最成功的特定优化领域或许是 凸优化(Convex optimization)。凸优化通过更强 的限制提供更多的保证。凸优化算法只对凸函数适用，即 Hessian 处处半正定的函 数。因为这些函数没有鞍点而且其所有局部极小点必然是全局最小点，所以表现很 好。然而，深度学习中的大多数问题都难以表示成凸优化的形式。凸优化仅用作一 些深度学习算法的子程序。</p>
<p>凸函数:f(tx+(1-t)y)&lt;=tf(x)+(1-t)f(y)      0&lt;=t&lt;=1</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/2.png">
<h2 id="约束优化"><a href="#约束优化" class="headerlink" title="约束优化"></a>约束优化</h2><p>有时候，在 x 的所有可能值下最大化或最小化一个函数 f(x) 不是我们所希望 的。相反，我们可能希望在 x 的某些集合 S 中找 f(x) 的最大值或最小值。这被称 为 约束优化(constrained optimization)。</p>
<p>（注意，这里的x是一个广义上的未知量而不是我们之前在线性回归模型等方法中使用的Dataset的input，这里的x表示为w或者theta都更加合适）</p>
<h3 id="KKT方法"><a href="#KKT方法" class="headerlink" title="KKT方法"></a>KKT方法</h3><h1 id="Basic-Machine-Learning-Methods"><a href="#Basic-Machine-Learning-Methods" class="headerlink" title="Basic Machine Learning Methods"></a>Basic Machine Learning Methods</h1><h2 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h2><h3 id="任务T"><a href="#任务T" class="headerlink" title="任务T"></a>任务T</h3><p>机器学习任务定义为机器学习系统应该如何处理 样本(example)。样本是 指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的 特征 (feature)的集合。</p>
<p>一些常见的机器学习任务列举：</p>
<blockquote>
<p>  分类/输入缺失分类/回归/转录/机器翻译/结构化输出/合成采样/缺失值填补/去噪/…</p>
</blockquote>
<h3 id="性能度量P"><a href="#性能度量P" class="headerlink" title="性能度量P"></a>性能度量P</h3><p>对于诸如分类、缺失输入分类和转录任务，我们通常度量模型的 准确率(accu- racy)。准确率是指该模型输出正确结果的样本比率。我们也可以通过 错误率(error rate)得到相同的信息。</p>
<p>通常，我们会更加关注机器学习算法在未观测数据上的性能如何，因为这将决 定其在实际应用中的性能。因此，我们使用 测试集(test set)数据来评估系统性能， 将其与训练机器学习系统的训练集数据分开。</p>
<h3 id="经验E"><a href="#经验E" class="headerlink" title="经验E"></a>经验E</h3><p>根据学习过程中的不同经验，机器学习算法可以大致分类为 无监督(unsuper- vised)算法和 监督(supervised)算法。</p>
<p>本书中的大部分学习算法可以被理解为在整个 数据集(dataset)上获取经验。 数据集是指很多样本组成的集合，如第 5.1.1 节所定义的。有时我们也将样本称为 数 据点(data point)。</p>
<p><strong>无监督学习算法(unsupervised learning algorithm)</strong>训练含有很多特征的数据 集，然后学习出这个数据集上有用的结构性质。在深度学习中，我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或去噪。 还有一些其他类型的无监督学习任务，例如聚类，将数据集分成相似样本的集合。</p>
<p><strong>监督学习算法(supervised learning algorithm)</strong>训练含有很多特征的数据集，不 过数据集中的样本都有一个 标签(label)或 目标(target)。</p>
<p>大致说来，无监督学习涉及到观察随机向量 x 的好几个样本，试图显式或隐式 地学习出概率分布 p(x)，或者是该分布一些有意思的性质;而监督学习包含观察随 机向量 x 及其相关联的值或向量 y，然后从 x 预测 y，通常是估计 p(y | x)。术语 监 督学习(supervised learning)源自这样一个视角，教员或者老师提供目标 y 给机器学习系统，指导其应该做什么。在无监督学习中，没有教员或者老师，算法必须学会在没有指导的情况下理解数据。</p>
<h3 id="数据表示"><a href="#数据表示" class="headerlink" title="数据表示"></a>数据表示</h3><p>大部分机器学习算法简单地训练于一个数据集上。数据集可以用很多不同方式 来表示。在所有的情况下，数据集都是样本的集合，而样本是特征的集合。</p>
<p>表示数据集的常用方法是 设计矩阵(design matrix)。设计矩阵的每一行包含 一个不同的样本。每一列对应不同的特征。</p>
<h2 id="容量"><a href="#容量" class="headerlink" title="容量"></a>容量</h2><p>机器学习的主要挑战是我们的算法必须能够在先前未观测的新输入上表现良好， 而不只是在训练集上表现良好。在先前未观测到的输入上表现良好的能力被称为 泛 化(generalization)。</p>
<p>通常情况下，当我们训练机器学习模型时，我们可以使用某个训练集，在训练 集上计算一些被称为 训练误差(training error)的度量误差，目标是降低训练误差。 目前为止，我们讨论的是一个简单的优化问题。机器学习和优化不同的地方在于，我 们也希望 泛化误差 (generalization error)(也被称为 测试误差(test error))很低。 泛化误差被定义为新输入的误差期望。这里，期望的计算基于不同的可能输入，这 些输入采自于系统在现实中遇到的分布。</p>
<p>训练集和测试集数据通过数据集上被称为 数据生成过程(data generating pro- cess)的概率分布生成。通常，我们会做一系列被统称为 独立同分布假设(i.i.d. assumption)的假设。该假设是说，每个数据集中的样本都是彼此 相互独立的(independent)，并且训练集和测试集是 同分布的(identically distributed)，采样自相 同的分布。这个假设使我们能够在单个样本的概率分布描述数据生成过程。然后相 同的分布可以用来生成每一个训练样本和每一个测试样本。我们将这个共享的潜在 分布称为 数据生成分布(data generating distribution)，记作 p<sub>data</sub>。这个概率框架 和独立同分布假设允许我们从数学上研究训练误差和测试误差之间的关系。</p>
<p>我们能观察到训练误差和测试误差之间的直接联系是，随机模型训练误差的期 望和该模型测试误差的期望是一样的。假设我们有概率分布 p(x, y)，从中重复采样 生成训练集和测试集。对于某个固定的 w，训练集误差的期望恰好和测试集误差的 期望一样，这是因为这两个期望的计算都使用了相同的数据集生成过程。这两种情 况的唯一区别是数据集的名字不同。</p>
<p>因此我们有两个因素来决定一个学习算法的好坏</p>
<blockquote>
<p>  降低训练误差-欠拟合（underfitting）</p>
<p>  缩小训练误差和测试误差的差距-过拟合（overfitting）</p>
</blockquote>
<p>通过调整模型的 容量(capacity)，我们可以控制模型是否偏向于过拟合或者欠 拟合。通俗地，模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟 合训练集。容量高的模型可能会过拟合，因为记住了不适用于测试集的训练集性质。</p>
<p>一种控制训练算法容量的方法是选择 假设空间(hypothesis space)，即学习算 法可以选择为解决方案的函数集。例如，线性回归算法将关于其输入的所有线性函 数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。这 样做就增加了模型的容量。</p>
<p>统计学习理论中最重要 的结论阐述了训练误差和泛化误差之间差异的上界随着模型容量增长而增长，但 随着训练样本增多而下降。</p>
<p>我们必须记住虽然更简单的函数更可能泛化(训练误差和测试误差的差距小)， 但我们仍然需要选择一个充分复杂的假设以达到低的训练误差。通常，当模型容量 上升时，训练误差会下降，直到其渐近最小可能误差(假设误差度量有最小值)。通 常，泛化误差是一个关于模型容量的 U 形曲线函数。</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/3.png">
<h3 id="Bayes-Error"><a href="#Bayes-Error" class="headerlink" title="Bayes Error"></a>Bayes Error</h3><p>理想模型假设我们能够预先知道生成数据的真实概率分布。然而这样的模型仍 然会在很多问题上发生一些错误，因为分布中仍然会有一些噪声。在监督学习中，从 x 到 y 的映射可能内在是随机的，或者 y 可能是其他变量(包括 x 在内)的确定性函数。从预先知道的真实分布 p(x, y) 预测而出现的误差被称为 贝叶斯误差(Bayes error)。</p>
<h3 id="No-Free-Lunch-Principle"><a href="#No-Free-Lunch-Principle" class="headerlink" title="No Free Lunch Principle"></a>No Free Lunch Principle</h3><h2 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h2><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/4.jpg">
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>至此，我们具体讨论修改学习算法的方法只有，通过增加或减少学习算法可选 假设空间的函数来增加或减少模型的表示容量。我们列举的一个具体示例是线性回 归增加或减少多项式的次数。目前为止讨论的观点都是过度简化的。</p>
<h3 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h3><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/5.png">
<p>在我们权重衰减的示例中，通过在最小化的目标中额外增加一项，我们明确地 表示了偏好权重较小的线性函数。有很多其他方法隐式或显式地表示对不同解的偏 好。总而言之，这些不同的方法都被称为 正则化(regularization)。<strong>正则化是指我们修改学习算法，使其降低泛化误差而非训练误差</strong>。正则化是机器学习领域的中心问 题之一，只有优化能够与其重要性相媲。</p>
<h2 id="超参数和验证集"><a href="#超参数和验证集" class="headerlink" title="超参数和验证集"></a>超参数和验证集</h2><p>大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值不是 通过学习算法本身学习出来的，比如控制权重衰减成都的lamda以及控制容量的多项式最高次数。</p>
<p>有时一个选项被设为学习算法不用学习的超参数，是因为它太难优化了。更多 的情况是，该选项必须是超参数，因为它不适合在训练集上学习。这适用于控制模 型容量的所有超参数。如果在训练集上学习超参数，这些超参数总是趋向于最大可 能的模型容量，导致过拟合(参考图 5.3 )。例如，相比低次多项式和正的权重衰减 设定，更高次的多项式和权重衰减参数设定 λ = 0 总能在训练集上更好地拟合。</p>
<p>为了解决这个问题，我们需要一个训练算法观测不到的 验证集(validation set) 样本。它可以用来估计学 习过程完成之后的学习器的泛化误差。其重点在于测试样本不能以任何形式参与到 模型的选择中，包括设定超参数。基于这个原因，测试集中的样本不能用于验证集。 因此，我们总是从训练数据中构建验证集。特别地，我们将训练数据分成两个不相 交的子集。其中一个用于学习参数。另一个作为验证集，用于估计训练中或训练后 的泛化误差，更新超参数。</p>
<h3 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h3><h2 id="Bias-amp-Variance"><a href="#Bias-amp-Variance" class="headerlink" title="Bias &amp; Variance"></a>Bias &amp; Variance</h2><p>偏差和方差度量着估计量的两个不同误差来源。偏差度量着偏离真实函数或参数的误差期望。而方差度量着数据上任意特定采样可能导致的估计期望的偏差。</p>
<p>当我们可以在一个偏差更大的估计和一个方差更大的估计中进行选择时，会发 生什么呢?我们该如何选择?</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/6.png">
<p>偏差和方差的关系和机器学习容量、欠拟合和过拟合的概念紧密相联。用 MSE 度 量泛化误差(偏差和方差对于泛化误差都是有意义的)时，增加容量会增加方差，降低偏差。如图所示，我们再次在关于容量的函数中，看到泛化误差的 U 形曲线。</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/7.png">
<h2 id="Maximum-Likelihood"><a href="#Maximum-Likelihood" class="headerlink" title="Maximum Likelihood"></a>Maximum Likelihood</h2><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/8.png">
<p>一种解释最大似然估计的观点是将它看作最小化训练集上的经验分布 pˆ<sub>data</sub> 和模型分布之间的差异.</p>
<h2 id="Bayes-Method"><a href="#Bayes-Method" class="headerlink" title="Bayes Method"></a>Bayes Method</h2><p>当训练数据很有限时，贝叶斯方法通常泛化得更好，但是当训练样本数目很大 时，通常会有很大的计算代价。</p>
<h2 id="最大后验估计-MAP"><a href="#最大后验估计-MAP" class="headerlink" title="最大后验估计 MAP"></a>最大后验估计 MAP</h2><h2 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h2><h3 id="Linear-Regression-1"><a href="#Linear-Regression-1" class="headerlink" title="Linear Regression"></a>Linear Regression</h3><h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><h3 id="Support-Vector-Machine-不输出概率-只输出类别"><a href="#Support-Vector-Machine-不输出概率-只输出类别" class="headerlink" title="Support Vector Machine:不输出概率 只输出类别"></a>Support Vector Machine:不输出概率 只输出类别</h3><blockquote>
<p>Kernal Method</p>
</blockquote>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><h2 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h2><p>一个经典的无监督学习任务是找到数据的 ‘‘最佳’’ 表示。‘‘最佳’’ 可以是不同的 表示，但是一般来说，是指该表示在比本身表示的信息更简单或更易访问而受到一 些惩罚或限制的情况下，尽可能地保存关于 x 更多的信息。</p>
<p>有很多方式定义较简单的表示。最常见的三种包括低维表示、稀疏表示和独立 表示。低维表示尝试将 x 中的信息尽可能压缩在一个较小的表示中。稀疏表示将数 据集嵌入到输入项大多数为零的表示中 (Barlow, 1989; Olshausen and Field, 1996; Hinton and Ghahramani, 1997)。稀疏表示通常用于需要增加表示维数的情况，使得 大部分为零的表示不会丢失很多信息。这会使得表示的整体结构倾向于将数据分布 在表示空间的坐标轴上。独立表示试图分开数据分布中变化的来源，使得表示的维 度是统计独立的。</p>
<h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p> PCA 学习一种比原始输入维数更低的表示。</p>
 <img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/9.png">
<h3 id="K均值聚类：-K-Clustering"><a href="#K均值聚类：-K-Clustering" class="headerlink" title="K均值聚类： K Clustering"></a>K均值聚类： K Clustering</h3><h2 id="随机梯度下降-Stochastic-Gradient-Descent-SGD"><a href="#随机梯度下降-Stochastic-Gradient-Descent-SGD" class="headerlink" title="随机梯度下降 Stochastic Gradient Descent, SGD"></a>随机梯度下降 Stochastic Gradient Descent, SGD</h2><p>机器学习中反复出现的一个问题是好的泛化需要大的训练集，但大的训练集的 计算代价也更大。</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/10.png">
<h2 id="Build-a-Machine-Learning-Algorithm"><a href="#Build-a-Machine-Learning-Algorithm" class="headerlink" title="Build a Machine Learning Algorithm"></a>Build a Machine Learning Algorithm</h2><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/11.png">
<h2 id="Dimension-Disaster"><a href="#Dimension-Disaster" class="headerlink" title="Dimension Disaster"></a>Dimension Disaster</h2>]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Advanced Mathematics </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning I Introduction, Probability, Algebra & Symbols]]></title>
      <url>/2018/04/07/Deep-Learning-I-Introduction-Symbols/</url>
      <content type="html"><![CDATA[<h1 id="Mathematical-Symbols"><a href="#Mathematical-Symbols" class="headerlink" title="Mathematical Symbols"></a>Mathematical Symbols</h1><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/1.png">
<p>许多人工智能任务都可以通过以下方式解决:先提取一个合适的特征集，然后将这些特征提供给简单的机器学习算法。例如，对于通过声音鉴别说话者的任务来 说，一个有用的特征是对其声道大小的估计。这个特征为判断说话者是男性、女性还是儿童提供了有力线索</p>
<p>然而，对于许多任务来说，我们很难知道应该提取哪些特征。例如，假设我们想 写一个程序来检测照片中的车。我们知道，汽车有轮子，所以我们可能会想用车轮的存在与否作为特征。</p>
<p>解决这个问题的途径之一是使用机器学习来发掘表示本身，而不仅仅把表示映射到输出。这种方法我们称之为表示学习(representation learning)。学习到的表示往往比手动设计的表示表现得更好。并且它们只需最少的人工干预，就能让AI系统迅速适应新的任务。</p>
<p>从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难，因此，乍一看，表示学习似乎并不能帮助我们。</p>
<p>深度学习(deep learning)通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。深度学习让计算机通过较简单概念构建复杂的概念。</p>
<p>深度学习的另一个最大的成就是其在 强化学习(reinforcement learning)领域 的扩展。在强化学习中，一个自主的智能体必须在没有人类操作者指导的情况下，通 过试错来学习执行任务。DeepMind 表明，基于深度学习的强化学习系统能够学会玩 Atari 视频游戏，并在多种任务中可与人类匹敌 (Mnih et al., 2015)。深度学习也显 著改善了机器人强化学习的性能 (Finn et al., 2015)。</p>
<h1 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h1><h2 id="标量Scalar：一个数"><a href="#标量Scalar：一个数" class="headerlink" title="标量Scalar：一个数"></a>标量Scalar：一个数</h2><h2 id="向量Vector：一列数"><a href="#向量Vector：一列数" class="headerlink" title="向量Vector：一列数"></a>向量Vector：一列数</h2><h2 id="矩阵Matrix：二维数组"><a href="#矩阵Matrix：二维数组" class="headerlink" title="矩阵Matrix：二维数组"></a>矩阵Matrix：二维数组</h2><p>A<sub>m,n</sub>表示一个高度m宽度n的数组，A<sub>i,:</sub> 和A<sub>:,j</sub>分别表示row i和column j。</p>
<h2 id="张量Tensor：超过两维的数组，如Ax-y-z"><a href="#张量Tensor：超过两维的数组，如Ax-y-z" class="headerlink" title="张量Tensor：超过两维的数组，如Ax,y,z"></a>张量Tensor：超过两维的数组，如A<sub>x,y,z</sub></h2><h2 id="转置Transpose-xT"><a href="#转置Transpose-xT" class="headerlink" title="转置Transpose: xT"></a>转置Transpose: x<sup>T</sup></h2><p>对于一个任意形状的矩阵都是可转置的。</p>
<h2 id="矩阵和向量相乘："><a href="#矩阵和向量相乘：" class="headerlink" title="矩阵和向量相乘："></a>矩阵和向量相乘：</h2><p>C=AB,A的#column等于B的#row。</p>
<h2 id="单位矩阵：In-n-n"><a href="#单位矩阵：In-n-n" class="headerlink" title="单位矩阵：In(n*n)"></a>单位矩阵：I<sub>n</sub>(n*n)</h2><p>任意向量和单位矩阵相乘都不会改变。</p>
<h2 id="逆矩阵：A-1"><a href="#逆矩阵：A-1" class="headerlink" title="逆矩阵：A-1"></a>逆矩阵：A<sup>-1</sup></h2><p>A<sup>-1</sup>A=I<sub>n</sub></p>
<h2 id="可逆矩阵"><a href="#可逆矩阵" class="headerlink" title="可逆矩阵"></a>可逆矩阵</h2><p>一个可逆矩阵必须是一个方阵，即m=n，且所有的列向量都是线性无关的。一个列向量线性相关的矩阵为<strong>奇异矩阵（singular）</strong>。</p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/2.png">
<p>用于衡量一个向量的大小，p belongs to R and p &gt;=1。</p>
<p>p=2:欧几里得范数</p>
<p>p=1:Lasso Regularzation</p>
<h2 id="对角矩阵：diagonal-matrix"><a href="#对角矩阵：diagonal-matrix" class="headerlink" title="对角矩阵：diagonal matrix"></a>对角矩阵：diagonal matrix</h2><h2 id="对称矩阵：AT-A"><a href="#对称矩阵：AT-A" class="headerlink" title="对称矩阵：AT=A"></a>对称矩阵：A<sup>T</sup>=A</h2><h2 id="单位向量-x-2-1"><a href="#单位向量-x-2-1" class="headerlink" title="单位向量: ||x||2=1"></a>单位向量: ||x||<sub>2</sub>=1</h2><h2 id="正交矩阵：orthogonal-matrix-AT-A-1"><a href="#正交矩阵：orthogonal-matrix-AT-A-1" class="headerlink" title="正交矩阵：orthogonal matrix AT=A-1"></a>正交矩阵：orthogonal matrix A<sup>T</sup>=A<sup>-1</sup></h2><h2 id="特征分解"><a href="#特征分解" class="headerlink" title="特征分解"></a>特征分解</h2><p>特征向量，指与矩阵 A 相乘后相当于对该向量进行缩放的非零向量 v</p>
<p>Av=lv</p>
<p>（l为特征值）</p>
<p>所有特征值都是正数的矩阵被称为 正定(positive definite);所有特征值都是非 负数的矩阵被称为 半正定(positive semidefinite)。同样地，所有特征值都是负数的 矩阵被称为 负定(negative definite);所有特征值都是非正数的矩阵被称为 半负定(negative semidefinite)。</p>
<h2 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h2><p>A=UDV<sup>T</sup></p>
<h2 id="Moore-Penrose伪逆A"><a href="#Moore-Penrose伪逆A" class="headerlink" title="Moore-Penrose伪逆A+"></a>Moore-Penrose伪逆A<sup>+</sup></h2><p>对于非方阵而言，其逆矩阵没有定义。</p>
<p>A<sup>+</sup>=VD<sup>+</sup>U<sup>T</sup></p>
<h2 id="迹Tr-A-Sum-Ai-i"><a href="#迹Tr-A-Sum-Ai-i" class="headerlink" title="迹Tr(A)=Sum Ai,i"></a>迹Tr(A)=Sum A<sub>i,i</sub></h2><h2 id="行列式：det-A"><a href="#行列式：det-A" class="headerlink" title="行列式：det(A)"></a>行列式：det(A)</h2><p>将方阵A映射到实数的函数</p>
<h1 id="Probability"><a href="#Probability" class="headerlink" title="Probability"></a>Probability</h1><h2 id="随机变量-Random-Variable"><a href="#随机变量-Random-Variable" class="headerlink" title="随机变量 Random Variable"></a>随机变量 Random Variable</h2><h2 id="概率分布-Probability-Distribution"><a href="#概率分布-Probability-Distribution" class="headerlink" title="概率分布 Probability Distribution"></a>概率分布 Probability Distribution</h2><h3 id="联合概率分布-P-X-x-Y-y"><a href="#联合概率分布-P-X-x-Y-y" class="headerlink" title="联合概率分布 P(X=x,Y=y)"></a>联合概率分布 P(X=x,Y=y)</h3><h3 id="概率密度函数-Probability-Density-Function-pdf"><a href="#概率密度函数-Probability-Density-Function-pdf" class="headerlink" title="概率密度函数 Probability Density Function/pdf"></a>概率密度函数 Probability Density Function/pdf</h3><h2 id="边缘概率分布"><a href="#边缘概率分布" class="headerlink" title="边缘概率分布"></a>边缘概率分布</h2><h2 id="条件概率-P-Y-y-X-x-P-Y-y-X-x-P-X-x"><a href="#条件概率-P-Y-y-X-x-P-Y-y-X-x-P-X-x" class="headerlink" title="条件概率: P(Y=y|X=x)=P(Y=y,X=x)/P(X=x)"></a>条件概率: P(Y=y|X=x)=P(Y=y,X=x)/P(X=x)</h2><h2 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/3.png">
<h2 id="独立性-条件独立性"><a href="#独立性-条件独立性" class="headerlink" title="独立性/条件独立性"></a>独立性/条件独立性</h2><h2 id="期望Expectation"><a href="#期望Expectation" class="headerlink" title="期望Expectation"></a>期望Expectation</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/4.png">
<img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/5.png">
<h2 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/6.png">
<h2 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/7.png">
<h2 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><h2 id="logistic-sigmoid函数"><a href="#logistic-sigmoid函数" class="headerlink" title="logistic sigmoid函数"></a>logistic sigmoid函数</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/8.png">
<h2 id="softplus函数"><a href="#softplus函数" class="headerlink" title="softplus函数"></a>softplus函数</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/9.png">
<h2 id="Bayes-Rules"><a href="#Bayes-Rules" class="headerlink" title="Bayes Rules"></a>Bayes Rules</h2><p>P(x|y)=P(x)P(y|x)/P(y)</p>
<h2 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h2><h2 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/10.png">
]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Probability </tag>
            
            <tag> Algebra </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Machine Learning Algorithm]]></title>
      <url>/2018/03/29/Machine-Learning-Algorithm/</url>
      <content type="html"><![CDATA[<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><p><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" target="_blank" rel="noopener">WIKIPEDIA</a></p>
<p><a href="https://coolshell.cn/articles/8052.html" target="_blank" rel="noopener">COOLSHELL</a></p>
<h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><p>The basic idea of KNN is to classify a certain sample into a categrory based on K nearest neighbors. </p>
<p>Different K could have a different influence on the result</p>
<p>To find the K nearest sample points, Max Heap could be a suitable solution</p>
<h2 id="Heap-and-Tree"><a href="#Heap-and-Tree" class="headerlink" title="Heap and Tree"></a>Heap and Tree</h2><p>Here since we involve the idea of Heap, I think it’s necessary to record some ideas about the Heap and Tree.</p>
<p>Heap is a special tree. As is know to us all, <strong>TREE</strong> is a data structure based on a <strong>value</strong>, that the left son is always smaller than its father while the right son is always greater than its father.</p>
<p>While <strong>HEAP</strong> is built based on a <strong>weight</strong>, that the father nodes’ weight is always greater or smaller than its sons.</p>
<p><strong>TREAP</strong> has both <strong>value</strong> and <strong>weight</strong>.</p>
<p>In KNN, it is possible to build min-max heap. The max heap is a heap that the node with the greatest weight as a root. So when we try to find the neighbors of a new k value, it has great performance.</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><p><a href="https://www.zhihu.com/question/21094489" target="_blank" rel="noopener">ZHIHU</a></p>
<p><a href="https://www.youtube.com/watch?v=3liCbRZPrZA" target="_blank" rel="noopener">YOUTUBE</a></p>
<p><a href="https://www.zhihu.com/question/24627666" target="_blank" rel="noopener">KERNEL METHOD</a></p>
<h1 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h1><p><a href="https://blog.csdn.net/xbinworld/article/details/44660339" target="_blank" rel="noopener">CSDN</a></p>
<p><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" target="_blank" rel="noopener">CNBLOG</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/26703300" target="_blank" rel="noopener">ZHIHU</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/26760551" target="_blank" rel="noopener">ZHIHU</a></p>
]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> KNN </tag>
            
            <tag> SVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[NP Complete Problems]]></title>
      <url>/2018/03/24/NP-Complete-Problems/</url>
      <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>迄今为止，几乎大部分算法都是多项式时间算法，也就是对于规模为n的输入，在最坏情况下的运行时间为O（n^k），其中k为某个常数，然而并不是所有的问题都能在多项式时间内解决，如著名的“停机问题”。</p>
<p>“NP完全”（NP-complete）问题的状态是未知的，既没有人找到这类问题的多项式时间算法，也没有人证明这类问题的多项式时间算法不存在。</p>
<blockquote>
<p>一个NPC不一定是无法解决的，但是他的算法可能复杂度是O（2^n）等等，总之是无法在多项式时间内解决。</p>
</blockquote>
<p>在本文档中介绍三类问题</p>
<ul>
<li><p>P：在多项式时间内可以解决的问题</p>
</li>
<li><p>NP：在多项式时间内可以验证的问题，在问题输入的规模的多项式时间内，可以验证某一个结果是否是正确的（不难看出，P⊆NP）</p>
</li>
<li><p>NPC：如果一个问题属于NP，并且与NP中的任何一个问题是一样难的，那么这个问题属于NPC，也就是说他是NP完全的</p>
</li>
</ul>
<blockquote>
<p>如果任何NPC问题可以在多项式时间内解决，那么每一个NPC问题都有一个多项式时间算法</p>
</blockquote>
<p>在证明一个问题是NPC问题的时候，我们需要的证明方式往往是去陈述它是一个多么困难的问题，而不是去证明存在某个算法与否。</p>
<h1 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h1><h2 id="判定问题与最优化问题"><a href="#判定问题与最优化问题" class="headerlink" title="判定问题与最优化问题"></a>判定问题与最优化问题</h2><p>NPC并不适用于最优化问题，但适用于判定问题，尽管证明一个问题是NPC问题会将我们的目光局限于判定问题，但是在最优化问题和判定问题之间有很方便的联系。</p>
<p>当我们在证明某一个最优化问题是一个困难的问题的时候，我们可以利用这个问题所对应的判定问题，<strong>因为从某种意义上来讲，判定问题会容易一些，或者至少不会更难。</strong></p>
<p>因此，加入我们能够提供证据表明某个判定问题是个困难问题的话，我们也提供了证据表明其相关的最优化问题也是困难的。</p>
<h2 id="归约"><a href="#归约" class="headerlink" title="归约"></a>归约</h2><p>对于一个判定问题A，我们希望在多项式时间内解决该问题，称这个问题的输入为该问题的一个实例，假设我们有另一个不同的判定问题B，我们知道如何在多项式时间内解决它，并且假设有一个过程，可以将A的任何实例转化成B的实例，并且这个转化的过程具有如下的性质：</p>
<ul>
<li><p>转换操作需要多项式时间</p>
</li>
<li><p>两个实例的答案是相同的</p>
</li>
</ul>
<p>那么我们称这个转化的过程为多项式时间的归约算法。因此可以将问题A的求解归约为B的求解（<strong>因为如果B的算法是多项式时间，转换过程为多项式时间，那么A也可以在多项式时间内解决</strong>）。</p>
<blockquote>
<p>第一个NPC问题，<strong>电路可满足性问题</strong>，已知一个布尔组合电路，由AND，OR和NOT组成，我们希望知道这个电路是否存在一组布尔输入，使得电路的输出为1，检查这个电路是否是可满足的，除了尝试去测试每一组输入输出之外，没有别的好办法，而这样的办法的复杂度为O（2^n）</p>
</blockquote>
<h1 id="多项式时间"><a href="#多项式时间" class="headerlink" title="多项式时间"></a>多项式时间</h1><p>我们形式化的定义一下多项式时间可解问题，这些问题通常都被看作是容易处理的。</p>
<h2 id="抽象问题"><a href="#抽象问题" class="headerlink" title="抽象问题"></a>抽象问题</h2><p>问了理解多项式时间可解问题，我们形式化定义“问题”这个概念：</p>
<ul>
<li>定义抽象问题Q为在问题实例集合I和问题解法集合S上的一个二元关系</li>
</ul>
<p>而为了简单起见，因为我们只讨论NPC问题中的判定问题，我们可以把抽象的判定问题看作是实例集I映射到解集{0，1}上的一个函数。如在一个最短路径问题中，我们的输入是一个实例i=<g,u,v,k>，那么如果从u到v最短路径长度为k，则PATH（i）=1，否则PATH（i）=0</g,u,v,k></p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>使用计算机解决问题，任何多边形，图，函数，有序对都可以编码成二进制串。</p>
<p>我们把实例集为二进制串的集合的问题成为<strong>具体问题</strong>，如果一个问题实例的长度为n=|i|，算法可以在O（T（n））内产生问题的解，那么我们说算法在这个时间内解决了该问题。</p>
<p>因此，如果给定一个抽象判定问题Q，其映射为实例集合I到{0,1}，通过某种编码e：I-&gt;{0,1}可以导出与问题相关的具体判定问题。</p>
<blockquote>
<p>通常情况下，编码的方式并不会影响问题的计算难度，然而在实践中并不是这样，我们需要假设采用标准编码的二进制串。</p>
</blockquote>
<h2 id="形式语言体系"><a href="#形式语言体系" class="headerlink" title="形式语言体系"></a>形式语言体系</h2><p>形式语言体系可以表述判定问题和求解算法之间的联系，如果给定输入x，算法输出A（x）=1，我们说算法A<strong>接受</strong>串x，如果A（x）=0，我们说算法A<strong>拒绝</strong>串x。<strong>被算法A接受的语言L={x belongs to {0,1}*: A(x)=1}</strong></p>
<p>如果对于L中每个x，要么被A接受要么被拒绝（不存在拒绝该x但是永远循环下去的情况，这种情况说A<strong>接受</strong>L），我们说L由A<strong>判定</strong>。</p>
<h1 id="多项式时间的验证"><a href="#多项式时间的验证" class="headerlink" title="多项式时间的验证"></a>多项式时间的验证</h1><h2 id="Hamilton-Cycle"><a href="#Hamilton-Cycle" class="headerlink" title="Hamilton Cycle"></a>Hamilton Cycle</h2><p>我们先使用形式语言来定义Hamilton Cycle问题</p>
<p>HAM-CYCLE={<g>:G is a Hamilton Cycle}</g></p>
<p>如何使用算法来判定Hamilton Cycle问题，已知一个问题实例<g>，一种办法就是列出G定点的全部排列，然后对于每一种排列进行检查，那么这个算法的运行时间为<strong>Omega（2^(n^1/2)）</strong></g></p>
<p>不难看出，如果有一个人说对于一个问题实例<g>,他说这个图是一个Hamilton Cycle并给出了一个回路排列来证明，我们很容易来验证这个答案是否是正确的。</g></p>
<h2 id="NP问题"><a href="#NP问题" class="headerlink" title="NP问题"></a>NP问题</h2><p>从上面的问题可以看出，HAM-CYCLE属于NP，因为他能在多项式时间内被验证。</p>
<h1 id="NP完全性与可归约性"><a href="#NP完全性与可归约性" class="headerlink" title="NP完全性与可归约性"></a>NP完全性与可归约性</h1><blockquote>
<p>HAM-CYCLE就是一个NPC问题</p>
</blockquote>
<h2 id="可归约性"><a href="#可归约性" class="headerlink" title="可归约性"></a>可归约性</h2><p>一个问题Q可以被归约为另一个问题Q‘，如果Q的任何实例都可以被容易的（<strong>在多项式时间内</strong>）表述为Q’的实例，并且Q‘实例的解也是Q的实例的解，<strong>因此，如果一个问题Q可以归约成Q’，则从某种意义上来说Q不比Q‘更难解决</strong></p>
<p>回归到形式语言体系中，也可也表述为L1可以在多项式时间内归约为语言L2，记作L1&lt;=pL2。</p>
<blockquote>
<p>如果L1&lt;=pL2，则L2属于P蕴含着L1属于P</p>
</blockquote>
<h2 id="NP完全性"><a href="#NP完全性" class="headerlink" title="NP完全性"></a>NP完全性</h2><p>通过以上对于可归约性的定义，我们可以定义NPC的集合</p>
<p>语言L属于NPC，如果：</p>
<ol>
<li><p>L属于NP</p>
</li>
<li><p>对于每个L‘属于NP，有L’&lt;=pL</p>
</li>
</ol>
<p>如果一种语言满足2，但不一定满足1，我们称这种语言是NP-Hard</p>
<blockquote>
<p>如果任何NP问题是多项式时间可以求解的，那么P=NP，等价的，如果NP中的任何问题不是多项式时间可以求解的，那么任何NP完全问题都不是多项式时间可以求解的。</p>
</blockquote>
<h1 id="NPC完全性的证明"><a href="#NPC完全性的证明" class="headerlink" title="NPC完全性的证明"></a>NPC完全性的证明</h1><h2 id="引理"><a href="#引理" class="headerlink" title="引理"></a>引理</h2><p>如果L是一种对于某个L‘属于NPC，有L’&lt;=pL的语言，则L是NP难度的，此外如果L属于NP，则L属于NPC。</p>
]]></content>
      
        
        <tags>
            
            <tag> NP Complete </tag>
            
            <tag> Algorithms Analysis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Computer Infrastructures Basic Parameters]]></title>
      <url>/2018/03/20/Computer-Infrastructures-Basic-Parameters/</url>
      <content type="html"><![CDATA[<h1 id="BASIC-PARAMETERS"><a href="#BASIC-PARAMETERS" class="headerlink" title="BASIC PARAMETERS"></a>BASIC PARAMETERS</h1><p><strong>T</strong> the length of time we observed the system</p>
<p><strong>A</strong> the number of request arrivals we observed</p>
<p><strong>C</strong> the number of request completions we observed</p>
<p><strong>Workload intensity/arrival rate Lamda</strong> the rate at which the customers arrive (eg 0.5 customers/second)  Lamda = A/T</p>
<p><strong>Throughput X</strong> the rate at which customers pass through the service center (0.5 customers/second) X = C/T</p>
<p><strong>N</strong> the average number of requests in the system (customer population) N = W/T</p>
<p><strong>Residence time R</strong> the average time spent at the service center by a customer, both queueing and receiving service R=W/C</p>
<p><strong>Queue length</strong> the average number of customers at the service center both waiting and receiving service (1.67 customers)</p>
<p><strong>B</strong> the length of time that the resource was obeserved to be busy</p>
<p><strong>Utilization U</strong> the proportion of time the server is busy (eg 0.625/62.5%)   U = B/T</p>
<p><strong>S</strong> the average service requirement of a customer (eg 1.25 seconds) S = B/C</p>
<p><strong>Z</strong> think time of a terminal user</p>
<p><strong>Dk</strong> Service demand at resource k Dk=VkSk</p>
<h1 id="BASIC-LAWS"><a href="#BASIC-LAWS" class="headerlink" title="BASIC LAWS"></a>BASIC LAWS</h1><p><strong>The Utilization Law</strong> U=X*S</p>
<p><strong>Little’s Law</strong> N=X*R</p>
<p><strong>The Response Time Law</strong> R=N/X-Z </p>
<p><strong>The Forced Flow Law</strong> Xi=Vi*X</p>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Computer Infrastructures </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part IV]]></title>
      <url>/2018/03/19/Cryptography-Part-IV/</url>
      <content type="html"><![CDATA[<h1 id="Mar-19-Block-Cipher-Cryptanalyses-Linear-Cryptanalysis"><a href="#Mar-19-Block-Cipher-Cryptanalyses-Linear-Cryptanalysis" class="headerlink" title="Mar 19 Block Cipher Cryptanalyses: Linear Cryptanalysis"></a>Mar 19 Block Cipher Cryptanalyses: Linear Cryptanalysis</h1><h1 id="Block-Cipher-Cryptanalysis"><a href="#Block-Cipher-Cryptanalysis" class="headerlink" title="Block Cipher Cryptanalysis"></a>Block Cipher Cryptanalysis</h1><p>Modern block cipher cryptanalysis aims at either recovering the key with an effort smaller than bruteforce</p>
<p>Block cipher cryptanalyses are usually split into two families: </p>
<ul>
<li><p>algebraic </p>
</li>
<li><p>statistical</p>
</li>
</ul>
<h1 id="Algebraic-Analysis"><a href="#Algebraic-Analysis" class="headerlink" title="Algebraic Analysis"></a>Algebraic Analysis</h1><h1 id="Statistical-Analysis"><a href="#Statistical-Analysis" class="headerlink" title="Statistical Analysis"></a>Statistical Analysis</h1><p>All the computationally secure ones produce a ctx where the probability that a bit is either one or zero is biased (= 1 ± ε) by the 2 ptx value</p>
<p><strong>Goal</strong>: find such relations between ptx and ctx, and exploit the statistical biases to extract a portion of the key</p>
<h1 id="The-“TRIVIAL”-Cipher"><a href="#The-“TRIVIAL”-Cipher" class="headerlink" title="The “TRIVIAL” Cipher"></a>The “TRIVIAL” Cipher</h1><h1 id="S-Boxes"><a href="#S-Boxes" class="headerlink" title="S-Boxes"></a>S-Boxes</h1><p>Without S-Boxes, the linear relations between ptx and ctx bits are always hold( i.e. with probability = 1)</p>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part III]]></title>
      <url>/2018/03/16/Cryptography-Part-III/</url>
      <content type="html"><![CDATA[<h1 id="Mar-12-SPN-amp-AES"><a href="#Mar-12-SPN-amp-AES" class="headerlink" title="Mar 12 SPN &amp; AES"></a>Mar 12 SPN &amp; AES</h1><h2 id="SPN"><a href="#SPN" class="headerlink" title="SPN"></a><a href="https://en.wikipedia.org/wiki/Substitution%E2%80%93permutation_network" target="_blank" rel="noopener">SPN</a></h2><p>SPN are built along <a href="https://en.wikipedia.org/wiki/Confusion_and_diffusion" target="_blank" rel="noopener">Shannon’s criteria of confusion and diffusion</a></p>
<ul>
<li><p>Confusion: obtained from the key mixing and substitution phase</p>
<blockquote>
<p>make the relationship between the key and cipher text as complicated as possible. Which means given cipher text it is hard to derive the key</p>
</blockquote>
</li>
<li><p>Diffusion: obtained through the permutation of linear diffusion phase</p>
<blockquote>
<p>dissipating the statistical structure of plaintext over the bulk of ciphertext. Which means the attacker could not break the system by statistic methods</p>
</blockquote>
</li>
</ul>
<h2 id="AES"><a href="#AES" class="headerlink" title="AES"></a><a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" target="_blank" rel="noopener">AES</a></h2><ul>
<li>128-bit block size (thought as a 4×4 byte matrix)</li>
<li><p>3 key sizes (128/192/256-bits)</p>
<blockquote>
<p>Round Structure: Given a 4*4 byte matrix as input</p>
<ol>
<li><p>A Substitution layer in the form of 16 S-boxes, 8-to-8 bit</p>
</li>
<li><p>A Permutation layer implemented via a bytewise rotation (ShiftRows) and a xor-linear operation among state bytes (MixColumn)</p>
</li>
<li><p>A key addition: bitwise ⊕, with 128 bits of expanded key material</p>
</li>
</ol>
</blockquote>
</li>
</ul>
<h2 id="Steam-Ciphers"><a href="#Steam-Ciphers" class="headerlink" title="Steam Ciphers"></a>Steam Ciphers</h2><p>In a Stream Cipher, we would like to </p>
<ol>
<li><p>use short keys k ∈ K to encrypt long messages </p>
</li>
<li><p>use algorithmically generated pseudo-random values for the keystream instead of truly random ones </p>
</li>
<li><p>be sure that the same keystream sequence is repeated only after a very long sequence of messages has been encrypted (. . . a practical value for infinity)</p>
</li>
</ol>
<blockquote>
<p>Synchronous Stream Ciphers</p>
<p>The keystream is generated as a function of the cipher key and of the memory elements, independently of any previous ptx or ctx digit, i.e. ki=f(k,s0,s1,…)</p>
<p>Asynchronous Stream Ciphers</p>
<p>The keystream is generated as a function of the cipher key and a finite number of previous ctxs. </p>
<p>Given a key k and an initial state S0 = ⟨sL−1, . . . , s0⟩ the keystream is composedas: ki =f(k,Si,Si−1,…)with Si =⟨ci+L−1,ci+L−2,…,ci+1,ci⟩</p>
</blockquote>
<h2 id="LFSR-Linear-Feedback-Shift-Registers"><a href="#LFSR-Linear-Feedback-Shift-Registers" class="headerlink" title="LFSR/Linear Feedback Shift Registers"></a>LFSR/Linear Feedback Shift Registers</h2><p><a href="https://www.youtube.com/watch?v=sKUhFpVxNWc" target="_blank" rel="noopener">https://www.youtube.com/watch?v=sKUhFpVxNWc</a></p>
<h1 id="Mar-15-Hybrid-Cryptosystems"><a href="#Mar-15-Hybrid-Cryptosystems" class="headerlink" title="Mar 15 Hybrid Cryptosystems"></a>Mar 15 Hybrid Cryptosystems</h1><h2 id="Hybrid-cryptosystems"><a href="#Hybrid-cryptosystems" class="headerlink" title="Hybrid cryptosystems"></a>Hybrid cryptosystems</h2><p>Encryption: Alice generates a random symmetric key k, encrypts the message with it, and encrypts k with kB<sub>pub</sub></p>
<p>Decryption: Bob decrypts k using kB<sub>pri</sub>, and uses it to decrypt the message, after which he may discards k.</p>
<p>Signature: Alice should sign something smaller than the whole message, although uniquely bound to it in some way</p>
<blockquote>
<p>Solving the efficient signature problem requires a new cryptographic primitive, the cryptographic hash</p>
</blockquote>
<h2 id="Cryptographic-Hash"><a href="#Cryptographic-Hash" class="headerlink" title="Cryptographic Hash"></a>Cryptographic Hash</h2><p>A hash is a deterministic function from arbitrary length message m, to fixed length output h = H(m) (Practically used to obtain a fixed-length “label” h for a digital object)</p>
<blockquote>
<p>The same value of h may be the hash of different messages (no such thing as bijective arbitrary size → fixed size compression)</p>
<p>Property</p>
<ol>
<li><p>Given h, hard to find m such that H(m)=h</p>
</li>
<li><p>Given m, hard to find m’ such that H(m)=H(m’)</p>
</li>
<li><p>Hard to find m’ and m’’ such that H(m’)=H(m’’)</p>
</li>
</ol>
</blockquote>
<h2 id="Public-Key-Authentication-证明公钥匙是谁的"><a href="#Public-Key-Authentication-证明公钥匙是谁的" class="headerlink" title="Public Key Authentication[证明公钥匙是谁的]"></a>Public Key Authentication[证明公钥匙是谁的]</h2><p>To prevent impersonation attack on publich key cryptosystems.(Pretend to be someone you are not and steal the information). Here rises the need of <strong>DIGITAL CERTIFICATE of authenticity of public keys</strong></p>
<h2 id="Digital-Certificate"><a href="#Digital-Certificate" class="headerlink" title="Digital Certificate"></a>Digital Certificate</h2><p>Our purpose is to authenticate the binding of a public key to the identity of someone/some company</p>
<p>举个例子方便大家理解，假设我们公司”ABC Company”花了1000块钱，向一个证书发布机构”SecureTrust CA”为我们自己的公司”ABC Company”申请了一张证书，注意，这个证书发布机构”SecureTrust CA”是一个大家公认并被一些权威机构接受的证书发布机构，我们的操作系统里面已经安装了”SecureTrust CA”的证书。”SecureTrust CA”在给我们发布证书时，把Issuer,Public key,Subject,Valid from,Valid to等信息以明文的形式写到证书里面，然后用一个指纹算法计算出这些数字证书内容的一个指纹，并把指纹和指纹算法用自己的私钥进行加密，然后和证书的内容一起发布，同时”SecureTrust CA”还会给一个我们公司”ABC Company”的私钥给到我们。我们花了1000块钱买的这个证书的内容如下：</p>
<p>×××××××××××××××证书内容开始×××××××××××××××××</p>
<p>Issuer : SecureTrust CA</p>
<p>Subject : ABC Company</p>
<p>Valid from ： 某个日期</p>
<p>Valid to： 某个日期</p>
<p>Public Key : 一串很长的数字</p>
<p>…… 其它的一些证书内容……</p>
<p>{证书的指纹和计算指纹所使用的指纹算法}[SecureTrust CA的私钥|RSA]</p>
<p>//这个部分验证了消息的完整性，确定这个消息没有被人中途修改过      </p>
<p>//这个就是”SecureTrust CA”对这个证书的一个数字签名，表示这个证书确实是他发布的，有什么问题他会负责(收了我们1000块，出了问题肯定要负责任的)</p>
<p>×××××××××××××××证书内容结束×××××××××××××××××</p>
<p>//{} 表示RSA加密后的内容，[ | ]表示用什么密钥和算法进行加密</p>
<blockquote>
<ol>
<li><p>首先当用户收到了来自一个服务器的一个安全证书，他会检查是否CA是这个用户信任的CA</p>
</li>
<li><p>其次用户会检查这个安全证书是否是权威的，也就是通过CA公布的公钥来验证CA的数字签名</p>
</li>
<li><p>如果用户确认了这一消息（该证书由一个可信赖的CA颁发并且内容没有修改过），那么这份安全证书就可以被信任</p>
</li>
</ol>
</blockquote>
<p>A keypair can be compromised (e.g. by theft, blackmail)。 Revocation of a certificate could be done by CRLs, or OCSP.</p>
<h2 id="Who-Signs-The-Certificate"><a href="#Who-Signs-The-Certificate" class="headerlink" title="Who Signs The Certificate"></a>Who Signs The Certificate</h2><p><strong>PKI/Public Key Infrastructure</strong>: A centralized, tree structured<br>architecture of entities which sign certificates of their subsiders. The root authorities are implicitly trusted</p>
<pre><code>Root CAs are a single point of failure for the whole infrastructure: if a Root CA gets its key compromised, all the certificates issued from offspring CAs become forgeable.
</code></pre><blockquote>
<p>ACME Control</p>
</blockquote>
<p><strong>WoT/Web-of-Trust</strong>: A distributed architecture relying on the “small world assumption” where everyone can sign certificates. The trust on the authenticity of a certificate is established depending on the trust on the authenticity of its signers</p>
<ul>
<li><p><strong>Users</strong>: The only actor of the scheme are users, they : </p>
<p>  Encrypt/sign/verify a digital object (file/mail message)</p>
<p>  Acts as a CA signing someone else’s key/id pair</p>
<p>  Keep a local key/id keyring where all the certificates are kept </p>
<p>  Choose which users they trust to be acting as a CA</p>
</li>
<li><p><strong>Keyservers</strong>: Provide a globally synchronized, trusted archive of public certificates.</p>
<p>  Public lookup is provided via either key ID or user ID</p>
<p>  The archive is append only, no practical removal is possible </p>
<p>  Anyone can run a keyserver, provided he has enough resources.</p>
</li>
<li><p><strong>Trust Levels</strong>:</p>
<p>  The default trust levels in the WoT scheme are :</p>
<ul>
<li><p>ultimate: It’s the user’s own key trust level. Every key you sign with an “ultimate” trusted key becomes authentic.</p>
</li>
<li><p>complete: One signature by a key with this level of trust makes the key/id pair authentic.</p>
</li>
<li><p>marginal: At least 2 keys with marginal trust have to sign a key/id pair to make it authentic.</p>
</li>
<li><p>untrusted: Untrusted key signatures do not contribute to mark a key/id pair as authentic</p>
<blockquote>
<p>This based on the assuming that before a certificate is signed, each user would be careful enough to verify the corresponding identity.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Certification Authority (CA): An entity (typically a firm) which takes care of signing the certificates, and distributes its public key to all the users in a trusted manner</p>
<blockquote>
<ol>
<li><p>The CA creates its own keypair and fills in the fields of its certificate</p>
</li>
<li><p>We assume, for the sake of clarity, that we are describing a root CA, i.e. one sitting at the top of the PKI hierarchy The CA self-signs its own certificate, and stores its own private key in a tightly guarded place (at least,hopefully)</p>
</li>
<li><p>The CA takes care to distribute its self-signed public key certificate in a safe manner to the largest possible user-base</p>
</li>
</ol>
</blockquote>
</li>
<li><p>Registration Authority (RA): An entity (again, usually a firm) which takes care of verifying the actual authenticity of a certificate, gathering data on the user (physically checking his/her identity and certificate hash). Very often, it coincides with the CA</p>
</li>
<li><p>User: Asks the CA to sign his certificate, or employs the CA public keys to verify the authenticity of the certificates for another user.</p>
</li>
</ul>
<h2 id="Mail-Protocol-PGP-GPG"><a href="#Mail-Protocol-PGP-GPG" class="headerlink" title="Mail Protocol PGP/GPG"></a>Mail Protocol PGP/GPG</h2><p>Possible to encrypt and sign any file, the most typical use is to encrypt and sign e-mail messages</p>
<p>PGP/GPG messages encrypted and signed with an hybrid symmetric+asymmetric scheme for efficiency</p>
<blockquote>
<p>This method is the typical hybrid system. Sender generates a symmetric key to encrypt files and send the symmetric key encrypted in the reciever’s public key.</p>
</blockquote>
<h1 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links"></a>Useful Links</h1><ol>
<li><p><a href="https://www.zhihu.com/question/52493697" target="_blank" rel="noopener">https://www.zhihu.com/question/52493697</a></p>
</li>
<li><p><a href="http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html" target="_blank" rel="noopener">http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html</a></p>
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part II]]></title>
      <url>/2018/03/16/Cryptography-Part-II/</url>
      <content type="html"><![CDATA[<h1 id="Mar-5-Block-Ciphers-amp-Modes-of-Operation"><a href="#Mar-5-Block-Ciphers-amp-Modes-of-Operation" class="headerlink" title="Mar 5 Block Ciphers &amp; Modes of Operation"></a>Mar 5 Block Ciphers &amp; Modes of Operation</h1><h2 id="Design-of-Symmetric-key-Ciphers-Confusion-amp-Diffusion"><a href="#Design-of-Symmetric-key-Ciphers-Confusion-amp-Diffusion" class="headerlink" title="Design of Symmetric-key Ciphers: Confusion &amp; Diffusion"></a>Design of Symmetric-key Ciphers: Confusion &amp; Diffusion</h2><ul>
<li><p>Confusion<br>  make the relation between the key, plaintext and ciphertext as complex as possible. Ideally, each digit of the key influences the correspondence between pxt and cxt letters in a non-predictable way</p>
<blockquote>
<p>Ciphers that do not offer effective confusion are vulnerable to frequency analysis</p>
</blockquote>
</li>
<li><p>Diffusion<br>  Refers to the property that the statistical distribution of “groups of pxt letters” frequencies (due to the redundancy of the ptx language) should be dissipated, as much as possible, into flat distribution statistics, i.e. the ctx should appear as random data.</p>
<blockquote>
<p>Diffusion spreads (diffuse) the influence of a single plaintext letter over many (or every) cxt letters</p>
<p>Ciphers suffering from poor diffusion can usually be broken by means of Known Plaintext Attacks (e.g., simple permutation ciphers) </p>
</blockquote>
</li>
</ul>
<h2 id="Block-Ciphers"><a href="#Block-Ciphers" class="headerlink" title="Block Ciphers"></a>Block Ciphers</h2><p>Block ciphers operate on a block of plaintext m∈M (m = <m1, .="" ,="" mn="">, with m<sub>i</sub>∈{0, 1}), to produce a block of ciphertext (c = <c1, .="" ,="" cn=""> ∈ C, with c<sub>i</sub>∈{0, 1}) through a key-parametric transformation (either E<sub>k</sub> () or D<sub>k</sub> ())</c1,></m1,></p>
<blockquote>
<p>The block size n is in the [64, 256] bit range</p>
<p>ptx size might not be multiple a of block size → PADDING</p>
<p>For ptxs longer than a single block, the scheme used to apply E<sub>k</sub> () (or D<sub>k</sub> ()) is called mode of operation</p>
</blockquote>
<h2 id="Basic-Terminologies"><a href="#Basic-Terminologies" class="headerlink" title="Basic Terminologies"></a>Basic Terminologies</h2><p><strong>Cipher State</strong>: The result of each operation performed by the cipher (Initialized with the ptx; contains the ctx at the end of the computation)</p>
<p><strong>Round</strong>: basic sequence of operations applied to the cipher state, a number of times (involves blending the key into the state)</p>
<p><strong>Key Schedule</strong>: procedure expanding the original user key into key material to be used in each round</p>
<h2 id="Modern-Block-Ciphers"><a href="#Modern-Block-Ciphers" class="headerlink" title="Modern Block Ciphers"></a>Modern Block Ciphers</h2><ul>
<li><p>Feistel Networks</p>
<p>  Invented by Horst Feistel (in ’50-’60), it splits the cipher state in two parts and acts on one of them per round</p>
<p>  A Feistel network transforms an n-bit ptx block m=<l0, r0="">, into an n-bit ctx block c=<rr, lr=""> through an r-round process (r≥1); where the sub-blocks Li , Ri are n/2-bit long.</rr,></l0,></p>
<pre><code>  Feistel(&lt;L, R&gt;, k)
      1 for i ← 0 to r − 1
      2   temp ← L
      3   L ← R
      4   R ← temp ⊕ F(ki, R) // Li = Ri−1, Ri = Li−1 ⊕ F(ki, Ri−1)
      5 R ← R ⊕ F(kr, L)
      6 return &lt;R, L&gt; // Note: the last round block halves are swapped
</code></pre><blockquote>
<p>Properties</p>
<p>L<sub>i</sub> = R<sub>i-1</sub>, R<sub>i</sub> = L<sub>i-1</sub> ⊕ F(k<sub>i</sub> , R<sub>i-1</sub>)</p>
<p>R<sub>i-1</sub> = L<sub>i</sub> , L<sub>i-1</sub> = R<sub>i</sub> ⊕ F(k<sub>i</sub>, L<sub>i</sub>)</p>
</blockquote>
  <img src="/2018/03/16/Cryptography-Part-II/Crypto.png">
<blockquote>
<p>Ciphers based on a Feistel Network</p>
<p>DES, Blowfish, Twofish, CAST5</p>
</blockquote>
</li>
<li><p>DES</p>
<p>  16-round Feistel cryptosystem with 64-bit wide cipher state</p>
  <img src="/2018/03/16/Cryptography-Part-II/Crypto2.png">
<p>  <strong>DES round</strong>: F(ki, Ri−1) = P-box(S-box(ki ⊕ E-box(Ri−1))</p>
<ol>
<li><p>E-box(Ri−1) expands Ri−1 from 32 (4 <em> 8) into 48 (6 </em> 8) bits </p>
</li>
<li><p>Adds (XOR) the 48-bit round key ki </p>
</li>
<li><p>Map the 48-bit word into a 32-bit one via applying 8 fixed S-boxes. Each S-box map a 6 bit word to a 4 bit one</p>
</li>
<li><p>Apply a fixed bitwise permutation specified by the P-box</p>
<p><strong>Weak Keys</strong>: Encrypting a ptx twice with a weak key k, yields the original ptx. DES(k, DES(k, m)) = m, ∀ m ∈ M</p>
<p><strong>Semi-Weak Keys</strong>: Also a Semi-Weak key pair <k, k0=""> causes the composition of two DES encryptions employing k and k0 to compute the original ptx DES(k, DES(k 0, m)) = m, ∀ m ∈ M</k,></p>
<p><strong>Not Closed</strong>: ∀m not exists k3 s.t. DES(k3, m) = DES(k2, DES(k1, m))</p>
<blockquote>
<p>The composition of two DES with distinct keys is still a permutation Sn, but in general it cannot be thought as computed by a DES with another key.</p>
</blockquote>
<p><a href="https://zh.wikipedia.org/wiki/資料加密標準" target="_blank" rel="noopener">DES in wiki</a></p>
<p><a href="https://zh.wikipedia.org/wiki/DES%E8%A1%A5%E5%85%85%E6%9D%90%E6%96%99#%E6%89%A9%E5%BC%A0%E5%87%BD%E6%95%B0_(E%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">DES support material</a>)</p>
</li>
</ol>
</li>
<li><p>2DES</p>
<p>  Double DES cipher consists of applying the DES primitive twice: c = 2DES(k1, k2, m) def as DES(k1, DES(k2, m))</p>
</li>
<li><p>Triple DES/TDES</p>
<p>  c = 3DES(k1, k2, k3, m) def as = DES(k1, DES−1 (k2, DES(k3, m)))</p>
<p>  m = 3DES−1(k1, k2, k3, m) def. = DES−1(k3, DES(k2, DES−1(k1, c)))</p>
</li>
<li><p>Substitution Permutation Networks (SPNs)</p>
<blockquote>
<p>The round of a SPN acts on the whole cipher state with:</p>
<p>A “non-linear” function providing Confusion represented as a lookup table, a.k.a.: Substitution-Box (S-box)</p>
<p>A “linear” function providing Diffusion, i.e., a bitwise permutation, or pairs of rotate &amp; xor operations The addition of a part of the key schedule</p>
</blockquote>
</li>
</ul>
<h2 id="Modes-of-Operation"><a href="#Modes-of-Operation" class="headerlink" title="Modes of Operation"></a>Modes of Operation</h2><p>A Mode of operation specifies the way to encrypt a message m∈M of arbitrary length through employing a block cipher</p>
<p>Currently, there are modes of operations to guarantee </p>
<ul>
<li><p>Confidentiality of messages:</p>
<p>  Electronic CodeBook mode (ECB)</p>
<p>  Cipher Block Chaining mode (CBC)–most popular–not entirely secure</p>
<p>  Output FeedBack mode (OFB)</p>
<p>  Cipher FeedBack mode (CFB)</p>
<p>  Counter mode (CTR)</p>
</li>
<li><p>Authentication of messages:<br>  CMAC</p>
</li>
<li><p>Both confidentiality and authentication:<br>  CCM and GCM</p>
</li>
</ul>
<h2 id="CBC"><a href="#CBC" class="headerlink" title="CBC"></a>CBC</h2><p><strong>Encryption</strong></p>
<p>c<sub>0</sub> = IV<br>c<sub>i</sub> = E<sub>k</sub> (m<sub>i</sub> ⊕ c<sub>i-1</sub>), for i ≥ 1</p>
<blockquote>
<p>The Initialization Vector (IV) ensures that two encryptions of the same ptx produce different ctxs</p>
</blockquote>
<p><strong>Decryption</strong></p>
<p>m<sub>i</sub> = D<sub>k</sub> (c<sub>i</sub>) ⊕ c<sub>i-1</sub>, for i ≥ 1</p>
<h2 id="Stream-Based-Models"><a href="#Stream-Based-Models" class="headerlink" title="Stream Based Models"></a>Stream Based Models</h2><p>Given a plaintext message m∈M as a sequence of blocks m=<m1, m2,="" .="" ,=""> the CFB, OFB and CTR modes of operation generate a key stream k1, k2, k3 . . . (each key has the size of a block) to mask the ptx m: ci = mi ⊕ ki , for i ≥ 1</m1,></p>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part I]]></title>
      <url>/2018/03/15/Cryptography-Part-I/</url>
      <content type="html"><![CDATA[<h1 id="Feb-26-Introduction-to-Cryptography"><a href="#Feb-26-Introduction-to-Cryptography" class="headerlink" title="Feb 26 Introduction to Cryptography"></a>Feb 26 Introduction to Cryptography</h1><h2 id="Instructor-Information"><a href="#Instructor-Information" class="headerlink" title="Instructor Information"></a>Instructor Information</h2><p>gerardo.pelosi@polimi.it</p>
<p>alessandro.barenghi@polimi.it</p>
<h2 id="Introduction-to-cryptography"><a href="#Introduction-to-cryptography" class="headerlink" title="Introduction to cryptography"></a>Introduction to cryptography</h2><p><strong>cryptography</strong>: how to design and implement cryptographic algorithms</p>
<p><strong>cryptanalysis</strong>: how to break a cipher (recover key/message), analyzing weak mathematical assumptions or advancements, bad implementations</p>
<h2 id="Modern-Cryptography"><a href="#Modern-Cryptography" class="headerlink" title="Modern Cryptography"></a>Modern Cryptography</h2><p><strong>Kerckhoff’s Principle</strong> A cryptosystem should be secure even if everything about the system is publicly known, except a single parameter (a.k.a., the cryptographic key)</p>
<h2 id="Security-Models"><a href="#Security-Models" class="headerlink" title="Security Models"></a>Security Models</h2><p><strong>Unconditional Security (Perfect Secrecy)</strong>: assumes an adversary with unlimited computing power and proves that she does not have enough information to infer either the cryptographic key or the original message </p>
<p><strong>Computational Security</strong>: assumes that any adversary is computationally limited (. . .as all adversaries are in practice). It gives a lower-bound on the computational complexity of the best methods available to break the cipher</p>
<h2 id="Security-Properties"><a href="#Security-Properties" class="headerlink" title="Security Properties"></a>Security Properties</h2><ol>
<li><p>Confidentiality[保密性]</p>
<p> Confidentiality provides encrypted information, thus making it unreadable to anyone except for the intended receivers, who are able to reverse the encryption</p>
</li>
<li><p>Authenticity[真实性]</p>
<p> Authenticity indicate that systems use to identify their users. It answers the questions of <em>Who is the user/counterpart?</em> and <em>is the user/counterpart really who she claims herself to be?</em></p>
<blockquote>
<p>When a system includes a communication protocol:</p>
<ul>
<li><p>The parties may need to identify themselves (<strong>entity authentication</strong>)</p>
</li>
<li><p>The parties want to make sure that data is really exchanged between the intended endpoints (i.e., No-one in middle is masquerading as one of them) (<strong>data origin authentication</strong>)</p>
</li>
</ul>
</blockquote>
</li>
<li><p>Data integrity[完整性]</p>
<p> Data integrity guarantees that data has not been tampered with.(Insertion/Replacement/Deletion)</p>
<blockquote>
<p>Data Authentication (data origin authentication + data integrity)</p>
<ul>
<li><p>data origin authentication (the fact that you know who the sender is)</p>
</li>
<li><p>data integrity (the fact that data has not been modified)</p>
</li>
</ul>
</blockquote>
</li>
<li><p>Non-repudiation[不可否认性]</p>
<p> Non-repudiation prevents an entity from denying previous commitments or actions later on.</p>
</li>
</ol>
<h2 id="Basic-Terminology-and-Concepts"><a href="#Basic-Terminology-and-Concepts" class="headerlink" title="Basic Terminology and Concepts"></a>Basic Terminology and Concepts</h2><ol>
<li><p><strong>Alphabet A</strong>: a finite set of symbols</p>
<p> The binary alphabet, A={0, 1}, is the most common choice as any other alphabet can be encoded over it</p>
</li>
<li><p><strong>Message Space M</strong>: consists of set of strings over an alphabet</p>
</li>
<li><p><strong>Plain Text</strong>: an element of M</p>
</li>
<li><p><strong>Ciphertext Space C</strong>: consists of a set of strings over an alphabet (which may differ from the alphabet for M).</p>
</li>
<li><p><strong>iphertext</strong>: an element of C </p>
</li>
<li><p><strong>KeySpace K</strong>: a set of elements called keys.(a set of keys)</p>
</li>
<li><p><strong>Encryption Transformation</strong>: Given an element e∈K, the encryption transformation E<sub>e</sub> : M→C, uniquely determines a bijective map from M to C.</p>
</li>
<li><p><strong>Decryption transformation</strong>: Given an element d∈K, the decryption transformation E<sub>d</sub> : C→M, uniquely determines a bijective map from C to M.</p>
</li>
<li><p><strong>Cryptoscheme</strong>: <a, m,="" c,="" k,="" {e<sub="">e : e ∈ K}, {D<sub>d</sub> : d ∈ K}&gt;</a,></p>
</li>
</ol>
<h2 id="Cryptographic-Paradigms"><a href="#Cryptographic-Paradigms" class="headerlink" title="Cryptographic Paradigms"></a>Cryptographic Paradigms</h2><ol>
<li><p>Symmetric (or Secret-Key) Cryptosystem</p>
<p> Every user is bound to a single secret key, with fixed length, i.e. encryption E<sub>e</sub> and decryption D<sub>d</sub> algorithms use the same key: e = d</p>
<blockquote>
<p>There are two main strategies for defining E and D, which lead to</p>
<ul>
<li><p>Block ciphers: act on a fixed length plain/ciphertext (e.g., AES, 3DES2, CAST5, Camellia, Gost, BlowFish)</p>
</li>
<li><p>Stream ciphers: act on an arbitrary length plain/ciphertext (e.g., RC4, Trivium, A5/1, A5/2, A5/3)</p>
</li>
</ul>
</blockquote>
</li>
<li><p>Asymmetric (or Public-Key) Cryptosystem</p>
<p> Every user is bound to a key pair:</p>
<ul>
<li><p>Public Key e ∈ K: is employed to encrypt plaintexts (E<sub>e</sub> (m), m ∈ M). Can be known to everybody</p>
</li>
<li><p>Private Key d ∈ K: is employed to decrypt ciphertexts (D<sub>d</sub> (c), c ∈ D). Must be known to the recipient only (and rigorously kept secret from everybody else)</p>
<blockquote>
<p>The public key needs authentication to avoid identity theft. Which guarantee do we have that the public key is really bound to the intended user?</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Digital Signatures and Certification Authorities (CAs)</p>
<p> To provide the Non-Repudiation service we need: Digital Signatures and Certification Authorities (CAs)</p>
<ul>
<li><p><strong>Digital Signature</strong></p>
<p>  A tool to authenticate the public key. It allows to verify the unambiguous association of a user to her public-key</p>
<ul>
<li><p>A digital signature can be obtained applying the decryption transformation(using his/her private key d) to the message m, which should be authenticated: s = D<sub>d</sub> (m)</p>
</li>
<li><p>Everyone can check the validity of the signed message <m,s> (by the public key e) through checking whether E<sub>e</sub> (s) = m or not, as e is a publicly known value</m,s></p>
<blockquote>
<p>非对称加密的原理就好像有一把锁，每个人都可以用一把钥匙（公钥e）锁上，但是要想开这把锁，必须用一把特殊的钥匙（私钥d）开锁，而数字签名的原理刚好相反，一个用户需要向所有的用户展示自己的身份，最好的办法就是他举起他的钥匙大喊，“看！这唯一的一把私钥在我手上”。而在计算机科学的领域，他的做法就是将一条消息解密（这是只有拥有私钥的人才能办得到的事情！）然后向每个人公布解密后的消息，每个人都可以拿到他解密后的消息s和原来的消息m，通过公钥加密s后可以得到m，就证明了这个私钥用户的身份。</p>
</blockquote>
</li>
</ul>
</li>
<li><p><strong>Certification Authority (CA)</strong></p>
<p>  An independent third party (that all users trust) certifies the binding of a public-key to the identity of the corresponding user。</p>
<p>  The CA digitally signs a document (<strong>Digital Certificate</strong>) saving in public repositories, containing</p>
<ul>
<li><p>The identity of the user</p>
</li>
<li><p>The public-key of the user</p>
</li>
<li><p>Metadata (e.g., expiration date, CA name, etc…)</p>
<p>The assumption is that everybody knows the public keys of the CAs, thus every certificate can be checked through verifying a CA signature</p>
</li>
</ul>
</li>
<li><p><strong>Identity Based Cryptosystem</strong></p>
<p>  A Public-Key system where the User Identity is employed to uniquely derive the public key.</p>
<ul>
<li><p>Identity: any previously recognized and publicly known piece of information bound to a specified user (e.g., a SSN, an email address, passport No., driving licence No., position in a company)</p>
</li>
<li><p>Public Key: is uniquely derived from the Identity chosen by the user. May be known to everybody</p>
</li>
<li><p>Private Key: is released to each user by a Trusted Authority (TA) who combines the user Identity and a master secret parameter to compute it</p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Attacks-on-Cryptoscheme"><a href="#Attacks-on-Cryptoscheme" class="headerlink" title="Attacks on Cryptoscheme"></a>Attacks on Cryptoscheme</h2><p><strong>Basic assumptions: Kerckhoff’s principle</strong></p>
<p>The alphabet A, the structure of the plaintexts (i.e., the form of M) and the details of the encryption/decryption algorithms are known</p>
<p><strong>Brute force attack (Exhaustive key search)</strong></p>
<p>Given a ciphertext, it checks <strong>all possible keys</strong> until the correct one is found. The attacker must be able to distinguish the correct plaintext from a valid but incorrect one</p>
<p><strong>Categrories</strong></p>
<ul>
<li><p>Ciphertext-only attack (COA)</p>
<p>  The attacker knows the ciphertext of a number of messages encrypted with same key (he doesn’t known any plaintext)</p>
</li>
<li><p>Known-plaintext attack (KPA)</p>
<p>  The attacker knowns plain-ciphertext pairs, encrypted with same key</p>
</li>
<li><p>Chosen-plaintext attack (CPA)</p>
<p>  The attacker chooses a number of plaintexts to be encrypted (all with the same unknown key) and obtains the corresponding ciphertexts</p>
</li>
</ul>
<h1 id="Mar-1-Historical-Ciphers"><a href="#Mar-1-Historical-Ciphers" class="headerlink" title="Mar 1 Historical Ciphers"></a>Mar 1 Historical Ciphers</h1><h2 id="Substitution-Ciphers"><a href="#Substitution-Ciphers" class="headerlink" title="Substitution Ciphers"></a>Substitution Ciphers</h2><ul>
<li><p>Monoalphabetic Substitution Cipher(eg: Shift Cipher, The Gold Bug Cryptogram):</p>
<p>  There is a 1-to-1 correspondence between plaintext (ptx) and ciphertext (ctx) letters (also digrams, trigrams, etc). Thus, assuming the Kerchoff’s principle holds, a Ciphertext-Only attack (COA) easily reveals the key(Based on the statistic of frequency of each letter).</p>
<blockquote>
<p>The statistics of the plaintext language (frequency distribution of the symbols of Am in M) is known</p>
<p>The statistics of the ciphertext space, i.e., the frequency distribution of the symbols of Ac in C, can be computed over the available ciphertexts.</p>
<p>The substitution map (i.e., the key) can be inferred easily by matching the symbols occurring with similar frequencies</p>
<p>Most common letters: E,A,T,O,N,I…</p>
<p>Most common bigrams: TH,HE,IN,ER…</p>
<p>Most common trigrams:THE,ING,AND…</p>
</blockquote>
</li>
<li><p>Polyalphabetic Cipher(eg: Vigenere Cipher):</p>
<p>  The plaintext and ciphertext spaces include finite sequence of letters (words) from the alphabets A<sub>m</sub> and A<sub>c</sub> , respectively.</p>
<p>  The encryption transformation is defined as the application of “L &gt; 1 bijective maps”(L is the length of the key, may be reused and reused) between the two alphabets: µ0, µ1,… here each µ means a mapping from A<sub>m</sub> to A<sub>c</sub>.</p>
<blockquote>
<p>here it means that one µ is a crypto-system that mapping A to C, B to D … so the keyspace is (|A<sub>m</sub>|!)^L</p>
</blockquote>
<p>  The key k = (µ0, µ1, . . . , µL−1) is constituted by the L maps employed to encrypt the ciphertext</p>
<ul>
<li><p>Vigenere Cipher</p>
<p>  If the plain text is <strong>ATTACKATDAWN</strong></p>
<p>  Choose the key as LEMON and get the length same with plain text <strong>LEMONLEMONLE</strong></p>
<p>  Here each letter in the key noted as a sequence, for example, </p>
<p>  K1 = L, and the M1 is A, so the C1 is L(the 1st one noted by L).</p>
<p>  K2 = E, and the M2 is T, so the C2 is X(the 20st one noted by E).</p>
<p>  … …</p>
<p>  And get the final cipher text LXFOPVEFRNHR</p>
<blockquote>
<p>The cipher is still easy to break with a Ciphertext Only Attack using Kasisky Test</p>
<p>It bases on the fact that two identical segments of 2 ≤ l ≤ L plaintext letters (l-gram), will be encrypted to the same sequence of l ciphertext letters (when properly aligned with the keyword)</p>
<p>Deduction: The distance d between two repeated sequences of l chars in the ciphertext may suggest a multiple of the key length L (find the GCD)</p>
</blockquote>
</li>
<li><p>Beale’s Cipher/Book Cipher</p>
</li>
</ul>
</li>
</ul>
<h2 id="Permutation-Ciphers-Transposition-Cipher"><a href="#Permutation-Ciphers-Transposition-Cipher" class="headerlink" title="Permutation Ciphers/Transposition Cipher"></a>Permutation Ciphers/Transposition Cipher</h2><p>The encryption transformation of this cipher consists of a permutation of the positions of the plaintext letters</p>
<blockquote>
<p>a permutation cipher is not equivalent to a substitution map as each plaintext letter may corresponds to multiple ciphertext letters depending on the position</p>
<p>COA may not effective, but KPA/CPA still work</p>
</blockquote>
<h2 id="Affine-Ciphers"><a href="#Affine-Ciphers" class="headerlink" title="Affine Ciphers"></a>Affine Ciphers</h2><ul>
<li>The Hill Cipher</li>
</ul>
<h2 id="Perfect-Secrecy"><a href="#Perfect-Secrecy" class="headerlink" title="Perfect Secrecy"></a>Perfect Secrecy</h2><p>A perfectly secret cipher should be unbreakable regardless of the (computational) effort thrown at it This implies that the ciphertext alone provides no information (no clue) to an attacker</p>
<p>A perfectly secure cipher is proven to be resistant to COAs, KPAs, and CCA(2)s.</p>
<blockquote>
<p>Definition</p>
<p>A symmetric-key cryptosystem is Perfectly Secure if the ciphertext does not reveal any information about the plaintext</p>
<p>Pr(P = m|C = c) = Pr(P = m), ∀m ∈ M, c ∈ C</p>
<p>LEMMA1: Pr(C = c|P = m) = Pr(C = c), ∀m ∈ M, c ∈ C</p>
<p>LEMMA2: Given a Perfectly Secure symmetric key cryptosystem, the followingconditions hold |K| ≥ |C| ≥ |M|</p>
</blockquote>
<h2 id="Theorem-C-Shannon"><a href="#Theorem-C-Shannon" class="headerlink" title="Theorem (C. Shannon)"></a>Theorem (C. Shannon)</h2><p>Let <a, m,="" k,="" c,="" {e<sub="">k (), k ∈ K}, {D<sub>k</sub> (), k ∈ K}&gt; denote a symmetric key cryptosystem where the keys are picked independently of plaintexts values and |K| = |C| = |M|, The cryptosystem is perfectly secure iff </a,></p>
<p>(i) every key is used with probability 1/|K| </p>
<p>(ii) ∀ (m, c)∈M×C there is a unique key k∈K s.t. E<sub>k</sub> (m)=c</p>
<h2 id="Vernam-Cipher-One-Time-Pad-OTP-一次性密码本"><a href="#Vernam-Cipher-One-Time-Pad-OTP-一次性密码本" class="headerlink" title="Vernam Cipher/One-Time-Pad (OTP)[一次性密码本]"></a>Vernam Cipher/One-Time-Pad (OTP)[一次性密码本]</h2><ul>
<li><p>Modified Shift Cipher</p>
<p>  To encrypt plain text [This is an example]</p>
<p>  Using the OTP of [MASKL NSFLD FKJPQ]</p>
<p>  First transform two strings into numbers</p>
<p>  This is an example → 19 7 8 18 8 18 0 13 4 23 0 12 15 11 4</p>
<p>  MASKL NSFLD FKJPQ → 12 0 18 10 11 13 18 5 11 3 5 10 9 15 16</p>
<p>  Sum them up and get</p>
<p>  31 7 26 28 19 31 18 18 15 26 5 22 24 26 20</p>
<p>  Mod 26 get</p>
<p>  5 7 0 2 19 5 18 18 11 0 5 22 24 0 20</p>
<p>  Transform back to English and get</p>
<p>  FHACTFSSLAFWYAU</p>
<blockquote>
<p>The aformentioned OTP system employed with binary keys and messages is the most effective implementation of a perfectly secure cryptoscheme</p>
<p>This system is perfectly secure (M=C=K={0, . . . , 25}^5; ptxs and keys are independent):</p>
<p>each key is chosen with uniform probability ⇒ Pr(K = k) = 1/26^5</p>
<p>for each ptx-ctx pair <m, c=""> there is a unique key: k<sub>i</sub>=(c<sub>i</sub>−m<sub>i</sub>) mod 26, ∀ i</m,></p>
</blockquote>
</li>
</ul>
<h2 id="Computationally-secure-ciphers"><a href="#Computationally-secure-ciphers" class="headerlink" title="Computationally secure ciphers"></a>Computationally secure ciphers</h2><h2 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h2><p>Definition</p>
<p>Let X be a random variable (generally means an alphabet) which takes values in {x1, x2, . . . xn} with probability distribution p<sub>i</sub>=Pr(X = x<sub>i</sub>), ∀ 1≤i≤n. The Entropy of X is defined as:</p>
<p>H(X) = −Sigma(i from 1 to n) p<sub>i</sub>log<sub>2</sub>p<sub>i</sub></p>
<p>assuming conventionally that p<sub>i</sub>log<sub>2</sub>p<sub>i</sub>=0, if p<sub>i</sub>=0.</p>
<blockquote>
<p>H(X, Y )≤H(X)+H(Y ), the equality holds if X, Y are independent</p>
<p>H(X, Y )=H(Y )+H(X|Y );</p>
<p>H(X|Y )≤H(X), the equality holds if X, Y are independent</p>
<p>H(P|K, C)=0: if you know the ctx and the key you do not have any uncertainty in deriving the ptx</p>
<p>H(C|P,K)=0: if you know the ptx and the key you do not have any uncertainty in deriving the ctx</p>
<p>H(C, P,K)=H(P,K)+H(C|P,K)=H(P,K)=H(P)+H(K)</p>
<p>H(C, P,K)=H(K, C)+H(P|K, C)=H(K, C)</p>
</blockquote>
<ul>
<li><p>Key Equivocation</p>
<p>  It defines the amount of information (uncertainty) about the key, that you got by the knowledge of a ctx: H(K|C)</p>
<p>  H(K|C) = H(K, C) − H(C) = H(P) + H(K) − H(C)</p>
</li>
<li><p>Definition of Language Redundancy</p>
<p>  R<sub>L</sub> = 1 − H<sub>L</sub>/log<sub>2</sub>|M|</p>
</li>
<li><p>Unicity Distance</p>
<p>  It is the length of ciphertext words (i.e., the number of ctx) n=n0 such that the number of spurious keys is equal to zero,</p>
<p>  n0 ≈ log<sub>2</sub>|K|/(R<sub>L</sub>log<sub>2</sub>|M|)</p>
</li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Algorithm and Complexity Analysis]]></title>
      <url>/2018/03/14/Algorithm-and-Complexity-Analysis/</url>
      <content type="html"><![CDATA[<p>EG: The Problem of sorting</p>
<p>Input: sequence (a1, a2, …, an) of numbers. </p>
<p>Output: permutation (a’1, a’2, …, a’n) such<br>    that a’1 &lt;= a’2 &lt;= … &lt;= a’n.</p>
<pre><code>///ONE SOLUTION: INSERTION SORT///

void insertion_sort(std::vector&lt;int&gt; &amp;A)
{
    int i;
    int j;
    int value;
    for(i=1; i&lt;A.size(); i++)
    {
       value = A[i];
       j = i-1;
       while(j&gt;=0 &amp;&amp; A[j]&gt;value)
       {
            A[j+1] = A[j];
            j = j-1; 
        }
       A[j+1] = value;
    }
}
</code></pre><ul>
<li>Running Time</li>
</ul>
<p>The running time depends on the input: an already sorted sequence is easier to sort.</p>
<p>Parameterize the running time by the size of the input, since short sequences are easier to sort than long ones.</p>
<p>Generally, we seek upper bounds on the running time, because everybody likes a guarantee.</p>
<ul>
<li>Kinds of Analysis</li>
</ul>
<p>Worst-case: (usually)</p>
<p>T(n) = maximum time of algorithm on any input of size n. </p>
<p>Average-case: (sometimes)</p>
<p>T(n) = expected time of algorithm over all inputs of size n.</p>
<p>Need assumption of statistical distribution of inputs.</p>
<p>Best-case: (bogus)</p>
<p>Cheat with a slow algorithm that works fast on some input.</p>
<ul>
<li>Machine-Independent Time</li>
</ul>
<p>What is insertion sort’s worst-case time?</p>
<p>It depends on the speed of our computer: </p>
<p>relative speed (on the same machine),</p>
<p>absolute speed (on different machines).</p>
<p>BIG IDEA:</p>
<p> Ignore machine-dependent constants. </p>
<p> Look at growth of T(n) as n → ∞ .</p>
<ul>
<li>Q-notation</li>
</ul>
<p>MATH: Q(g(n)) = { f (n) :there exist positive constants c1, c2, and   n0 such that 0 &lt;= c1g(n) &lt;= f (n) &lt;= c2g(n) for all n &gt;= n0 }</p>
<p>ENGINEERING: Drop low-order terms; ignore leading constants.Example: 3n^3 + 90n^2 – 5n + 6046 = Q(n^3)</p>
<p>Here get back to the example of insertion analysis:<br>• Worst case: Input reverse sorted.<br>T(n)=Σ(j=2…n)Q(j)=Q(n^2</p>
<p>While in the Merge-Sort</p>
<p>MERGE-SORT A[1 . . n] 1. </p>
<ol>
<li><p>If n = 1, done.</p>
</li>
<li><p>Recursively sort A[ 1,…,[n/2] ] and A[ [n/2]+1,…,n ]</p>
</li>
<li><p>“Merge” the 2 sorted lists.</p>
</li>
</ol>
<pre><code>void merge_sort(std::vector&lt;int&gt; &amp;A)
{
    std::vector&lt;int&gt; A1;
    std::vector&lt;int&gt; A2;
    if (A.size()==1) return;
    for(int i=0; i&lt;A.size()/2; i++)
            A1.push_back(A[i]);
    for(int i=A.size()/2; i&lt;A.size(); i++)
            A2.push_back(A[i]);
    merge_sort(A1); 
    merge_sort(A2);
    A = merge(A1,A2);
}
</code></pre><p>The complexity of merge sort is</p>
<p>if n=1: T(n)=Q(1)</p>
<p>if n&gt;1: T(n)=2T(n/2) + Q(n)</p>
<p>Since there is lg(n) levels, and for eahc level the cost of merge is n so the total cost is nlg(n).</p>
<ul>
<li>O-Notation(Upper Bounds)</li>
</ul>
<p>We write f(n) = O(g(n)) if there exist constants c &gt; 0, n0 &gt; 0 such that 0 &lt;= f(n) &lt;= cg(n) for all n &gt;= n0.</p>
<p>O(g(n)) = { f(n) : there exist constants c &gt; 0, n0 &gt; 0 such that 0 &lt;= f(n) &lt;= cg(n) for all n &gt;= n0 }</p>
<p>[O(g(n)) noted a whole class of algorithms whos upper bound complexity  is O(g(n))]</p>
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/Algorithms.jpg" title="This is an example for time complexity in O">
<ul>
<li>Marco Substitution</li>
</ul>
<p>Convention: A set in a formula represents an anonymous function in the set.</p>
<pre><code>    EXAMPLE1:
        f(n)=n^3+O(n^2)
        MEANS
        f(n)=n^3+h(n)
        FOR SOME h(n) belongs to O(n^2)
</code></pre><pre><code>    EXAMPLE2:
        n^2+O(n)=O(n^2)
        MEANS
        FOR ANY f(n) belongs to O(n)
            n^2+f(n)=h(n)
            FOR SOME h(n) belongs to O(n^2)
</code></pre><ul>
<li>Omega-Notation</li>
</ul>
<p>Omega(g(n)) = { f(n) : there exist constants c &gt; 0, n0 &gt; 0 such that 0 &lt;= cg(n) &lt;= f(n) for all n &gt;= n0 }</p>
<ul>
<li>Boundary Conditions</li>
</ul>
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/BoundaryConditions.png">
<ul>
<li>Common Cases</li>
</ul>
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/CommonCase1.png">
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/CommonCase2.png">
]]></content>
      
        
        <tags>
            
            <tag> Algorithm </tag>
            
            <tag> POLIMI </tag>
            
            <tag> Parallel Programming </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Jupyter Notebook of Machine Learning]]></title>
      <url>/2018/03/12/Jupyter-Notebook-of-Machine-Learning/</url>
      <content type="html"><![CDATA[<p>This is a studying ntoe in the process of the application of Jupyter Notebook in Machine Learning.</p>
<p>Starting from a basic example of the Iris-Analysis</p>
<pre><code>    # dataframe management
    import pandas as pd

    # numerical computation
    import numpy as np

    # visualization library
    import seaborn as sns
    sns.set(style=&quot;white&quot;, color_codes=True)
    sns.set_context(rc={&quot;font.family&quot;:&#39;sans&#39;,&quot;font.size&quot;:24,&quot;axes.titlesize&quot;:24,&quot;axes.labelsize&quot;:24})


    # import matplotlib and allow it to plot inline
    import matplotlib.pyplot as plt
    %matplotlib inline

    # seaborn can generate several warnings, we ignore them
    import warnings
    warnings.filterwarnings(&quot;ignore&quot;)

    # sklearn is a python library including a lot of machine learning models
    import sklearn

    # opencv is a tool to import image and do image analysis
    import cv2

    # Scipy is a tool to practice some scientific mathematical calculation
    import scipy

    # skimage is a tool to do image analysis
   import skimage
</code></pre><ul>
<li><p><a href="https://pandas.pydata.org/" target="_blank" rel="noopener">Pandas</a> is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.</p>
<p>Generally speaking, the basic load of information could be done by pandas function</p>
</li>
<li><p><a href="http://www.numpy.org/" target="_blank" rel="noopener">NumPy</a>’s main object is the homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of positive integers. In NumPy dimensions are called axes. The number of axes is rank.</p>
<p>For example NumPy could be used to return the max/min values of one column of values</p>
</li>
<li><p><a href="https://seaborn.pydata.org/" target="_blank" rel="noopener">Seaborn</a> is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.</p>
</li>
<li><p><a href="https://matplotlib.org/" target="_blank" rel="noopener">Matplotlib</a> is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shells, the Jupyter notebook, web application servers, and four graphical user interface toolkits.</p>
</li>
<li><p><a href="http://scikit-learn.org/stable/" target="_blank" rel="noopener">Sklearn</a> is a free software machine learning library for the Python programming language.[3] It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.</p>
</li>
<li><p><a href="http://opencv-python-tutroals.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">OpenCV</a> (Open Source Computer Vision) is a library of programming functions mainly aimed at real-time computer vision.[1] Originally developed by Intel, it was later supported by Willow Garage then Itseez (which was later acquired by Intel). The library is cross-platform and free for use under the open-source BSD license.</p>
</li>
<li><p><a href="https://www.scipy.org/" target="_blank" rel="noopener">Scipy</a> is a Python-based ecosystem of open-source software for mathematics, science, and engineering.</p>
</li>
<li><p><a href="http://scikit-image.org/" target="_blank" rel="noopener">skimage</a> is a collection of algorithms for image processing. It is available free of charge and free of restriction. We pride ourselves on high-quality, peer-reviewed code, written by an active community of volunteers. </p>
</li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> Jupyter Notebook </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Game Concept Art Design]]></title>
      <url>/2018/01/31/Game-Concept-Art-Design/</url>
      <content type="html"><![CDATA[<p>This is a general gallery for the art design I made, as a raw material for future use.</p>
<ul>
<li>Photoshop Art Design</li>
</ul>
<ol>
<li><img src="/2018/01/31/Game-Concept-Art-Design/ArtDesign1.jpg" title="practice on PS">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/ArtDesign2.jpg" title="logo od Scarlet Games">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/ArtDesign3.png" title="Date Masamune">
</li>
</ol>
<ul>
<li>Paper Art Design</li>
</ul>
<ol>
<li><img src="/2018/01/31/Game-Concept-Art-Design/1.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/2.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/3.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/4.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/5.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/6.jpg">
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> Game Development </tag>
            
            <tag> Art Design </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Wechat Game Development]]></title>
      <url>/2018/01/25/Wechat-Game-Development/</url>
      <content type="html"><![CDATA[<p>This is a development journal for a simple wechat game.</p>
<p>Outside Link <a href="https://mp.weixin.qq.com/debug/wxagame/dev/" target="_blank" rel="noopener">WECHAT HELPER DOCUMENT</a></p>
]]></content>
      
        
        <tags>
            
            <tag> Game Development </tag>
            
            <tag> Wechat </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linear Programming]]></title>
      <url>/2018/01/10/Linear-Programming/</url>
      <content type="html"><![CDATA[<h1 id="Linear-Progarmming"><a href="#Linear-Progarmming" class="headerlink" title="Linear Progarmming"></a>Linear Progarmming</h1><p>Algorithm in Primal Dual Simplex</p>
<pre><code>Procedure Simplex_Primal_Dual(A,b,c,x,unbounded,y) 
    {A:input matrix // b:known term vector}
    {c: cost vector // x: feasible solution}
    {y: optimal solution of D}
    //////////
    begin
    optimal:=false; unbounded:=false;
    I:={i: Aix=bi};
    {Select the active constraints}
    if I==None then grow_along(c,x,I,unbounded); 
    while not optimal or not unbounded do 
        begin
        {g means yita and e means yipxilun}
        if {gAI=c} has no solution then 
            begin compute e&lt;: AIe=0, ce=1; grow_along(e,x,I,unbounded); end;
        else if {gAI=c} has a solution and exists h: gh&lt;0 then 
            begin compute e: AIe=uh; grow_along(e,x,I,unbounded); end;
        else optimal:=true; 
        {the dual system has a solution: gAI=c, g&gt;=0} 
        end;
    end.
</code></pre>]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Foundations of Operations Research </tag>
            
            <tag> Linear Programming </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Graphs and Network Flows]]></title>
      <url>/2018/01/09/Graphs-and-Network-Flows/</url>
      <content type="html"><![CDATA[<h1 id="Defination"><a href="#Defination" class="headerlink" title="Defination"></a>Defination</h1><ul>
<li>G=(N,A)</li>
<li>Path</li>
<li>Closed Path</li>
<li>Simple Path: path with no repeated arcs</li>
<li>Elementary path: a path with no repeated nodes</li>
<li>Cycle</li>
<li>Hamilton Cycle: a cycle having all nodes in the G(N,A)</li>
<li>Eulerian Cycle: a cycle having all arcs in the G(N,A)</li>
</ul>
<h1 id="Undirected-graphs-spanning-tree-and-Hamiltonian-circuit"><a href="#Undirected-graphs-spanning-tree-and-Hamiltonian-circuit" class="headerlink" title="Undirected graphs: spanning tree and Hamiltonian circuit"></a>Undirected graphs: spanning tree and Hamiltonian circuit</h1><ul>
<li><p>Spanning tree: formulation and a solution algorithm</p>
<blockquote>
<p>  The algorithm we are considering iteratively builds a solution starting from the empty one, and at each new step adds a new arc to the set of those that had been chosen. Two criteria must be established to guarantee the correct functioning of the algorithm: <em>i) the order according to which we should select the arcs to be put in the solution;</em> <em>ii) the criterion according to which we decide to add an arc to those already existing.</em></p>
<p>  i) Considering the order, we are guided by arc weights. So we begin by considering the arcs with lighter weight and end with the heavier ones.</p>
<p>  ii) An arc is added to the current solution only if the set of arcs, so augmented, can be part of a feasible solution. In the considered case this means that the arc added to the solution must not form cycles with the chosen arcs. Otherwise, we would come to a redundant solution.</p>
</blockquote>
</li>
<li><p>Minimum cost Hamiltonian circuit</p>
<blockquote>
<p>  Traveling Salesperson Problem</p>
</blockquote>
</li>
</ul>
<h1 id="Graph-connection-search-algorithm"><a href="#Graph-connection-search-algorithm" class="headerlink" title="Graph connection: search algorithm"></a>Graph connection: search algorithm</h1><p>Property: path or cut</p>
<p>Let there be a digraph G=(N,A) with s and t∈N. Only one of the following statements is valid:</p>
<p><em>i) there exists a path directed from s to t</em></p>
<p><em>ii) there exists a cut (Ns, Nt) such that s∈Ns and t∈Nt, and there exist no arcs being in accordance with the cut, that is to say all arcs (i,j)∈A crossing the cut have i∈Nt and j∈Ns</em></p>
<p>A simple but extremely important algorithm is the one performing the search of digraph G starting from a root node s. The algorithm restores a vector of predecessors. The predecessor P[i] of a node i provides the immediately preceding node i in the path directed from s to i. If at the end of the algorithm a node has predecessor equal to zero, this means that the node is not reachable from r.</p>
<p>Algorithms</p>
<pre><code>Procedure Search (G=(N,A),s,P): 
    begin
        for i := 1 to n do P[i] :=0; P[s] := s; Q := {s}; 
        {initialization, s is the start point} 
        repeat
            select i from Q; Q:=Q\{i};     
            {selection and removal of a node from Q} 
            for each (i,j) ∈ FS(i) do
                if P[j]=0
                    then 
                        begin P[j]:=i; 
                        Q:=Q∪{j}
                    end; 
        until Q = ø
    end
</code></pre><h1 id="Shortest-Paths"><a href="#Shortest-Paths" class="headerlink" title="Shortest Paths"></a>Shortest Paths</h1><ul>
<li>Shortest-path tree algorithm on acyclic graphs<blockquote>
<p>  Let there be an acyclic weighted digraph G=(N,A). Note that both application examples seen above give rise to a graph of this type. In order to verify whether a graph is acyclic, we just need to check if it is possible to renumber the graph nodes so that <em>if (i,j)∈A then i&lt;j</em>.</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>Procedure Topological_numbering(N,A,φ,x) 
    begin
        if ∃ i∈N: BS(i)=ø 
            {i is the root node, with no BS}
            then φ(i)=x; 
            Topological_numbering(N\{i}, A\FS(i),x+1)
        else if N≠ø 
            then return(&quot;Non-acyclic graph&quot;) 
    end.
</code></pre><blockquote>
<p>  From now on we assume G to be topologically numbered. Wishing to find the shortest-path tree with root 1, we can proceed by induction. We associate with each node i a label d[i] providing the length of the shortest path from 1 to i. A possible algorithm proceeds according to the following inductive rule:</p>
<p>  d[1] = 0;</p>
<p>  d[k] = min {d[i] + c_ik, i=1,…,k-1}, k=2,…,n.</p>
</blockquote>
<ul>
<li>Shortest-path tree algorithm on acyclic graphs (II)<blockquote>
<p>  A further and equivalent method visits the forward stars of each node. In this case, node labels are gradually updated as a better route is found. At the beginning, except for node 1 whose label is definitively fixed at value 0, labels are set equal to a very high value, such that any path from 1 to the node in question is shorter than that value.</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>    Procedure SPT_Acyclic (P,d) 
        begin
            P[1]:=1; d[1]:=0; 
            {P note the BS ndoe and d note the cost from root to this node}
            for i:=2 to n 
                do 
                    begin 
                        P[i]:=1; 
                        d[i]:=M 
                    end; 
            {Initialization}

            for i:=1 to n-1 do
                for each (i,j)∈FS(i) 
                    do
                        if d[i]+cij &lt; d[j] 
                            then 
                                begin 
                                    P[j]:=i; 
                                    d[j]:=d[i]+cij 
                                end
        end
</code></pre><ul>
<li>Dijkstra’s algorithm<blockquote>
<p>  We are now going to present an algorithm which, under appropriate hypotheses, behaves like SPT_Acyclic on non-acyclic graphs as well. The algorithm uses a set Q into which are introduced nodes whose forward star must be explored. <strong>Initially Q contains only the root node. Every time a node label is updated, the node, if not already there, is introduced into Q. The key instruction of the algorithm is the selection from Q of the node from which the graph search is to be continued. In the case of the SPT_Acyclic algorithm nodes were examined according to the topological ordering given by the numbering. In order to have the certainty of a similar behavior, and in particular the certainty that an examined node will never be introduced into Q again, the algorithm examines each time the node i having the smallest d[i] label.</strong></p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>    Procedure SPT_Dijkstra (r,P,d) 
        begin
            for i:=1 to n 
                do 
                    begin 
                        P[i]:=r; 
                        d[i]:=M;
                        {P note the BS node and d note the distance to this node}
                        {M is a relative big value, to be more specific, infinite}
                    end; 
            d[r]:=0; Q:={r}; 
            {initialization} 
        repeat
            select i from Q such that d[i]=min{d[h]: h∈Q}; 
            {smallest label node is selected} 
            Q:=Q\{i};
            for each (i,j)∈FS(i) 
                do
                    if d[i]+cij &lt; d[j] 
                        then
                            begin 
                                P[j]:=i; 
                                d[j]:=d[i]+cij; 
                                if j∈Q 
                                    then Q:=Q∪{j} 
                                end 
        until Q=∅
end.
</code></pre><ul>
<li>SPT_L (label correcting) algorithm<blockquote>
<p>  If the graph is not acyclic and some of the lengths associated with arcs are negative, the properties seen above do not hold any more. In particular, it is not necessarily true that a node, once selected from  Q, cannot enter it again.</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>    Procedure SPT_L (r,P,d) 
        begin
            for i:=1 to n 
                do begin P[i]:=r; d[i]:=M end; d[r]:=0; 
            {Initialization}
            repeat
                select i from Q; Q:=Q\{i}; 
                {insertions into and selections from Q are performed according to a FIFO policy} 
                {(Q is a queue)}
                for each (i,j)∈FS(i) do
                    if d[i]+cij &lt; d[j] then
                        begin
                            P[j]:=i; d[j]:=d[i]+cij; 
                            Q:=Q∪{j} 
                        end
            until Q=∅ end.
</code></pre><h1 id="Maximum-Flow"><a href="#Maximum-Flow" class="headerlink" title="Maximum Flow"></a>Maximum Flow</h1><p>Properties of flows and cuts</p>
<p>A partition of the nodes into two subsets (Ns,Nt) such that s∈Ns, and t∈Nt, is called s-t cut. The arcs crossing the cut (having one endpoint in Ns and the other in Nt) are themselves partitioned into two subsets: the set of direct arcs A+(Ns,Nt)={(i,j)∈A: i∈Ns,j∈Nt}, and the set of inverse arcs A- (Ns,Nt)={(i j)∈A: i∈Nt,j∈Ns}.</p>
<p>x(Ns,Nt)= ∑ xij((i,j)belongs to A+)– ∑ xij((i,j)belongs to A-).</p>
<ul>
<li>Augmenting path algorithm<br>We try to solve the problem incrementally: given a feasible flow, we test if it is improvable, i.e., if there exists a way of routing more flow from s to t. In order to discover if such flow augmentation is practicable, we introduce the residual graph of a flow x’. Given a graph G=(N,A) with capacity on the arcs u and a feasible flow x’, we define the residual graph GR(x’) = (N,A(x’)), where arcs are defined as follows:</li>
</ul>
<blockquote>
<p>  A(x’) = A+(x’) ∪ A-(x’),</p>
<p>  A+(x’) = {(i,j): (i,j)∈A, xij’&lt;uij}     // could increased</p>
<p>  A-(x’) = {(i,j): (j,i)∈A, xji’&gt;0}.      // could decreased</p>
</blockquote>
<p>Given a feasible flow x’, consider the residual graph GR(x’). Searching for a path from s to t, corresponding to a possible flow augmentation, two exclusive cases may occur:</p>
<p><em>i) there exists a path from s to t in GR(x’);</em></p>
<p><em>ii) there exists a cut (Ns,Nt) in GR(x’) such that A-(x’)(Ns,Nt) = ∅.</em></p>
<p>In the first case the flow x’ is not optimal and it can be increased by a strictly positive quantity, whereas in the second case x’ is optimal.</p>
<p>In the first case we found an augmenting path (on which the flow can be varied without violating the capacity constraints). Let Pst be such path. Now we define the maximum quantity of flow θ that can be sent on the detected path and that is defined by the minimum of residual capacities of the corresponding arcs on the original graph:</p>
<blockquote>
<p>  θ is the minimum value of the uij-x’ij : (i,j)∈A + (x’) intersect with Pst and x’ij: (i,j)∈A-(x’) intersect with Pst</p>
</blockquote>
<h1 id="Minimum-Cost-Flow"><a href="#Minimum-Cost-Flow" class="headerlink" title="Minimum Cost Flow"></a>Minimum Cost Flow</h1><p>The minimum cost flow problem is a problem of optimization on networks of a more general kind: both the maximum flow problem and the shortest-path tree problem may be viewed as particular cases of the minimum cost flow problem. A network flow is specified by a digraph G=(N,A); with each node i∈N we associate a value bi (called balance of the node); with each arc (i,j) we associate the unit cost cij and a capacity uij limiting the maximum quantity of flow that can transit. Balances at nodes regulate the flow on the network.</p>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Graphs </tag>
            
            <tag> Network Flows </tag>
            
            <tag> Algorithms </tag>
            
            <tag> Foundations of Operations Research </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo Writing Formulation]]></title>
      <url>/2017/12/28/Hexo-Writing-Formulation/</url>
      <content type="html"><![CDATA[<p>This is a writing test for HEXO under the theme of material</p>
<h1 id="Block-Quote"><a href="#Block-Quote" class="headerlink" title="Block Quote"></a>Block Quote</h1><ul>
<li>Block without source<pre><code>{% blockquote %}
    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.
    {% endblockquote %}
</code></pre><blockquote><p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.</p>
</blockquote>
</li>
</ul>
<ul>
<li>Block with source<pre><code>{% blockquote David Levithan, Wide Awake %}
    Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy.
    {% endblockquote %}
</code></pre><blockquote><p>Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy.</p>
<footer><strong>David Levithan</strong><cite>Wide Awake</cite></footer></blockquote>
</li>
</ul>
<h1 id="Quote-from-Twitter"><a href="#Quote-from-Twitter" class="headerlink" title="Quote from Twitter"></a>Quote from Twitter</h1><pre><code>    {% blockquote @DevDocs https://twitter.com/devdocs/status/356095192085962752 %}
    NEW: DevDocs now comes with syntax highlighting. http://devdocs.io
    {% endblockquote %}
</code></pre><blockquote><p>NEW: DevDocs now comes with syntax highlighting. <a href="http://devdocs.io" target="_blank" rel="noopener">http://devdocs.io</a></p>
<footer><strong>@DevDocs</strong><cite><a href="https://twitter.com/devdocs/status/356095192085962752" target="_blank" rel="noopener">twitter.com/devdocs/status/356095192085962752</a></cite></footer></blockquote>
<h1 id="Quote-from-other-resource"><a href="#Quote-from-other-resource" class="headerlink" title="Quote from other resource"></a>Quote from other resource</h1><pre><code>    {% blockquote Seth Godin http://sethgodin.typepad.com/seths_blog/2009/07/welcome-to-island-marketing.html Welcome to Island Marketing %}
    Every interaction is both precious and an opportunity to delight.
    {% endblockquote %}
</code></pre><blockquote><p>Every interaction is both precious and an opportunity to delight.</p>
<footer><strong>Seth Godin</strong><cite><a href="http://sethgodin.typepad.com/seths_blog/2009/07/welcome-to-island-marketing.html" target="_blank" rel="noopener">Welcome to Island Marketing</a></cite></footer></blockquote>
<h1 id="Quote-an-Image-from-default-path"><a href="#Quote-an-Image-from-default-path" class="headerlink" title="Quote an Image from default path"></a>Quote an Image from default path</h1><pre><code>{% asset_img example.png This is an example image %}
</code></pre><img src="/2017/12/28/Hexo-Writing-Formulation/example.png" title="This is an example image">
<h1 id="Paragraph"><a href="#Paragraph" class="headerlink" title="Paragraph"></a>Paragraph</h1><pre><code>&gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,
&gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.
&gt;
&gt; &gt; And Here is a nested quote block.
&gt;
&gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.
&gt; 
&gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse
&gt; id sem consectetuer libero luctus adipiscing.
</code></pre><blockquote>
<p>This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,<br>consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.</p>
<blockquote>
<p>And Here is a nested quote block.</p>
</blockquote>
<p>Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.</p>
<p>Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse<br>id sem consectetuer libero luctus adipiscing.</p>
</blockquote>
<h1 id="Unorder-List-Item"><a href="#Unorder-List-Item" class="headerlink" title="Unorder List Item"></a>Unorder List Item</h1><pre><code>*   This is a list item with two paragraphs.

    This is the second paragraph in the list item. You&#39;re
only required to indent the first line. Lorem ipsum dolor
sit amet, consectetuer adipiscing elit.

*   Another item in the same list.

    &gt; This is a quote.
</code></pre><ul>
<li><p>This is a list item with two paragraphs.</p>
<p>This is the second paragraph in the list item. You’re<br>only required to indent the first line. Lorem ipsum dolor<br>sit amet, consectetuer adipiscing elit.</p>
</li>
<li><p>Another item in the same list.</p>
<blockquote>
<p>This is a quote.</p>
</blockquote>
</li>
</ul>
<h1 id="Strongthen-text"><a href="#Strongthen-text" class="headerlink" title="Strongthen text"></a>Strongthen text</h1><pre><code>*single asterisks*

_single underscores_

**double asterisks**

__double underscores__
</code></pre><p><em>single asterisks</em></p>
<p><em>single underscores</em></p>
<p><strong>double asterisks</strong></p>
<p><strong>double underscores</strong></p>
<h1 id="Attach-a-link"><a href="#Attach-a-link" class="headerlink" title="Attach a link"></a>Attach a link</h1><pre><code>[Cesare&#39;s Homepage](https://cesaremjli.github.io/)
</code></pre><p><a href="https://cesaremjli.github.io/" target="_blank" rel="noopener">Cesare’s Homepage</a></p>
]]></content>
      
        
        <tags>
            
            <tag> Markdown Language </tag>
            
            <tag> HEXO </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Binary Trees]]></title>
      <url>/2017/12/19/Binary-Trees/</url>
      <content type="html"><![CDATA[<p>A short introduction of binary trees and its use in Python.</p>
<h1 id="Description-of-the-binary-tree-problems"><a href="#Description-of-the-binary-tree-problems" class="headerlink" title="Description of the binary tree problems"></a>Description of the binary tree problems</h1><p><strong>Preorder Traversals</strong></p>
<p>Count the node whenever it is the first time you reach it</p>
<p><strong>Inorder Traversals</strong></p>
<p>Count the node in the order just like spanning all the nodes in the horizontal plane</p>
<blockquote>
<p><a href="https://leetcode.com/problems/binary-tree-inorder-traversal/description/" target="_blank" rel="noopener">Description of one situation</a>:</p>
<blockquote>
<p>Given a binary tree, return the inorder traversal of its nodes’ values.</p>
<ul>
<li>algorithm</li>
</ul>
</blockquote>
</blockquote>
<pre><code>class TreeNode(object):
    def __init__(self, x):
        self.val = x
        self.left = None
        self.right = None

class Solution(object):
    def inorderTraversal(self, root):
        &quot;&quot;&quot;
        :type root: TreeNode
        :rtype: List[int]
        &quot;&quot;&quot;
        # curNode=root
        res=[1]
        curNode=root
        while curNode!=None:
            if curNode.left==None:
                res.append(curNode.val)
                print curNode.val
                curNode=curNode.right
            else:
                thisNode=curNode
                curNode=curNode.left
                nextNode=curNode
                while nextNode.right!=None:
                    nextNode=nextNode.right
                nextNode.right=thisNode
                thisNode.left=None
        return res[1:]
</code></pre><blockquote>
<p><a href="https://leetcode.com/problems/validate-binary-search-tree/description/" target="_blank" rel="noopener">Description of another situation</a>:</p>
<blockquote>
<p>Given a binary tree, determine if it is a valid binary search tree (BST).<br>Assume a BST is defined as follows:</p>
<ul>
<li>The left subtree of a node contains only nodes with keys less than the node’s key.</li>
<li>The right subtree of a node contains only nodes with keys greater than the node’s key.</li>
<li>Both the left and right subtrees must also be binary search trees.</li>
<li>algorithm</li>
</ul>
</blockquote>
</blockquote>
<pre><code>class TreeNode(object):
    def __init__(self, x):
        self.val = x
        self.left = None
        self.right = None

class Solution(object):
    def isValidBST(self, root):
        &quot;&quot;&quot;
        :type root: TreeNode
        :rtype: bool
        &quot;&quot;&quot;
        stack=[]
        pre=None
        cur=root
        while stack or cur:
            while cur:
                stack.append(cur)
                cur=cur.left
            top=stack.pop()
            if pre is not None and pre&gt;=top.val:
                return False
            pre=top.val
            cur=top.right
        return True
</code></pre><p><strong>Postorder Traversals</strong></p>
<p>Count the node whenever it is the last time  you leave it</p>
]]></content>
      
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> Binary Trees </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python List]]></title>
      <url>/2017/12/09/Python-List/</url>
      <content type="html"><![CDATA[<p>This journal aims to describe a problem of PYTHON LIST. </p>
<p>The decription of the problem could be found <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/description/" target="_blank" rel="noopener">here</a> from LEETCODE.</p>
<h1 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h1><p>Given a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list.</p>
<p>For example,<br>Given 1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5, return 1-&gt;2-&gt;5.<br>Given 1-&gt;1-&gt;1-&gt;2-&gt;3, return 2-&gt;3.</p>
<h1 id="CODE"><a href="#CODE" class="headerlink" title="CODE"></a>CODE</h1><pre><code># Definition for singly-linked list.
# class ListNode(object):
#     def __init__(self, x):
#         self.val = x
#         self.next = None

class Solution(object):
    def deleteDuplicates(self, head):
        &quot;&quot;&quot;
        :type head: ListNode
        :rtype: ListNode
        &quot;&quot;&quot;
        dummyHead=ListNode(0)
        dummyHead.next=head
        curNode=dummyHead

        while curNode!=None:
            nextNode=curNode.next
            if nextNode!=None and nextNode.next!=None and nextNode.val==nextNode.next.val:
                while nextNode!=None and nextNode.next!=None and nextNode.val==nextNode.next.val:
                    nextNode=nextNode.next
                # lastNode.next=nextNode.next
                curNode.next=nextNode.next;
            else:
                curNode=curNode.next

        return dummyHead.next
</code></pre>]]></content>
      
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> List </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unity Development Journal]]></title>
      <url>/2017/12/03/Unity-Development-Journal/</url>
      <content type="html"><![CDATA[<p>This journal aims to record the interesting methods and functions used in the <strong>Unity Game Development</strong>.</p>
<h1 id="Useful-External-Links"><a href="#Useful-External-Links" class="headerlink" title="Useful External Links"></a>Useful External Links</h1><p><a href="https://docs.unity3d.com/ScriptReference/index.html" target="_blank" rel="noopener">Unity Scripting API</a>: Unity official programmer API</p>
<p><a href="https://docs.unity3d.com/Manual/index.html" target="_blank" rel="noopener">Unity User Manual</a>: Unity official user manual</p>
<p><a href="https://cowlevel.net/feed" target="_blank" rel="noopener">Cow Level</a>: Game news and evaluations</p>
<p><a href="https://www.indienova.com/" target="_blank" rel="noopener">Indie Nova</a>: Game developments</p>
<h1 id="Unity-Development-Process"><a href="#Unity-Development-Process" class="headerlink" title="Unity Development Process"></a>Unity Development Process</h1><blockquote>
<p><em>Player</em></p>
<ul>
<li>Player Tranforms</li>
</ul>
</blockquote>
<pre class=" language-css"><code class="language-css">    <span class="token selector">void Start () 
    </span><span class="token punctuation">{</span>
        // Debug<span class="token number">.</span>Log <span class="token punctuation">(</span><span class="token string">"I AM "</span> + gameObject<span class="token number">.</span>name<span class="token punctuation">)</span><span class="token punctuation">;</span>

        _transform = GetComponent&lt;Transform><span class="token punctuation">(</span><span class="token punctuation">)</span> as Transform<span class="token punctuation">;</span>
        _animator = GetComponent&lt;Animator><span class="token punctuation">(</span><span class="token punctuation">)</span> as Animator<span class="token punctuation">;</span>
        _rigidbody = GetComponent&lt;Rigidbody<span class="token number">2</span>D><span class="token punctuation">(</span><span class="token punctuation">)</span> as Rigidbody<span class="token number">2</span>D<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token selector">void Update () 
    </span><span class="token punctuation">{</span>    
        <span class="token selector">m_horizontal = Math<span class="token class">.Sign</span>(Input<span class="token class">.GetAxis</span> ("Horizontal"));
        m_vertical = Math<span class="token class">.Sign</span>(Input<span class="token class">.GetAxis</span> ("Vertical"));    

        _transform<span class="token class">.position</span> = _transform<span class="token class">.position</span> +
            _transform<span class="token class">.right</span> * m_horizontal * m_speed * Time<span class="token class">.deltaTime</span> +
            _transform<span class="token class">.up</span> * m_vertical * m_speed * Time<span class="token class">.deltaTime</span>;

        if (Input<span class="token class">.GetKeyDown</span>(KeyCode<span class="token class">.J</span>))
        </span><span class="token punctuation">{</span>
            <span class="token comment" spellcheck="true">/* Whenever it detects some key on the keyboard, do Something */</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
</code></pre>
<blockquote>
<p><em>Animation</em> </p>
</blockquote>
<pre><code>Firstly, add an animation controller in the object to be attached with an animation.
Then drag the animation controller on to the game object
</code></pre><ul>
<li>Transition Control<pre class=" language-css"><code class="language-css">_animator<span class="token number">.</span><span class="token function">SetInteger</span><span class="token punctuation">(</span><span class="token string">"ParameterName"</span>,n<span class="token punctuation">)</span><span class="token punctuation">;</span>
_animator<span class="token number">.</span><span class="token function">SetBoolean</span><span class="token punctuation">(</span><span class="token string">"ParameterName"</span>,true/false<span class="token punctuation">)</span><span class="token punctuation">;</span>
_animator<span class="token number">.</span><span class="token function">SetTrigger</span><span class="token punctuation">(</span><span class="token string">"ParameterName"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
</li>
</ul>
<blockquote>
<p><em>Game Object</em></p>
<ul>
<li>Instantiate Prefabs</li>
</ul>
</blockquote>
<pre><code>We could create game objects according to the predefined game objects. 
First create an empty game object, and then attach this scripts into this
game object.
</code></pre><pre class=" language-css"><code class="language-css">    <span class="token selector">public class InstantiateObj : MonoBehaviour </span><span class="token punctuation">{</span>

    <span class="token selector">public Transform prefab;

    public float timeDif=0<span class="token class">.5f</span>;
    private float nextTime;

    void Start () </span><span class="token punctuation">{</span>
        nextTime=<span class="token number">0.0</span>f<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token selector">void Update () </span><span class="token punctuation">{</span>
        <span class="token selector">if(Time<span class="token class">.time</span>>nextTime)</span><span class="token punctuation">{</span>
            <span class="token function">Instantiate</span><span class="token punctuation">(</span>prefab<span class="token punctuation">)</span><span class="token punctuation">;</span>
            nextTime=nextTime+timeDif<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<blockquote>
<p><em>Sound Manager</em></p>
</blockquote>
<pre><code>Create an empty game object, and then add the sound scripts into the inspector, 
and then add different sound source and sound clips into the object. Meanwhile
we always put the audio listener onto the main camera.
</code></pre><ul>
<li><p>Sound Manager Scripts</p>
<pre class=" language-css"><code class="language-css"><span class="token selector">public class SoundManager : MonoBehaviour </span><span class="token punctuation">{</span>

<span class="token selector">public static SoundManager Instance;

<span class="token attribute">[Header("Sound Source")]</span>
public AudioSource as;
public AudioClip ac;
public AudioClip ac2;

<span class="token attribute">[Header("Soundtrack")]</span>
public AudioSource as_bgm_future;
public AudioClip ac_bgm_future;

<span class="token attribute">[Header("Soundtrack")]</span>
public AudioSource as_bgm_past;
public AudioClip ac_bgm_past;

float timeStamp;

// Use this for initialization
void Awake () </span><span class="token punctuation">{</span>
    <span class="token selector">if (Instance == null)
    </span><span class="token punctuation">{</span>
        Instance = this<span class="token punctuation">;</span>
        <span class="token function">DontDestroyOnLoad</span><span class="token punctuation">(</span>gameObject<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token selector">else
    </span><span class="token punctuation">{</span>
        <span class="token function">Destroy</span><span class="token punctuation">(</span>gameObject<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token selector">void Start()</span><span class="token punctuation">{</span>
    as_bgm_future<span class="token number">.</span>clip = ac_bgm_future<span class="token punctuation">;</span>
    as_bgm_past<span class="token number">.</span>clip = ac_bgm_past<span class="token punctuation">;</span>
    as_bgm_future<span class="token number">.</span><span class="token function">Play</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token selector">public void PlayeOneTime()</span><span class="token punctuation">{</span>
    as<span class="token number">.</span><span class="token function">PlayOneShot</span><span class="token punctuation">(</span>ac<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token selector">public void SwitchBGMandPitch(bool flag)</span><span class="token punctuation">{</span>
    <span class="token selector">as_bgm_past<span class="token class">.pitch</span>=1<span class="token class">.0f</span>;
    as_bgm_future<span class="token class">.pitch</span>=1<span class="token class">.0f</span>;
    if (flag)</span><span class="token punctuation">{</span>
        as_bgm_past<span class="token number">.</span><span class="token function">Pause</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        as_bgm_future<span class="token number">.</span><span class="token function">Play</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span class="token selector">else</span><span class="token punctuation">{</span>
        as_bgm_future<span class="token number">.</span><span class="token function">Pause</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        as_bgm_past<span class="token number">.</span><span class="token function">Play</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>    
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
</li>
<li>Whenever it is used in another scripts<pre class=" language-css"><code class="language-css">SoundManager<span class="token number">.</span>Instance<span class="token number">.</span><span class="token function">FutureTravelToPast</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
</li>
</ul>
<blockquote>
<p><em>Camera</em></p>
<ul>
<li>Camera Following</li>
</ul>
</blockquote>
<pre class=" language-css"><code class="language-css"><span class="token selector">public class CameraFollow : MonoBehaviour </span><span class="token punctuation">{</span>
    <span class="token selector">public GameObject player;
    private Vector3 offset;

    void Start () </span><span class="token punctuation">{</span>
        // offset = transform<span class="token number">.</span>position - player<span class="token number">.</span>transform<span class="token number">.</span>position<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token selector">void Update () </span><span class="token punctuation">{</span>
        Vector<span class="token number">3</span> playerPosition =player<span class="token number">.</span>transform<span class="token number">.</span>position<span class="token punctuation">;</span>
        // transform<span class="token number">.</span>position = player<span class="token number">.</span>transform<span class="token number">.</span>position + offset<span class="token punctuation">;</span>
        // if <span class="token punctuation">(</span>playerPosition<span class="token number">.</span>x&lt;-<span class="token number">2.3</span><span class="token punctuation">)</span>
        //     return<span class="token punctuation">;</span>
        transform<span class="token number">.</span>position = new Vector<span class="token number">3</span><span class="token punctuation">(</span>playerPosition<span class="token number">.</span>x,<span class="token number">0</span>,-<span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<h1 id="Some-Tricks"><a href="#Some-Tricks" class="headerlink" title="Some Tricks"></a>Some Tricks</h1><blockquote>
<ol>
<li>The image size of the animation must by unified. Or some effects terrible would happen. All the images must by saved in .png with a tranparent background</li>
<li>Generally speaking, it is always a good idea to put <em>Player</em>, <em>Camera</em>, <em>Sound Manager</em> in a empty game object to manage them.</li>
</ol>
</blockquote>
<h2 id="Cesare-Dec-3-2017"><a href="#Cesare-Dec-3-2017" class="headerlink" title="Cesare Dec 3 2017"></a>Cesare Dec 3 2017</h2>]]></content>
      
        
        <tags>
            
            <tag> Unity </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[A Simple Python Depth First Search]]></title>
      <url>/2017/11/30/A-Simple-Python-Depth-First-Search/</url>
      <content type="html"><![CDATA[<p>Depth First Search in some real problems.</p>
<h1 id="Description-of-8-queens-Problem"><a href="#Description-of-8-queens-Problem" class="headerlink" title="Description of 8-queens Problem"></a>Description of 8-queens Problem</h1><p>Here is the description of <a href="https://leetcode.com/problems/n-queens/description/" target="_blank" rel="noopener">8-QUEEN PROBLEM</a>.</p>
<p>The n-queens puzzle is the problem of placing n queens on an n×n chessboard such that no two queens attack each other.</p>
<p>Given an integer n, return all distinct solutions to the n-queens puzzle.</p>
<p>Each solution contains a distinct board configuration of the n-queens’ placement, where ‘Q’ and ‘.’ both indicate a queen and an empty space respectively</p>
<h1 id="Solution-in-python-DFS"><a href="#Solution-in-python-DFS" class="headerlink" title="Solution(in python - DFS)"></a>Solution(in python - DFS)</h1><pre><code>    class Solution(object):
        def solveNQueens(self, n):
            &quot;&quot;&quot;
            :type n: int
            :rtype: List[List[str]]
            &quot;&quot;&quot;
            def DFS(queens, xy_dif,xy_sum):
                l=len(queens)
                if l==n:
                    result.append(queens)
                    return None
                for p in range(n):
                    if p not in queens and l-p not in xy_dif and l+p not in xy_sum:
                        DFS(queens+[p],xy_dif+[l-p],xy_sum+[l+p])
            result=[]
            DFS([],[],[])
            print result
            return [[&#39;.&#39;*i+&#39;Q&#39;+&#39;.&#39;*(n-i-1) for i in sol]for sol in result]
</code></pre>]]></content>
      
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> Depth First Search </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
