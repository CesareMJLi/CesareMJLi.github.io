<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[Computer Graphics Assignment]]></title>
      <url>/2019/06/13/Computer-Graphics-Assignment/</url>
      <content type="html"><![CDATA[<p>Identity Matrix:<br>var I = [   [1.0, 0.0, 0.0, 0.0],<br>            [0.0, 1.0, 0.0, 0.0],<br>            [0.0, 0.0, 1.0, 0.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h1 id="Assignment-1-OK"><a href="#Assignment-1-OK" class="headerlink" title="Assignment 1 OK"></a>Assignment 1 OK</h1><h1 id="Assignment-2-OK"><a href="#Assignment-2-OK" class="headerlink" title="Assignment 2 OK"></a>Assignment 2 OK</h1><h2 id="Translate-of-3-on-x-axis-5-on-z-axis"><a href="#Translate-of-3-on-x-axis-5-on-z-axis" class="headerlink" title="Translate of +3 on x-axis, -5 on z axis"></a>Translate of +3 on x-axis, -5 on z axis</h2><p>var I = [  [1.0, 0.0, 0.0, 3.0],<br>            [0.0, 1.0, 0.0, 0.0],<br>            [0.0, 0.0, 1.0, -5.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h2 id="Rotate-of-30-on-the-y-axis"><a href="#Rotate-of-30-on-the-y-axis" class="headerlink" title="Rotate of 30 on the y-axis"></a>Rotate of 30 on the y-axis</h2><p>var I = [  [0.866, 0.0, 0.5, 3.0],<br>            [0.0, 1.0, 0.0, 0.0],<br>            [-0.5, 0.0, 0.866, -5.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h2 id="Make-the-starship-2-times-bigger"><a href="#Make-the-starship-2-times-bigger" class="headerlink" title="Make the starship 2 times bigger"></a>Make the starship 2 times bigger</h2><p>var I = [   [2.0, 0.0, 0.0, 0.0],<br>            [0.0, 2.0, 0.0, 0.0],<br>            [0.0, 0.0, 2.0, 0.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h2 id="Make-the-starship-1-5-times-longer-on-x-axis-half-on-the-other-axis"><a href="#Make-the-starship-1-5-times-longer-on-x-axis-half-on-the-other-axis" class="headerlink" title="Make the starship 1.5 times longer on x-axis, half on the other axis"></a>Make the starship 1.5 times longer on x-axis, half on the other axis</h2><p>var I = [   [1.5, 0.0, 0.0, 0.0],<br>            [0.0, 0.5, 0.0, 0.0],<br>            [0.0, 0.0, 0.5, 0.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h2 id="Mirror-over-yz-plane"><a href="#Mirror-over-yz-plane" class="headerlink" title="Mirror over yz-plane"></a>Mirror over yz-plane</h2><p>var I = [   [-1, 0.0, 0.0, 0.0],<br>            [0.0, 1.0, 0.0, 0.0],<br>            [0.0, 0.0, 1.0, 0.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h2 id="Mirror-over-yz-plane-1"><a href="#Mirror-over-yz-plane-1" class="headerlink" title="Mirror over yz-plane"></a>Mirror over yz-plane</h2><p>var I = [   [-1, 0.0, 0.0, 0.0],<br>            [0.0, 1.0, 0.0, 0.0],<br>            [0.0, 0.0, 1.0, 0.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h2 id="Flatten-over-zx-plane"><a href="#Flatten-over-zx-plane" class="headerlink" title="Flatten over zx-plane"></a>Flatten over zx-plane</h2><p>var I = [   [1.0, 0.0, 0.0, 0.0],<br>            [0.0, 0.0, 0.0, 0.0],<br>            [0.0, 0.0, 1.0, 0.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h2 id="Shear-along-the-x-axis-by-a-factor-of-1-along-the-y-axis"><a href="#Shear-along-the-x-axis-by-a-factor-of-1-along-the-y-axis" class="headerlink" title="Shear along the x-axis, by a factor of 1 along the y-axis"></a>Shear along the x-axis, by a factor of 1 along the y-axis</h2><p>var I = [   [1.0, 0.0, 0.0, 0.0],<br>            [1.0, 1.0, 0.0, 0.0],<br>            [0.0, 0.0, 1.0, 0.0],<br>            [0.0, 0.0, 0.0, 1.0]]</p>
<h1 id="Assignment-3-OK"><a href="#Assignment-3-OK" class="headerlink" title="Assignment 3 OK"></a>Assignment 3 OK</h1><h2 id="Rotate-30-degrees-around-an-arbitrary-axis-passing-through-1-1-0-The-x-axis-can-be-aligned-to-the-arbitrary-axis-after-a-rotation-of-15-degrees-around-the-z-axis-and-then-45-degrees-around-the-y-axis"><a href="#Rotate-30-degrees-around-an-arbitrary-axis-passing-through-1-1-0-The-x-axis-can-be-aligned-to-the-arbitrary-axis-after-a-rotation-of-15-degrees-around-the-z-axis-and-then-45-degrees-around-the-y-axis" class="headerlink" title="Rotate 30 degrees around an arbitrary axis passing through (1,1,0). The x-axis can be aligned to the arbitrary axis after a rotation of 15 degrees around the z-axis, and then 45 degrees around the y-axis."></a>Rotate 30 degrees around an arbitrary axis passing through (1,1,0). The x-axis can be aligned to the arbitrary axis after a rotation of 15 degrees around the z-axis, and then 45 degrees around the y-axis.</h2><p>R1 =T(1,1,0)R(y,45)R(z,15)R(x,30)R(z,-15)R(y,-45)T(-1,-1,0)</p>
<pre><code>var R1 =  [0.926,        0.365,        0.067,        -0.294,
           -0.318,        0.875,        -0.365,        0.443,
           -0.192,        0.318,        0.929,        -0.126,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="Double-the-size-of-an-object-using-as-fixed-point-1-1-0"><a href="#Double-the-size-of-an-object-using-as-fixed-point-1-1-0" class="headerlink" title="Double the size of an object, using as fixed point (1,1,0)"></a>Double the size of an object, using as fixed point (1,1,0)</h2><p>S1 =T(1,1,0)S(2,2,2)T(-1,-1,0)</p>
<pre><code>var S1 =  [1.0,        0.0,        0.0,        0.0,
           0.0,        1.0,        0.0,        0.0,
           0.0,        0.0,        1.0,        0.0,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="Mirror-the-starship-along-a-plane-passing-through-1-2-0-and-obtained-rotating-38-degree-around-the-y-axis-the-xy-plane"><a href="#Mirror-the-starship-along-a-plane-passing-through-1-2-0-and-obtained-rotating-38-degree-around-the-y-axis-the-xy-plane" class="headerlink" title="Mirror the starship along a plane passing through (1,2,0), and obtained rotating 38 degree around the y axis the xy plane"></a>Mirror the starship along a plane passing through (1,2,0), and obtained rotating 38 degree around the y axis the xy plane</h2><p>S2 = T(1,2,0)R(y,38)Mirror(xy)R(y,-38)T(-1,-2,0)</p>
<pre><code>var S2 =  [0.242,        0.0,        -0.970,        0.758,
           0.0,        1.0,        0.0,        0.0,
           -0.970,        0.0,        0.242,        0.970,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="The-ship-has-been-doubled-in-size-rotated-45-degrees-around-the-x-axis-30-degrees-around-the-y-axis-and-moved-to-1-1-2-Return-the-ship-in-its-original-position"><a href="#The-ship-has-been-doubled-in-size-rotated-45-degrees-around-the-x-axis-30-degrees-around-the-y-axis-and-moved-to-1-1-2-Return-the-ship-in-its-original-position" class="headerlink" title="The ship has been doubled in size, rotated 45 degrees around the x axis, 30 degrees around the y axis, and moved to (1,1,-2). Return the ship in its original position"></a>The ship has been doubled in size, rotated 45 degrees around the x axis, 30 degrees around the y axis, and moved to (1,1,-2). Return the ship in its original position</h2><p>I1 = S(0.5,0.5,0.5)R(x,-45)R(y,-30)T(-1,-1,2)</p>
<pre><code>var I1 =  [0.433,        0.0,        -0.25,        -0.933,
           0.177,        0.354,        0.306,        0.082,
           0.167,        -0.354,        0.306,        0.789,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h1 id="Assignment-4-OK"><a href="#Assignment-4-OK" class="headerlink" title="Assignment 4 OK"></a>Assignment 4 OK</h1><h2 id="Parallel-By-the-given-information-in-the-assignment-below-calculate-by-w-a-f-n"><a href="#Parallel-By-the-given-information-in-the-assignment-below-calculate-by-w-a-f-n" class="headerlink" title="Parallel. By the given information in the assignment below. calculate by w,a,f,n"></a>Parallel. By the given information in the assignment below. calculate by w,a,f,n</h2><p>Other matrix are calculated by this matrix multiply with rotation</p>
<pre><code>var A =  [0.025,    0.0,        0.0,        0.0,
           0.0,        0.044,        0.0,        0.0,
           0.0,        0.0,        -0.02,        -1.02,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="Make-an-isometric-view-w-40-a-16-9-n-1-f-101"><a href="#Make-an-isometric-view-w-40-a-16-9-n-1-f-101" class="headerlink" title="Make an isometric view, w = 40, a = 16/9, n = 1, f = 101."></a>Make an isometric view, w = 40, a = 16/9, n = 1, f = 101.</h2><pre><code>var A1 =  [0.018,    0.0,        0.018,        0.0,
           0.018,        0.036,        -0.018,        0.0,
           0.012,        -0.012,        -0.012,        -1.02,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="Make-a-dimetric-view-w-40-a-16-9-n-1-f-101-rotated-20-around-the-x-axis"><a href="#Make-a-dimetric-view-w-40-a-16-9-n-1-f-101-rotated-20-around-the-x-axis" class="headerlink" title="Make a dimetric view, w = 40, a = 16/9, n = 1, f = 101, rotated 20 around the x-axis"></a>Make a dimetric view, w = 40, a = 16/9, n = 1, f = 101, rotated 20 around the x-axis</h2><pre><code>var A2 =  [0.018,    0.0,        0.018,        0.0,
           0.011,        0.041,        -0.011,        0.0,
           0.0133,        -0.007,        -0.133,        -1.02,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="Make-a-trimetric-view-w-40-a-16-9-n-1-f-101-rotated-30-around-the-x-axis-and-30-around-the-y-axis"><a href="#Make-a-trimetric-view-w-40-a-16-9-n-1-f-101-rotated-30-around-the-x-axis-and-30-around-the-y-axis" class="headerlink" title="Make a trimetric view, w = 40, a = 16/9, n = 1, f = 101, rotated -30 around the x-axis and 30 around the y-axis"></a>Make a trimetric view, w = 40, a = 16/9, n = 1, f = 101, rotated -30 around the x-axis and 30 around the y-axis</h2><pre><code>var A3 =  [0.022,    0.0,        0.0125,        0.0,
           -0.011,        0.038,        0.019,        0.0,
           0.009,        0.01,        -0.015,        -1.02,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="Make-an-cavalier-projection-view-w-40-a-16-9-n-1-f-101-at-45-degrees-【Matrix-with-Sheer】"><a href="#Make-an-cavalier-projection-view-w-40-a-16-9-n-1-f-101-at-45-degrees-【Matrix-with-Sheer】" class="headerlink" title="Make an cavalier projection view, w = 40, a = 16/9, n = 1, f = 101, at 45 degrees 【Matrix with Sheer】"></a>Make an cavalier projection view, w = 40, a = 16/9, n = 1, f = 101, at 45 degrees 【Matrix with Sheer】</h2><pre><code>var O1 =  [0.025,    0.0,        -0.018,        0.0,
           0.0,        0.044,        -0.031,        0.0,
           0.0,        0.0,        -0.02,        -1.02,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h2 id="Make-a-cabinet-projection-view-w-40-a-16-9-n-1-f-101-at-60-degrees"><a href="#Make-a-cabinet-projection-view-w-40-a-16-9-n-1-f-101-at-60-degrees" class="headerlink" title="Make a cabinet projection view, w = 40, a = 16/9, n = 1, f = 101, at 60 degrees"></a>Make a cabinet projection view, w = 40, a = 16/9, n = 1, f = 101, at 60 degrees</h2><pre><code>var O2 =  [0.025,    0.0,        -0.006,        0.0,
           0.0,        0.044,        -0.019,        0.0,
           0.0,        0.0,        -0.02,        -1.02,
           0.0,        0.0,        0.0,        1.0];
</code></pre><h1 id="Assignment-5-OK"><a href="#Assignment-5-OK" class="headerlink" title="Assignment 5 OK"></a>Assignment 5 OK</h1><h2 id="Build-a-Perspective-projection"><a href="#Build-a-Perspective-projection" class="headerlink" title="Build a Perspective projection"></a>Build a Perspective projection</h2><pre><code>var out = [1.0,        0.0,        0.0,        0.0,
           0.0,        1.0,        0.0,        0.0,
           0.0,        0.0,        -1.0,        -0.2,
           0.0,        0.0,        -1.0,        0.0];
</code></pre><h2 id="Build-a-perspective-projection-matrix-for-a-viewport-whose-size-is-determined-by-parameters-w-width-and-h-height-and-whose-fov-y-is-passed-in-parameter-fov-Near-plane-is-n-0-1-and-far-plane-f-100"><a href="#Build-a-perspective-projection-matrix-for-a-viewport-whose-size-is-determined-by-parameters-w-width-and-h-height-and-whose-fov-y-is-passed-in-parameter-fov-Near-plane-is-n-0-1-and-far-plane-f-100" class="headerlink" title="// Build a perspective projection matrix, for a viewport whose size is determined by parameters w (width) and h (height), and whose fov-y is passed in parameter fov. Near plane is n=0.1, and far plane f=100."></a>// Build a perspective projection matrix, for a viewport whose size is determined by parameters w (width) and h (height), and whose fov-y is passed in parameter fov. Near plane is n=0.1, and far plane f=100.</h2><p>Page-36</p>
<pre><code>var out = [h/(w*Math.tan(Math.PI*fov/360)),        0.0,        0.0,        0.0,
           0.0,        1.0/Math.tan(Math.PI*fov/360),        0.0,        0.0,
           0.0,        0.0,        -1.0,        -0.2,
           0.0,        0.0,        -1.0,        0.0];
</code></pre><h1 id="Assignment-6-KO"><a href="#Assignment-6-KO" class="headerlink" title="Assignment 6 KO"></a>Assignment 6 KO</h1><h1 id="Assignment-7-OK"><a href="#Assignment-7-OK" class="headerlink" title="Assignment 7 OK"></a>Assignment 7 OK</h1><h1 id="Assignment-8-OK"><a href="#Assignment-8-OK" class="headerlink" title="Assignment 8 OK"></a>Assignment 8 OK</h1><h1 id="Assignment-9-OK"><a href="#Assignment-9-OK" class="headerlink" title="Assignment 9 OK"></a>Assignment 9 OK</h1><h1 id="Assignment-10-OK"><a href="#Assignment-10-OK" class="headerlink" title="Assignment 10 OK"></a>Assignment 10 OK</h1><h1 id="Assignment-11-OK"><a href="#Assignment-11-OK" class="headerlink" title="Assignment 11 OK"></a>Assignment 11 OK</h1><h1 id="Assignment-12-OK"><a href="#Assignment-12-OK" class="headerlink" title="Assignment 12 OK"></a>Assignment 12 OK</h1>]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Computer Graphics </tag>
            
            <tag> Assignment </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[ROS学习笔记]]></title>
      <url>/2019/05/05/ROS%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="从小海龟说起"><a href="#从小海龟说起" class="headerlink" title="从小海龟说起"></a>从小海龟说起</h1><pre><code>roscore
rosrun turtlesim turtlesim_node 
rosrun turtlesim turtle_teleop_key
</code></pre><p>使用三个terminal分别使用以上三个指令可以创造一个可以用键盘控制的小海龟，三个终端的目的是为了让三条指令同时运行，在ROS中，所有的软件都组织成为<strong>包（软件包/功能包）</strong>的形式。比如在前面的代码中，turtlesim是一个包，而turtlesim_node以及turtle_teleop_key是turtlesim包中的可执行文件。所有的ROS软件都是一个软件包的一部分。</p>
<h1 id="查看软件包和定位软件包"><a href="#查看软件包和定位软件包" class="headerlink" title="查看软件包和定位软件包"></a>查看软件包和定位软件包</h1><pre><code>rospack list

rospack list | wc -l      
# 返回软件包的个数
</code></pre><p>每个包由一个package.xml定义，该文件定义关于包的细节，包含package.xml的目录成为软件包目录，</p>
<pre><code># rospack find package-name
# 找到一个包的目录，包的名称也可以用Tab键补全
rospack find turtlesim


# rosls package-name 
# 查看软件包目录下的文件
rosls turtlesim
rosls turtlesim/images

# roscd package-name
# 切换当前目录至此软件包目录下
roscd turtlesim/images/
eog box-turtle.png
</code></pre><h1 id="节点管理"><a href="#节点管理" class="headerlink" title="节点管理"></a>节点管理</h1><p>ROS的目标是使来自不同的程序员设计的<strong>节点</strong>同时运行，他们彼此几乎相互独立，但是我们又要求他们能够彼此通信，ROS中实现通信的关键部分就是ROS节点管理器，要启动节点管理器，使用如下命令</p>
<pre><code>roscore
</code></pre><p>在turtlesim中我们使用过这个命令，不带任何参数，也无需任何配置。节点管理器应该在使用ROS的全部时间内保持运行，我们需要先在terminal启动roscore然后运行其他程序，在其他程序均完成后，在roscore的终端输出Ctrl+c停止节点管理器。</p>
<h1 id="节点"><a href="#节点" class="headerlink" title="节点"></a>节点</h1><p>在turtlesim中，我们创建了两个节点</p>
<ol>
<li>节点一是turtlesim_node的实例化，这个节点创建turtlesim窗口和模拟海龟运动</li>
<li>节点二使turtle_teleop_key的实例化，这个节点捕捉键盘事件，并转换为运动命令，然后将命令发送给turtle_sim节点</li>
</ol>
<p>启动节点使用如下命令</p>
<pre><code># rosrun package-name executalbe-name
rosrun turtlesim turtlesim_node 

# 获得运行节点列表
rosnode list
# 该命令的输出为（在turtle_sim的例子下）
/rosout
/teleop_turtle
/turtlesim
# 其中rosout是一个特殊的节点，通过roscore自动启动，功能类似控制台程序中的标准输出

# 查看节点
# rosnode info node-name
rosnode info /teleop_turtle

# 终止节点
# rosnode kill node-name
rosnode kill /teleop_turtle
</code></pre><h1 id="话题和消息"><a href="#话题和消息" class="headerlink" title="话题和消息"></a>话题和消息</h1><p>ROS中，消息有组织的存放在<strong>话题</strong>里，这个机制可以描述为：当一个节点想要分享信息时，它会发布消息到对应的一个或者多个话题，当一个节点要接受信息时，它就会订阅它所需要的一个或者过个话题。</p>
<pre><code># 查看ros中的发布/订阅关系
rqt_graph
</code></pre><p>所有的节点都向话题/rosout发布消息，该话题由同名节点/rosout节点订阅。在turtlesim例中，当你按下一个键时，/teleop_turtle节点会以消息的形式将这些运 动控制命令发布到话题/turtle1/cmd_vel;与此同时，因为turtlesim_node订阅了该话题，因此它会接收到这个些消息，控制海龟按照该预定的速度移动。</p>
<pre><code># 获得当前活跃话题
rostopic list

# 打印某个话题下的消息内容
# rostopic echo topic-name
rostopic echo /turtle1/cmd_vel

# 测量某个话题发布频率以及占用贷款
rostopic hz topic-name
rostopic bw topic-name

# 查看话题
# rostopic info topic-name
rostopic info /tutle1/color_sensor

# 查看某种类型消息的详情
#rosmsg show message-type-name
rosmsg show turtlesim/Color
rosmsg show geometry_msgs/Twist

# 用命令行发布消息
#rostopic pub –r rate-in-hz topic-name message-type message-content
rostopic pub –r 1 /turtle1/cmd_vel geometry_msgs/Twist &#39;[2,0,0]&#39; &#39;[0,0,0]&#39;
</code></pre><p>理解消息类型的命名：ROS中，每条消息类型都属于一个包，消息类型名总会包含一个斜杠，斜杠前的名字就是包含他的包，如turtlesim/Color</p>
<h1 id="问题检查"><a href="#问题检查" class="headerlink" title="问题检查"></a>问题检查</h1><pre><code>roswtf
</code></pre><h1 id="编写ROS程序"><a href="#编写ROS程序" class="headerlink" title="编写ROS程序"></a>编写ROS程序</h1><p>所有的ROS软件，都被组织成包，在编写之前，创建一个容纳功能包的工作区。然后创建一个功能包</p>
<pre><code># 创建功能包
# catkin_create_pkg package-name
catkin_create_pkg agitr
</code></pre><p>写一个这样的函数是简单的，但是我们必须要根据cpp文件的一些特定对其txt进行相应的配置，以使得该文件能够被正确的配置。</p>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> ROS </tag>
            
            <tag> Ubuntu/Linux </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[论文阅读笔记]]></title>
      <url>/2019/04/01/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/</url>
      <content type="html"><![CDATA[<h1 id="Exploration-of-Indoor-Environments-Predicting-the-Layout-of-Partially-Observed-Rooms"><a href="#Exploration-of-Indoor-Environments-Predicting-the-Layout-of-Partially-Observed-Rooms" class="headerlink" title="Exploration of Indoor Environments - Predicting the Layout of Partially Observed Rooms"></a>Exploration of Indoor Environments - Predicting the Layout of Partially Observed Rooms</h1><h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>文中讨论了<strong>an agent incrementally huilds the maos of initially unknown indoor environments</strong>。在这个情景中，agent需要不断的作出一系列的action的决定，如<em>下一步去探索哪里</em>等，而这些决定仅根据现在agent画出来的当前environment的map而决定。</p>
<p>而文中的核心想法就是，利用agent现在对于环境的预测(a prediction of the geometric structure of the unknown parts of an environment)来选择下一个action。</p>
<blockquote>
<p>整个过程可以分为两步</p>
<ol>
<li><p>reconstruct the layout of the environment starting from a partial grid map and to predict the shape of partially observed rooms on the basis of geometric features【如何根据当前的partial observation有效的重建environment的layout】</p>
</li>
<li><p>use the predicted layout to estimate the amount of new area the agent would observe from candidate locations in order to inform the selection of the next best one【如何使用layout进行下一步预测的辅助】</p>
</li>
</ol>
</blockquote>
<h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2>]]></content>
      
        
        <tags>
            
            <tag> AI </tag>
            
            <tag> POLIMI </tag>
            
            <tag> Computer Science </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Advanced Recommender Systems]]></title>
      <url>/2019/01/26/Advanced-Recommender-Systems/</url>
      <content type="html"><![CDATA[<h1 id="Esimating-Rating-as-Optimization-Problem"><a href="#Esimating-Rating-as-Optimization-Problem" class="headerlink" title="Esimating Rating as Optimization Problem"></a>Esimating Rating as Optimization Problem</h1><p>SLIM(Sparse Linear Models) techniques:  a machine learning approach to ITEM-BASED COLLABORATIVE FILTERING.</p>
<h2 id="Starting-from-IBCF"><a href="#Starting-from-IBCF" class="headerlink" title="Starting from IBCF"></a>Starting from IBCF</h2><p>The estimation formula can be generalized for the dot product between the URM(User rating matrix, numUsers*numItems) and ISM (Item similarity matrix, numItems*numItems), which return <strong>the matrix of all estimated ratings for all users and all items</strong>.</p>
<h2 id="Minimize-the-estimation-error"><a href="#Minimize-the-estimation-error" class="headerlink" title="Minimize the estimation error"></a>Minimize the estimation error</h2><blockquote>
<p>KEY IDEA: Machine Learning Method-write a formula that estimate the error, and minimize the error of model by adjusting the unknown parameters.</p>
</blockquote>
<p>In RS, the error is how different our estimation is from the actual ratings of the users, and the unknown parameters are the elements of the similarity matrix. </p>
<p>Here we use the MSE (Mean Square Error). We find the item similarity matrix that minimize this MSE, thus giving the best performance for estimation of ratings.</p>
<h2 id="Optimization-problem-setting"><a href="#Optimization-problem-setting" class="headerlink" title="Optimization problem setting"></a>Optimization problem setting</h2><p>Condiser MSE. If we have</p>
<ol>
<li>R: URM</li>
<li>S: Item similarity matrix</li>
</ol>
<p>And we would like to minimize norm|R-R*S|. If S is the identity matrix, this norm would be 0. Since we would like to find an effective method to calculate S, we add constraint that the diagonal of S are all 0 elements.</p>
<h1 id="2-Norm-amp-F-norm"><a href="#2-Norm-amp-F-norm" class="headerlink" title="2-Norm &amp; F-norm"></a>2-Norm &amp; F-norm</h1><p><a href="http://mathworld.wolfram.com/FrobeniusNorm.html" target="_blank" rel="noopener">F-norm</a></p>
<p>If you measure the quality of your recommendation by using an <strong>accuracy metric</strong>, the experience is telling us that the F-norm leads to better quality recommendation. If, on the contrary, you measure the quality by using an <strong>error metric</strong>, such as Mean Square Error, it is better to use the 2-norm. </p>
<blockquote>
<p>这里我的理解是2-norm是对所有的URM的非零元素求MSE，F-norm对于URM中的所有元素求MSE。</p>
</blockquote>
<h1 id="Missing-as-negative-amp-Missing-as-random"><a href="#Missing-as-negative-amp-Missing-as-random" class="headerlink" title="Missing as negative &amp; Missing as random"></a>Missing as negative &amp; Missing as random</h1><h2 id="F-norm"><a href="#F-norm" class="headerlink" title="F-norm"></a>F-norm</h2><p>F-norm is assuming that, if an item in a URM is missing, the rating is zero. As F-norm if trying to convince your model to estimate a zero in URM as a zero, which is the missing as negative. </p>
<h2 id="Quality-Metrics-for-ML"><a href="#Quality-Metrics-for-ML" class="headerlink" title="Quality Metrics for ML"></a>Quality Metrics for ML</h2><p>Typically in ML, we always minimize an error function. We apply accuracy metrics like <strong>precision, recall, fallout and so on</strong>.</p>
<h2 id="Overfitting-and-Regularization-of-the-model"><a href="#Overfitting-and-Regularization-of-the-model" class="headerlink" title="Overfitting and Regularization of the model"></a>Overfitting and Regularization of the model</h2><p>One way to regularize overfitting is to reduce the number of unknown paramters, and we could add regularization terms to error function to achieve this result.</p>
<blockquote>
<p>The Regualtion Term: generally we minimize a function contains the sum of <strong>three terms</strong>: 1)the real error of our mdoel, 2) the 1-norm and 3) the 2-norm of S. By this we could control the sparsity of the matrix.</p>
</blockquote>
<h1 id="Stochastic-Gradient-Descent"><a href="#Stochastic-Gradient-Descent" class="headerlink" title="Stochastic Gradient Descent"></a>Stochastic Gradient Descent</h1><p>SGD is a general technique for solving optimization problems. </p>
<blockquote>
<p>SGD problem &amp; learning rate: SGD may stuck in locl minima, we could increase learning rate to solve this problem. But large learning rate brings other problem.</p>
</blockquote>
<h1 id="Rank"><a href="#Rank" class="headerlink" title="Rank"></a>Rank</h1><h2 id="The-learning-to-rank-approach"><a href="#The-learning-to-rank-approach" class="headerlink" title="The learning to rank approach"></a>The learning to rank approach</h2><p>Choosing an error function turned into a more general problem: <em>can we find an error function or can we solve a machine learnign problem, to solve the ranking instead of ratings</em>.</p>
<blockquote>
<p>Suppose there is a list of items ranked by users, and a list of items ranked by RS. Our goal is to create a list of items with the order defined by the users.</p>
</blockquote>
<h2 id="Ranking-error-metrics-list-wise-metric"><a href="#Ranking-error-metrics-list-wise-metric" class="headerlink" title="Ranking error metrics: list-wise metric"></a>Ranking error metrics: list-wise metric</h2><p>We could compare two lists and then compare all positions. (This is complex because it is diffcult to compute the gradient)</p>
<h2 id="Ranking-error-metrics-point-wise-metric"><a href="#Ranking-error-metrics-point-wise-metric" class="headerlink" title="Ranking error metrics: point-wise metric"></a>Ranking error metrics: point-wise metric</h2><p>We measure exactly the position of an item in the list of users and the list of RS. We measure how much these are different,. (This is also hard to compute the gradient)</p>
<h2 id="Ranking-error-metrics-pair-wise-metric"><a href="#Ranking-error-metrics-pair-wise-metric" class="headerlink" title="Ranking error metrics: pair-wise metric"></a>Ranking error metrics: pair-wise metric</h2><p>Take two items, we compare whether the relative order between 2 items are same in two lists. We could optimize the error function by this easily.</p>
<h1 id="BPR-Bayesian-Probabilistic-Ranking"><a href="#BPR-Bayesian-Probabilistic-Ranking" class="headerlink" title="BPR: Bayesian Probabilistic Ranking"></a>BPR: Bayesian Probabilistic Ranking</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>Based on pairwise error metrics, BPR is the most famous one, usually works with SGD.</p>
<blockquote>
<p>SGD: Normally, when you want to compute the gradient of your error function, you compute the gradient for all the users and all the items in your data set: you compute it which is normally a big matrix and then you can use it to perform the down step, or the up step, depending if you are minimizing or maximizing. Stochastic Gradient Descent works in this way: it is a trick to reduce the computational complexity of each single step and, also, the overfitting risk. Its idea is that you randomly select one user and one item. You compute the gradient only for them. You update the data and, then, you randomly pick another user and another item, performing the same previous steps and so on.</p>
</blockquote>
<h2 id="BPR-with-implicit-ratings"><a href="#BPR-with-implicit-ratings" class="headerlink" title="BPR with implicit ratings"></a>BPR with implicit ratings</h2><p>We randomly take one user and two items of this user. The two items are item i, that user likes for sure, and item j that the user does not like.</p>
<p>It is easy when deal with explicit ratings. While dealing with implicit items, we are not so sure. Actually we just select the unseen items, it may rise a questions that why <em>we can safely randomly select an item that the user didn’t click and we can bet money saying that the user does not like these items</em>. Actually, it just works, because if you randomly select an item that the user didn’t click, the probability that the user does like this item, is very low. So, in an implicit dataset, you’re going to select the items that the user picked interactively and an item that the user didn’t pick.</p>
<h2 id="BPR-error-function"><a href="#BPR-error-function" class="headerlink" title="BPR error function"></a>BPR error function</h2><p>We want to estimate the rating of i (liked items) is much bigger than the rating of j (uninterested items). </p>
<p>We would like to maximize the difference. The absolute value of this error function does not work well. Instead we take quantity error. It could be positive or negative. With the help of sigmoid function, we could restrict the error to [0,1]. </p>
<h2 id="Explicit-rating-amp-Implicit-rating"><a href="#Explicit-rating-amp-Implicit-rating" class="headerlink" title="Explicit rating &amp; Implicit rating"></a>Explicit rating &amp; Implicit rating</h2><p>BPR works well with both, but better with implicit ratings. The problem of explicit ratings is the user bias.</p>
<p>In explicit ratings, we select item i (liked items) by high rating items, and item j (uninterested items) by low rating items. We could select item j also those un-rated items. It makes BPR works perfect with explicit items.</p>
<h1 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h1><p>MF is a family of Collaborative filtering techiniques. These techniques are useful when URM is sparse. MF usually work better than item-based or user-based collaborative filtering.</p>
<blockquote>
<p>KEY IDEA: For each user, we have a vector x which decribes their preference for each attribute k of an item, (the demension of this vector is smaller than the number of items!), and for each item we have a vector y that describes it.</p>
</blockquote>
<h2 id="Funk-SVD"><a href="#Funk-SVD" class="headerlink" title="Funk SVD"></a>Funk SVD</h2><p>We could estimate the rating as the dot product of the vector x and y. From a matrix point of view, we are decompositing URM to matrix X and Y. </p>
<h2 id="Latent-factors"><a href="#Latent-factors" class="headerlink" title="Latent factors"></a>Latent factors</h2><p>The dimension of X and Y depends on the designer of the system. X is matrix of numUser*N, and Y is N*numItems. N is the number of latent facotrs.</p>
<p>We usually have N of from 10 to 200. N too small, no useful at all. N too big, X and Y become too sparse.</p>
<blockquote>
<p>Avoid Overfitting: add regularization terms for X and Y on the error function. </p>
</blockquote>
<h1 id="SVD"><a href="#SVD" class="headerlink" title="SVD++"></a>SVD++</h1><p>We describe an improved version of funk SVD. Which works for URM with explicit ratings. We need to nornalize the URM, and contains two parts, the Global Effects and Funk SVD.</p>
<p>It take user bias and item bias into consideration.</p>
<h2 id="Assumption-on-zero-elements"><a href="#Assumption-on-zero-elements" class="headerlink" title="Assumption on zero elements"></a>Assumption on zero elements</h2><p>The classical formulation of SVD++ minimizes the error function on the non-zero elements. </p>
<p>If the goal is to estimate the real value of the ratings of the user, this is a good appoach. While if the goal is to do a top-n recommendation and desire to have good precision, missing as negative would be better.</p>
<h1 id="Adapting-SVD"><a href="#Adapting-SVD" class="headerlink" title="Adapting SVD++"></a>Adapting SVD++</h1><p>In order to avoid recomputing the estimated ratings from scratch for each new user, we need to improve SVD++. </p>
<p>For new user, we would like to calculate the new latent factor. It is telling us how much this user like latent attribute k. </p>
<blockquote>
<p>We want to estimate how much user “u” likes latent feature “k” based on the ratings he gave to other items. Now we need something which is telling us if attribute “k” is present or not in item “j”. Y<sub>k,j</sub> telling us the information of attribute k in item j. Therefore, we can approximate X<sub>u,k</sub> as the dot product of the vector of ratings of the user and the latent factors for the corresponding items. </p>
</blockquote>
<h1 id="Matrix-formulation"><a href="#Matrix-formulation" class="headerlink" title="Matrix formulation"></a>Matrix formulation</h1><p>We obtain the matrix of estimated ratings R as the product of 2 terms.</p>
<ol>
<li>The URM, R</li>
<li>The transpose of matrix Y times matrix Y (the dimension of Y is numLatentFactors*numItems), and this product is of shape numItems*numItems</li>
</ol>
<p>This is quite same to the IBCF. And we use the parameters in Y limit the overfitting problem</p>
<h1 id="Asymmetric-SVD"><a href="#Asymmetric-SVD" class="headerlink" title="Asymmetric SVD"></a>Asymmetric SVD</h1><p>In Asymmetric SVD’s main advantage is that it allows us to overcome the main shortcoming of SVD++, which was that the algorithm is not model-based, thus needs recomputing everytime a new user is added in the system.</p>
<p>With A-SVD, when new users are added into the system, we can start giving them relevant recommendations just by asking for a few of their favorite items.</p>
<p>Instead of using vector x to represent user preferences directly, we introduce another matrix Q. Q multiplied the vector r of recorder user ratigns approximates the vector x. We could klearn Q by ML approaches. </p>
<blockquote>
<p>KEY IDEA: we solve how much a user likes a feature, than we solve how much a user likes an item.</p>
</blockquote>
<h1 id="Hybrid-RS"><a href="#Hybrid-RS" class="headerlink" title="Hybrid RS"></a>Hybrid RS</h1><p>Hybrid RS combine the results of two or more algorithms together. </p>
<h2 id="Linear-Combination"><a href="#Linear-Combination" class="headerlink" title="Linear Combination"></a>Linear Combination</h2><p>The simplest hybridization, compute the estimated rating for user u and item i as the linear combination of the result of different RS. We could also combine lists.</p>
<blockquote>
<p>Disadvantages: the optimal values depends on the dataset. </p>
</blockquote>
<h2 id="Pipeline-Algorithms"><a href="#Pipeline-Algorithms" class="headerlink" title="Pipeline Algorithms"></a>Pipeline Algorithms</h2><p>We could use the result of one RS as the input of a second algorithm. It works better if we use a content based technique to enrich a collaborative techinique.</p>
<blockquote>
<p>Disadvantages: memory and computation problem.</p>
</blockquote>
<h2 id="Merging-models"><a href="#Merging-models" class="headerlink" title="Merging models"></a>Merging models</h2><p>Merge two algorithms, A and B together into one . For example, marge a content based method to calculate the item similarity matrix, and then we use IBCF to calculate another item similarity matrix, we could reach the very same conclusion.</p>
<h1 id="S-SLIM-Side-Information"><a href="#S-SLIM-Side-Information" class="headerlink" title="S-SLIM: Side Information"></a>S-SLIM: Side Information</h1><p>S-SLIM merges collaborative filtering and content based approach.</p>
<p>SLIM is a CF, and the target of CF and CBF are both calculating item similarity matrix.</p>
<blockquote>
<p>KEY-IDEA: combine two item similarity matrix together, and use an error function to find the best weights. And we need to constraint the result item similarity matrix have a diagonal with zero.</p>
</blockquote>
<h1 id="Context-Aware-RS"><a href="#Context-Aware-RS" class="headerlink" title="Context Aware RS"></a>Context Aware RS</h1><p>In some application, the RS depends on the external factors like the weather, the hour of the day. These information are called context.</p>
<p>To represent context, we augment the URM to include them as new type of varaible. The URM is not 2d any more, it is 3D! For each rating, we record the rating in different context. </p>
<h2 id="Tensor-Factorization"><a href="#Tensor-Factorization" class="headerlink" title="Tensor Factorization"></a>Tensor Factorization</h2><p>To use the tensor, we extend the matrix factorization to the tensor case. With MF we estimat the URM as product of two matrices, X and Y. In Tensor, we decomposite the 3-d tensor to product of X, Y and Z.</p>
<ol>
<li>X: how much the user like a latent feature.</li>
<li>Y: how much the latent feature is important to describe the item.</li>
<li>Z: how much the feature is relevant in the context.</li>
</ol>
<h1 id="Factorization-Machines"><a href="#Factorization-Machines" class="headerlink" title="Factorization Machines"></a>Factorization Machines</h1><p>FM is a new technique of collaborative filtering with side information. It looks like Matrix Factorization, but the technique is quite different.</p>
<p><a href="https://www.cnblogs.com/pinard/p/6370127.html" target="_blank" rel="noopener">LINK 1</a><br><a href="https://www.jianshu.com/p/78628d1cc621" target="_blank" rel="noopener">LINK 2</a></p>
<blockquote>
<p>FM的原理是将所有的user，item都看作输入，将rating看作输出，我们通过这种方式将原本的RS问题转化成了一个regression问题。</p>
</blockquote>
<h2 id="FM-vs-CF"><a href="#FM-vs-CF" class="headerlink" title="FM vs CF"></a>FM vs CF</h2><p>FM is creating a table, and approximating each rating in the table with a formula and estimate the unknown parameters by minimizeing some error, it is just like collaborative filtering.</p>
<h2 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h2><p>FM is more flexible with side information: just add new columns!</p>
<h2 id="Disadvantages"><a href="#Disadvantages" class="headerlink" title="Disadvantages"></a>Disadvantages</h2><p>The computation cost is ahigh, and we need to regularize the overfitting problem.</p>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Recommender Systems </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Numerical Analysis]]></title>
      <url>/2019/01/12/Numerical-Analysis/</url>
      <content type="html"><![CDATA[<h1 id="Bisection-Newton-Fixed-Point"><a href="#Bisection-Newton-Fixed-Point" class="headerlink" title="Bisection/Newton/Fixed Point"></a>Bisection/Newton/Fixed Point</h1><h2 id="Bisection-二分法求零点"><a href="#Bisection-二分法求零点" class="headerlink" title="Bisection 二分法求零点"></a>Bisection 二分法求零点</h2><p>我们使用二分法求零点，根据函数的连续性，假如在一个函数在interval[a,b]上连续，而且在这个interval的两端取得不同的符号，那么显然我们在这个区间上至少有一个零点，如果函数是单调的，那么在这个interval上的零点唯一。</p>
<p>我们可以用二分法进行求解，需要给定interval的两端[a,b]的值，以及tolerance的值，通过区间的长度和tolerance来计算需要迭代的次数n，然后进行n次迭代后输出。</p>
<h2 id="Newton-牛顿法和modified牛顿法"><a href="#Newton-牛顿法和modified牛顿法" class="headerlink" title="Newton 牛顿法和modified牛顿法"></a>Newton 牛顿法和modified牛顿法</h2><p>二分法相当于只使用了函数interval两端的信息，但是我们可以有更快的选择。牛顿法是一种收敛速度比二分法更快的方法，可以描述为在x<sup>(k)</sup>上做一条与原函数相切的直线，将这条直线与x轴的焦点做为下次迭代的x<sup>(k+1)</sup>。</p>
<p>和二分法不同，尽管牛顿法更快，但是牛顿法并不是全局收敛的，仅仅对于零点a附近某个区间内的点是收敛的，并且我们<strong>不能</strong>判断给定一个点x<sub>0</sub>以及对应的函数值导数值等，去判断能否从x<sub>0</sub>收敛到a。</p>
<p>我们既然提到了牛顿法是收敛更快的算法，那么要快多少呢？二分法的收敛是线性的，因为我们可以视error为e<sup>(k)</sup>每次迭代都变为e<sup>(k+1)</sup>都是原来的一半。而牛顿法，如果零点a是simple的（即f’(a)不等于0），那么牛顿法是quadratically收敛的。</p>
<p>如果零点a不是simple的，且m是a的multiplicity，如果想让牛顿法收敛，我们需要确保x<sup>(0)</sup>的选择是合理的，且在interval上没有其他x使得f’(x)=0，此时牛顿法的收敛为线性的，如果我们使用modified牛顿法（m对应multiplicity的值），此时modified牛顿法的收敛依然是quadratically的。</p>
<blockquote>
<p>如果f在interval[a,b]上是单调的，且f(a)和f(b)异号，那么对任何[a,b]上的x<sub>0</sub>，假如x<sub>0</sub>满足f(x<sub>0</sub>)*f’’(x<sub>0</sub>)&gt;0，那么牛顿法在x<sub>0</sub>上收敛。</p>
</blockquote>
<h2 id="Fixed-Point定点法"><a href="#Fixed-Point定点法" class="headerlink" title="Fixed Point定点法"></a>Fixed Point定点法</h2><p>定点法：x<sup>(k+1)</sup>=phi(x<sup>(k)</sup>)</p>
<img src="/2019/01/12/Numerical-Analysis/1.png">
<p>根据上图不难得出结论，假如a是phi的一个fixed point(即有a=phi(a))，lim e<sup>(k+1)</sup>/e<sup>(k)</sup> = phi’(a),我们希望error在这个迭代的过程中是不断递减的，那么必须有phi’(a)&lt;1。那么我们根据a的关于phi的导数，有如下三种情况</p>
<ol>
<li>|phi’(a)|<1 :存在一个r，对于任意的(a-0,a+0)中的x<sub="">0定点法收敛（注意，此处的定点法收敛指的是对于合适的x<sub>0</sub>定点法收敛）</1></li>
<li>|phi’(a)|&gt;1 :存在至少1个x<sub>0</sub>不收敛到a（即定点法不收敛）</li>
<li>|phi’(a)|=1 :可能收敛也可能不收敛</li>
</ol>
<blockquote>
<p>对于phi，我们可以根据phi在fixed point a上的导数来判断收敛的速度，如果phi<sup>(i)</sup>=0, i=1,2…p-1，且phi<sup>(p)</sup>!=0，那么定点法x<sup>(k+1)</sup>=phi(x<sup>(k)</sup>)的order为p，即lim e<sup>(k+1)</sup>/(e<sup>(k)</sup>)<sup>p</sup>=constant。</p>
</blockquote>
<h2 id="Convergence-Order"><a href="#Convergence-Order" class="headerlink" title="Convergence Order"></a>Convergence Order</h2><p>判断convergence order，本质上就是判断constant=e<sup>(k+1)</sup>/(e<sup>(k)</sup>)<sup>p</sup>中p的值，如果p为1，则为线性的，如果p为2，则为quadratically的，以此类推。通过求log可以很快的得出结论并画出图像。</p>
<h1 id="LU分解"><a href="#LU分解" class="headerlink" title="LU分解"></a>LU分解</h1><p>Ax=b, A是一个n*n矩阵，b是一个n维向量，求解x。</p>
<h2 id="Backward-and-forward-substitution"><a href="#Backward-and-forward-substitution" class="headerlink" title="Backward and forward substitution"></a>Backward and forward substitution</h2><p>A=LU，L是一个下三角矩阵，而U是一个上三角矩阵，将这个式子和上面的式子连立起来，能得到Ly=b,Ux=y。</p>
<p>这样做的好处是在正常情况下，为了求解x的值，需要令b右乘A的逆矩阵，即x=A<sup>-1</sup>b，但是求逆矩阵是非常复杂的，需要很高的computing power，为了避免求逆矩阵，我们就采用LU分解。</p>
<p>L(U)是下(上)三角矩阵，对于L使用forward substitution，因为显然从方程的角度去看这个问题，我们有L<sub>1,1</sub> <em> y<sub>1</sub>=b<sub>1</sub>，从而可以一一解出y的值。   对于U使用backward substitution，解答的方法同上，但是由于我们是从U最下面的元素开始解出x的值的U<sub>n,n</sub> </em> x<sub>n</sub>=y<sub>n</sub>，所以将这个方法称为backward substitution。</p>
<h2 id="LU分解存在的条件"><a href="#LU分解存在的条件" class="headerlink" title="LU分解存在的条件"></a>LU分解存在的条件</h2><p>不是每一个A都可以分解成LU的形式，那么什么样的矩阵可以分解为LU的形式呢？显然对于一个不可逆矩阵，是无法分解成LU的形式的，但是对于一个可逆矩阵，也可能出现无法分解成LU的情况。</p>
<ol>
<li>如果A是一个row/column对角线dominant的矩阵（即a对角线上的元素大于同一row/column中所有其他元素的绝对值之和），矩阵A能够LU分解。</li>
<li>A是一个symmetric positve definite矩阵，则A能够进行LU分解。</li>
</ol>
<blockquote>
<p>判断A是否是正定矩阵，我们可以通过eig(A)&gt;0来判断，eig(A)表示A的特征值，而正定矩阵的特征值是全正的。</p>
</blockquote>
<p>以上的两种情形是A能够进行LU分解的特殊情况，一个更general的条件是，<strong>给定矩阵A，其LU分解存在且唯一的充要条件是A对角线上的所有方阵A<sub>i</sub>都是非奇异矩阵(行列式不等于0)</strong></p>
<h2 id="General-LU-Decomposition"><a href="#General-LU-Decomposition" class="headerlink" title="General LU Decomposition"></a>General LU Decomposition</h2><p>LU分解是将一个矩阵分解为L*U，其中L的对角线上的元素为1。具体的操作过程可以视为将其进行不断的transform，不断的进行每个row之间的数乘和加减。</p>
<h2 id="对于特殊的A进行特殊的LU分解-Cholesky分解"><a href="#对于特殊的A进行特殊的LU分解-Cholesky分解" class="headerlink" title="对于特殊的A进行特殊的LU分解-Cholesky分解"></a>对于特殊的A进行特殊的LU分解-Cholesky分解</h2><p>如果A是一个symmetric positive definite的矩阵，那么A可以分解为H*H<sup>T</sup>，根据其对称的形式，可以很简单的用矩阵表示出H中的每个元素。</p>
<h2 id="对于特殊的A进行特殊的LU分解-Thomas-Algorithm"><a href="#对于特殊的A进行特殊的LU分解-Thomas-Algorithm" class="headerlink" title="对于特殊的A进行特殊的LU分解-Thomas Algorithm"></a>对于特殊的A进行特殊的LU分解-Thomas Algorithm</h2><p>如果A是一个对称矩阵，并且只有三列对角线上的元素，那么我们可以用类似上面的general LU decomposition的方法进行分解，但是每一个value的表示形式会变得更加简便。</p>
<blockquote>
<p>建立一个对角线矩阵</p>
<p>a = [1:10]’;</p>
<p>c = [10:19]’;</p>
<p>e = [102:111]’;</p>
<p>n = length(a);</p>
<p>A = spdiags([e a c], [−1 0 1], n, n)</p>
</blockquote>
<h2 id="LU-with-pivoting"><a href="#LU-with-pivoting" class="headerlink" title="LU with pivoting"></a>LU with pivoting</h2><p>Pivoting是一种改变改变矩阵的行的顺序的方法，使得一个不能进行LU分解的矩阵可以进行LU分解。表示为Ax=b,PA=LU。</p>
<blockquote>
<p>infinity norm of the error: norm(x-x1,inf)</p>
<p>infinity norm of the <em>normalized</em> residual error: norm(b-A*x1, inf)/norm(b, inf)</p>
</blockquote>
<h2 id="Condition-Number"><a href="#Condition-Number" class="headerlink" title="Condition Number"></a>Condition Number</h2><p>P-norm: ||A||<sub>p</sub>=(SIGMA|x<sub>i</sub>|<sup>p</sup>)<sup>1/p<sup></sup></sup></p>
<p>Condition number: K<sub>p(A)=||A||<sub>p</sub>*||A<sup>-1</sup>||<sub>p</sub></sub></p>
<blockquote>
<p>condition number: cond(A,n)</p>
</blockquote>
<p>K<sub>p(A)是衡量sensitivity的一个指标，即对于b的微小的扰动，x的扰动程度。如果K<sub>p(A)越小，表示A越well-conditioned。</sub></sub></p>
<h1 id="Iterative-Methods-of-Linear-system"><a href="#Iterative-Methods-of-Linear-system" class="headerlink" title="Iterative Methods of Linear system"></a>Iterative Methods of Linear system</h1><p>Ax=b, A是一个n*n矩阵，b是一个n维向量，求解x。</p>
<h2 id="Stationary-methods"><a href="#Stationary-methods" class="headerlink" title="Stationary methods"></a>Stationary methods</h2><p>x<sup>(k+1)</sup> = B*x<sup>(k)</sup>+g</p>
<p>s.t. x<sup>*</sup> = B<em>x<sup>\</sup></em>+g</p>
<p>我们设置stopping criterion为</p>
<ol>
<li>||x<sup>(k+1)</sup>-x<sup>(k)</sup>||&lt;=tolerance</li>
<li>||b-Ax<sup>(k+1)</sup>||&lt;=tolerance</li>
</ol>
<blockquote>
<p>这种方法收敛的充要条件是ρ(B)&lt;1，ρ(B)=max(|eig(B)|)。</p>
</blockquote>
<p>同时，为了估计当前迭代状态下的误差error ||x<sup>k</sup>-x<sup>*</sup>||，我们可以通过||x<sup>(k+1)</sup>-x<sup>k</sup>||来约束这个误差。</p>
<p><strong>目标：构建一个A=P-(P-A)。</strong></p>
<h2 id="Jacobi-method-amp-Gauss-Seidel-method"><a href="#Jacobi-method-amp-Gauss-Seidel-method" class="headerlink" title="Jacobi method &amp; Gauss Seidel method"></a>Jacobi method &amp; Gauss Seidel method</h2><img src="/2019/01/12/Numerical-Analysis/2.png">
<h2 id="Richardson-method"><a href="#Richardson-method" class="headerlink" title="Richardson method"></a>Richardson method</h2><p>不难看出，其实Jacobi method和Gauss Seidel method都是Richardson method的特殊化的形式，就像是牛顿法本质上是定点法的特殊演绎一样。</p>
<img src="/2019/01/12/Numerical-Analysis/3.png">
<p>其中α的最佳选择α<sub>opt</sub>=2/(λ<sub>min</sub>+λ<sub>min</sub>)，λ<sub>min</sub>/λ<sub>min</sub>表示P<sup>-1</sup>A的最小/大的特征值。</p>
<h2 id="Gradient-method-此节不在考试范围内"><a href="#Gradient-method-此节不在考试范围内" class="headerlink" title="Gradient method* 此节不在考试范围内"></a>Gradient method* 此节不在考试范围内</h2><img src="/2019/01/12/Numerical-Analysis/4.png">
<h1 id="Interpolation"><a href="#Interpolation" class="headerlink" title="Interpolation"></a>Interpolation</h1><p>interpolation的直译结果为【插值】，但是其实在这门课所涉及到的地方，将其理解为【拟合】这个概念会更好理解一些，从原函数f(x)上取得一系列的点，然后根据这些点来设计一个新的函数f*(x)来近似这个原函数f(x)。</p>
<img src="/2019/01/12/Numerical-Analysis/5.png">
<h2 id="拉格朗日多项式插值"><a href="#拉格朗日多项式插值" class="headerlink" title="拉格朗日多项式插值"></a>拉格朗日多项式插值</h2><p>对于任意n个nodes{x<sub>i,y<sub>i}，存在唯一的一个多项式f<em>(x)，其degree小于等于n，且对于任何x<sub>i，都有f</sub></em>(x<sub>i)=y<sub>i。</sub></sub></sub></sub></p>
<p>根据上面的公式，为了获取f<em>(x)的表达形式，我们设计φ<sub>k</sub>(x<sub>j</sub>)=1 if j=k, 0 else。然后求和φ<sub>k</sub>(x<sub>j</sub>) </em> f(x<sub>k</sub>)，得到f*(x)。</p>
<img src="/2019/01/12/Numerical-Analysis/6.png">
<h2 id="分段线性插值"><a href="#分段线性插值" class="headerlink" title="分段线性插值"></a>分段线性插值</h2><p>这种插值的方式就很好理解了，我们将函数分为很多段，然后将每一段用一条直线连接起来，相比于上面，虽然这样得到的f*(x)不是光滑的，但是也是原函数的一种近似的方式。</p>
<img src="/2019/01/12/Numerical-Analysis/7.png">
<img src="/2019/01/12/Numerical-Analysis/8.png">
<h2 id="Spline插值"><a href="#Spline插值" class="headerlink" title="Spline插值"></a>Spline插值</h2><p>与分段式线性插值有一些类似，我们将函数分为很多段，但是我们还希望让我们的新的f*(x)是光滑的，在上面的近似方式中，不光滑的点仅仅存在在两个interval的连接处，那么我们在spline的方法中，对每个interval [x<sub>i</sub>,x<sub>j</sub>]都使用一个三次函数（注意！不再是上面的线性/一次函数了）进行近似，我们可以调整这个函数，使其不仅经过x<sub>i</sub>和x<sub>j</sub>对应的点，同时在这两个点上的导数与前一个以及后一个interval是相同的。</p>
<h1 id="Integral-积分"><a href="#Integral-积分" class="headerlink" title="Integral 积分"></a>Integral 积分</h1><img src="/2019/01/12/Numerical-Analysis/9.png">
<img src="/2019/01/12/Numerical-Analysis/10.png">
<p>midpoint rule和trapezoidal rule都是order 1的，这意味着它们可以近似线性函数而没有任何误差，而Simpson rule的degree of exactness等于3，这意味着order低于3的function的积分值是准确的。</p>
]]></content>
      
        
        <tags>
            
            <tag> Numerical Analysis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Artificial Intelligence]]></title>
      <url>/2018/12/20/Artificial-Intelligence/</url>
      <content type="html"><![CDATA[<h1 id="General-Information"><a href="#General-Information" class="headerlink" title="General Information"></a>General Information</h1><p>This is a notes for the AI lesson of POLIMI 2018-2019.</p>
<blockquote>
<p>Chapter 1: Introduction. The whole chapter</p>
<p>Chapter 2: Intelligent agents. The whole chapter</p>
<p>Chapter 3: Solving problems by searching. Sections 3.1-3.6</p>
<p>Chapter 5: Adversarial search. Sections 5.1-5.5, 5.7-5.8</p>
<p>Chapter 6: Constraint propagation. Sections 6.1-6.3</p>
<p>Chapter 7: Logical agents. Sections 7.1, 7.3-7.5, 7.6.1</p>
<p>Chapter 10: Classical planning. Sections 10.1, 10.2, 10.4</p>
</blockquote>
<h1 id="Chapter-I-INTRODUCTION"><a href="#Chapter-I-INTRODUCTION" class="headerlink" title="Chapter I INTRODUCTION"></a>Chapter I INTRODUCTION</h1><h2 id="1-1-What-is-AI"><a href="#1-1-What-is-AI" class="headerlink" title="1.1 What is AI"></a>1.1 What is AI</h2><p>Four definitions: </p>
<ol>
<li>Thinking Humanly: Coginitive Science-首先我们需要知道如何定义“Humanly”，也就是人类究竟是如何思考的。在这种AI的定义中，我们寄希望于构造一个machine使其能够按照人类思考的方式进行思考，然而目前这个课题本事也是充满谜团和未知的。</li>
<li>Thinking Rationally: The “laws of thought” Approach-这一定义涉及到Logic部分的内容，将Knowledge用Formal Language进行表述，从而使机器能够对这些Knowledge进行推导和解决。</li>
<li>Acting Humanly: Turing Test-假如一个机器可以欺骗人类让人误以为对方是真正的人类，那么我们就认为这个机器达到了真正的智能的水平。</li>
<li>Acting Rationally: The Rational Agent Approach-每一个agent都有一定的acts，我们定义【<em>A rational agent is one that acts so as to achieve the best outcome or, when there is uncertainty, the best expected outcome</em>】。根据这个定义，correct inferences对一个rational agent是格外重要的，因为这是使得agent能够到达他预设的goal的必要条件。</li>
</ol>
<h2 id="1-2-The-Foundations-of-AI"><a href="#1-2-The-Foundations-of-AI" class="headerlink" title="1.2 The Foundations of AI"></a>1.2 The Foundations of AI</h2><ol>
<li>Philosophy: 知识从哪儿来？意识是怎样从大脑中诞生的？…</li>
<li>Mathematics: 我们怎样通过formal rules推导新的正确的结论？通过计算可以得出什么？…</li>
<li>Economics: 为了最大化收益应该怎样做结论？（决策论）…</li>
<li>Neuroscience: 大脑是如何处理信息的？…</li>
<li>Psychology: …</li>
<li>Computer Engineering: …</li>
<li>Control theory and cybernetics: …</li>
<li>Liguistics :…</li>
</ol>
<h2 id="1-3-The-History-of-AI"><a href="#1-3-The-History-of-AI" class="headerlink" title="1.3 The History of AI:"></a>1.3 The History of AI:</h2><p>Knowledge Bases Systems/Neural Network/…</p>
<h2 id="1-4-The-state-of-art-Some-Real-Applications"><a href="#1-4-The-state-of-art-Some-Real-Applications" class="headerlink" title="1.4 The state of art: Some Real Applications"></a>1.4 The state of art: Some Real Applications</h2><h1 id="Chapter-II-INTELLIGENT-AGENTS"><a href="#Chapter-II-INTELLIGENT-AGENTS" class="headerlink" title="Chapter II INTELLIGENT AGENTS"></a>Chapter II INTELLIGENT AGENTS</h1><h2 id="2-1-Agents-and-Environments"><a href="#2-1-Agents-and-Environments" class="headerlink" title="2.1 Agents and Environments"></a>2.1 Agents and Environments</h2><p>AGENT: An agent is anything that can be viewed as perceiving its environment through sensors and acting upon that environment through actuators.</p>
<p>AGENT FUNCTION: Mathematically speaking, we say that an agent’s behavior is described by the agent function that maps any given percept sequence to an action.</p>
<p>AGENT PROGRAM: The agent function for an artificial agent will be implemented by an agent program.</p>
<blockquote>
<p>The agent function is an abstract mathematical description; the agent program is a concrete implementation, running within some physical system.</p>
</blockquote>
<h2 id="2-2-Good-behavior-the-concepts-of-retionality"><a href="#2-2-Good-behavior-the-concepts-of-retionality" class="headerlink" title="2.2 Good behavior: the concepts of retionality"></a>2.2 Good behavior: the concepts of retionality</h2><p>A rational agent is one that does the right thing, but what does it mean to do the right thing?</p>
<p>By considering the consequences of the agent’s behavior. When an agent is plunked down in an environment, it generates <strong>a sequence of actions</strong> according to the percepts it receives. This sequence of actions causes the environment to go through <strong>a sequence of states</strong>. If the sequence is desirable, then the agent has performed well. This notion of desirability is captured by a performance measure that evaluates any given sequence of environment states.</p>
<p>Obviously, there is not one fixed performance measure for all tasks and agents; typically, a designer will devise one appropriate to the circumstances.</p>
<p>Four PRECONDITIONS of rationality</p>
<ol>
<li>The performance measure that defines the criterion of success.</li>
<li>The agent’s prior knowledge of the environment.</li>
<li>The actions that the agent can perform.</li>
<li>The agent’s percept sequence to date.</li>
</ol>
<p>DEFINITION OF A RATIONAL AGENT: For each possible percept sequence, a rational agent should select an action that is expected to maximize its performance measure, given the evidence provided by the percept sequence and whatever built-in knowledge the agent has.</p>
<p>Rationality is not the same as <strong>perfection</strong>. Rationality maximizes expected performance, while perfection maximizes actual performance</p>
<p>To the extent that an agent relies on the prior knowledge of its designer rather than on its own percepts, we say that the agent lacks autonomy. A rational agent should be autonomous—<strong>it should learn what it can to compensate for partial or incorrect prior knowledge</strong>.</p>
<h1 id="2-3-The-Nature-of-Environments"><a href="#2-3-The-Nature-of-Environments" class="headerlink" title="2.3 The Nature of Environments"></a>2.3 The Nature of Environments</h1><p>In our discussion of the rationality of the simple vacuum-cleaner agent, we had to specify the performance measure, the environment, and the agent’s actuators and sensors. We group all these under the heading of the task environment. For the acronymically minded, we call this the <strong>PEAS (Performance, Environment, Actuators, Sensors) description</strong>.</p>
<blockquote>
<p>Properties of environments:</p>
<p><strong>Fully observable vs partially observable</strong>:  If an agent’s sensors give it access to the complete state of the environment at each point in time, then we say that the task environ- ment is fully observable. </p>
<p><strong>Single agent vs multiagent</strong>: For example, an agent solving a crossword puzzle by itself is clearly in a single-agent environment, whereas an agent playing chess is in a two- agent environment. </p>
<p><strong>Deterministic vs stochastic</strong>:  If the next state of the environment is completely deter- mined by the current state and the action executed by the agent, then we say the environment is deterministic; otherwise, it is stochastic. </p>
<p><strong>Episodic vs sequential</strong>: Many classification tasks are episodic. For example, an agent that has to spot damaged parts on an assembly line bases each decision on the current part, regardless of previous decisions; In sequential environments, on the other hand, the current decision could affect all future decisions.</p>
<p><strong>Static vs dynamic</strong>: If the environment can change while an agent is deliberating, then we say the environment is dynamic for that agent; otherwise, it is static.</p>
<p><strong>Discrete vs continuous</strong>: The discrete/continuous distinction applies to the state of the environment, to the way time is handled, and to the percepts and actions of the agent. </p>
</blockquote>
<h2 id="2-4-The-Structure-of-Agents"><a href="#2-4-The-Structure-of-Agents" class="headerlink" title="2.4 The Structure of Agents"></a>2.4 The Structure of Agents</h2><p>The job of AI is to design an <strong>agent program</strong> that implements the agent function — the mapping from percepts to actions. We assume this program will run on some sort of computing device with physical sensors and actuators—we call this the <strong>architecture</strong>:</p>
<blockquote>
<p>agent = architecture + program</p>
</blockquote>
<ol>
<li>Simple reflex agents: These agents select actions on the basis of the current percept, ignoring the rest of the percept history. (e.g. 一个设计好的conversation agent，每当输入“你好”的时候，输出“你好”，但是这个机器人实际上并没有计算之前说了多少次你好，哪怕是输入一万次“你好”也会输出“你好”，而不是“你有完没完”。) </li>
<li>Model-based reflex agents: The most effective way to handle partial observability is for the agent to keep track of the part of the world it can’t see now. That is, the agent should maintain some sort of internal state that depends on the percept history and thereby reflects at least some of the unobserved aspects of the current state. An agent that uses such a model is called a model-based agent.(e.g. 接上例提到的conversation agent，如果我们设计一个model—如一个FSA，当输入超过三次的“你好”后，会输出“你有完没完”，输入超过四次“你好”后输出null)</li>
<li>Goal-based agents: Knowing something about the current state of the environment is not always enough to decide what to do. The agent needs some sort of goal information that describes situations that are desirable.(e.g. 比如设计一个用于解决推箱子问题的AI，它的goal是为了将所有的箱子按照一定的规则推到指定的位置)</li>
<li>Utility-based agents: Goals alone are not enough to generate high-quality behavior in most environments. For example, many action sequences will get the taxi to its destination (thereby achieving the goal) but some are quicker, safer, more reliable, or cheaper than others. Goals just provide a crude binary distinction between “happy” and “unhappy” states. An agent’s utility function is essentially an internalization of the performance measure.</li>
<li>Learning agents: Improving with experiencing</li>
</ol>
<blockquote>
<p>All agents can improve their performance through learning.</p>
</blockquote>
<h1 id="Chapter-III-SOLVING-PROBLEMS-BY-SEARCHING"><a href="#Chapter-III-SOLVING-PROBLEMS-BY-SEARCHING" class="headerlink" title="Chapter III SOLVING PROBLEMS BY SEARCHING"></a>Chapter III SOLVING PROBLEMS BY SEARCHING</h1><p><strong>How an agent can find a sequence of actions that achieves its goals when no single action will do.</strong></p>
<h2 id="3-1-Problem-solving-agents"><a href="#3-1-Problem-solving-agents" class="headerlink" title="3.1. Problem-solving agents"></a>3.1. Problem-solving agents</h2><p>Intelligent agents are supposed to maximize their performance measure. Achieving this is sometimes simplified if the agent can adopt a goal and aim at satisfying it.</p>
<p>A problem is defined by five components:</p>
<ol>
<li>The initial state that the agent starts in.</li>
<li>A description of the possible actions available to the agent. Given a particular state s, ACTIONS(s) returns the set of actions that can be executed in s.</li>
<li>A description of what each action does; the formal name for this is the <strong>transition model</strong>, specified by a function RESULT(s,a) that returns the state that results from doing action a in state s. </li>
<li>The goal test, which determines whether a given state is a goal state.</li>
<li>A path cost function that assigns a numeric cost to each path.</li>
</ol>
<blockquote>
<p>A solution to a problem is an action sequence that leads from the initial state to a goal state. Solution quality is measured by the path cost function, and an optimal solution has the lowest path cost among all solutions.</p>
</blockquote>
<h2 id="3-2-Examples"><a href="#3-2-Examples" class="headerlink" title="3.2 Examples"></a>3.2 Examples</h2><h2 id="3-3-Searching-for-Solutions"><a href="#3-3-Searching-for-Solutions" class="headerlink" title="3.3 Searching for Solutions"></a>3.3 Searching for Solutions</h2><p>Having formulated some problems, we now need to solve them. A solution is an action sequence, so search algorithms work by considering various possible action sequences.<strong> The possible action sequences starting at the initial state form a search tree with the initial state at the root; the branches are actions and the nodes correspond to states in the state space of the problem</strong>.</p>
<p>Then we need to consider taking various actions. We do this by expanding the current state; that is, applying each legal action to the current state, thereby generating a new set of states. </p>
<p>Search algorithms all share this basic structure; they vary primarily according to how they choose which state to expand next, which is called <strong>search strategy</strong>.</p>
<blockquote>
<p>Graph Search vs Tree Search: 在tree search中，我们可能会重复的陷入某一个redundant loop，而在graph search中，我们会记录我们所经过的node，确保我们不会浪费computing power在那些没有意义或者更加昂贵的solution上。</p>
</blockquote>
<p>Measuring problem-solving performances: 4-VALUES</p>
<ol>
<li>Completeness: Is the algorithm guaranteed to find a solution when there is one? </li>
<li>Optimality: Does the strategy find the optimal solution? </li>
<li>Time complexity: How long does it take to find a solution?</li>
<li>Space complexity: How much memory is needed to perform the search?</li>
</ol>
<h2 id="3-4-Uninformed-search-strategies"><a href="#3-4-Uninformed-search-strategies" class="headerlink" title="3.4 Uninformed search strategies"></a>3.4 Uninformed search strategies</h2><p>This section covers several search strategies that come under the heading of uninformed search (also called blind search). The term means that the strategies have no additional information about states beyond that provided in the problem definition. All they can do is generate successors and distinguish a goal state from a non-goal state. (想象身处于一个迷宫之中，你知道这个迷宫是有一个出口的，但是你并不确定这个出口具体的方位，你能做的就是盲目的前后左右去探索迷宫直至找到出口为止。)</p>
<h3 id="Breadth-first-search"><a href="#Breadth-first-search" class="headerlink" title="Breadth-first search"></a>Breadth-first search</h3><p>Breadth-first search is a simple strategy in which the root node is expanded first, then all the successors of the root node are expanded next, then their successors, and so on. In general, all the nodes are expanded at a given depth in the search tree before any nodes at the next level are expanded.</p>
<p>Breadth-first search is optimal if the path cost is a nondecreasing function of the depth of the node. The most common such scenario is that all actions have the same cost. And of course it is complete.</p>
<p>The time complexity and space complexity for it are both O(b<sup>d</sup>), b means the branching factor for each node, and d means the depth of the solution found. The memory requirements are a bigger problem for breadth-first search than is the execution time. One might wait 13 days for the solution to an important problem with search depth 12, but no personal computer has the petabyte of memory it would take. Fortunately, other strategies require less memory.</p>
<h3 id="Uniform-cost-search"><a href="#Uniform-cost-search" class="headerlink" title="Uniform cost search"></a>Uniform cost search</h3><p>When all step costs are equal, breadth-first search is optimal because it always expands the shallowest unexpanded node. By a simple extension, we can find an algorithm that is optimal with any step-cost function. Instead of expanding the shallowest node, <strong>uniform-cost search expands the node n with the lowest path cost g(n)</strong>. This is done by storing the frontier as a priority queue ordered by g. </p>
<p>Accoring to this description, it is not difficult to reach the conclusion that uniform cost search is optimal and complete</p>
<p>Uniform-cost search does not care about the number of steps a path has, but only about their total cost. Therefore, it will get stuck in an infinite loop if there is a path with an infinite sequence of zero-cost actions.</p>
<h3 id="Depth-first-search"><a href="#Depth-first-search" class="headerlink" title="Depth first search"></a>Depth first search</h3><p>Depth-first search always expands the deepest node in the current frontier of the search tree. The search proceeds immediately to the deepest level of the search tree, where the nodes have no successors. As those nodes are expanded, they are dropped from the frontier, so then the search “backs up” to the next deepest node that still has unexplored successors.</p>
<p>And we could find that breadth-first-search uses a FIFO queue, depth-first search uses a LIFO queue.</p>
<p>The properties of depth-first search depend strongly on whether the graph-search or tree-search version is used. The graph-search version, which avoids repeated states and redundant paths, is complete in finite state spaces because it will eventually expand every node. The tree-search version, on the other hand, is not complete (because that it may fall in a infinite redundant loop).</p>
<p>The advantage of DFS is the space complexity. For a graph search, there is no advantage, but a depth-first tree search needs to store only a single path from the root to a leaf node, along with the remaining unexpanded sibling nodes for each node on the path. </p>
<p>And DFS is complete, but not optimal assurance.</p>
<h3 id="Depth-limited-search"><a href="#Depth-limited-search" class="headerlink" title="Depth-limited search"></a>Depth-limited search</h3><p>The embarrassing failure of depth-first search in infinite state spaces can be alleviated by supplying depth-first search with a predetermined depth limit l. That is, nodes at depth l are treated as if they have no successors. This approach is called depth-limited search. The depth limit solves the infinite-path problem.</p>
<h3 id="Iterative-deepening-depth-first-search"><a href="#Iterative-deepening-depth-first-search" class="headerlink" title="Iterative deepening depth-first search"></a>Iterative deepening depth-first search</h3><p>Iterative deepening search (or iterative deepening depth-first search) is a general strategy, often used in combination with depth-first tree search, that finds the best depth limit. It does this by gradually increasing the limit—first 0, then 1, then 2, and so on—until a goal is found. This will occur when the depth limit reaches d, the depth of the shallowest goal node. </p>
<p> Like depth-first search, its memory requirements are modest: O(bd) to be precise. Like breadth-first search, it is complete when the branching factor is finite and optimal when the path cost is a nondecreasing function of the depth of the node.</p>
<p>In general, iterative deepening is the preferred uninformed search method when the search space is large and the depth of the solution is not known.</p>
<h3 id="Bidirectional-search"><a href="#Bidirectional-search" class="headerlink" title="Bidirectional search"></a>Bidirectional search</h3><p>The idea behind bidirectional search is to run two simultaneous searches—one forward from the initial state and the other backward from the goal—hoping that the two searches meet in the middle.</p>
<img src="/2018/12/20/Artificial-Intelligence/1.png">
<h2 id="3-5-Informed-Heuristic-Search-Strategies"><a href="#3-5-Informed-Heuristic-Search-Strategies" class="headerlink" title="3.5 Informed (Heuristic) Search Strategies"></a>3.5 Informed (Heuristic) Search Strategies</h2><p>This section shows how an informed search strategy—one that uses problem-specific knowledge beyond the definition of the problem itself—can find solutions more efficiently than can an uninformed strategy.(尽管我们依然身在迷宫之中，但是我们已经知道迷宫的出口在东北方向，那么直觉上我们会觉得东北方的路会有更大的可能能够带我们走出迷宫。)</p>
<p>The evaluation function f(n) is construed as a cost estimate, so the node with the lowest evaluation is expanded first. Which means that it is the cost from the initial state to the goal state, even if this cost is estimated a lot. </p>
<p>The heuristic function h(n) is estimated cost of the cheapest path from the state at node n to a goal state.</p>
<h3 id="Greedy-best-first-search"><a href="#Greedy-best-first-search" class="headerlink" title="Greedy best first search"></a>Greedy best first search</h3><p>Greedy best-first search tries to expand the node that is closest to the goal, on the grounds that this is likely to lead to a solution quickly. </p>
<p>And here in this search f(n)=h(n). (这也就是Greedy Best Search与A*的最大区别，我们只考虑哪个next state是最优的，无论从当前的state到这个next state的path cost是多少。)</p>
<h3 id="A-search-Minimizing-the-total-estimated-solution-cost"><a href="#A-search-Minimizing-the-total-estimated-solution-cost" class="headerlink" title="A* search: Minimizing the total estimated solution cost"></a>A* search: Minimizing the total estimated solution cost</h3><p>The most widely used form of best-first search is called A<em> search. It evaluates nodes by combining <em>*g(n), the cost to reach the node, and h(n), the cost to get from the node to the goal</em></em>: f(n)=g(n)+h(n)</p>
<p>And here <strong>f(n) = estimated cost of the cheapest solution through n</strong>. Thus if we are trying to find the cheapest solution, a reasonable thing is to find the lowest f(n).</p>
<blockquote>
<p>Conditions for optimality: Admissibility and consistency</p>
<p>The first condition we require for optimality is that h(n) be an admissible heuristic. <strong>An admissible heuristic is one that never overestimates the cost to reach the goal</strong>. Because g(n) is the actual cost to reach n along the current path, and f (n) = g(n) + h(n), we have as an immediate consequence that f(n) never overestimates the true cost of a solution along the current path through n.</p>
<p>A second, slightly stronger condition called consistency (or sometimes monotonicity) is required only for applications of A<em> to graph search. A heuristic h(n) is consistent if, for every node n1 and every successor n2 of n1 generated by any action a, the estimated cost of reaching the goal from n2 is no greater than the step cost of getting to n2 plus the estimated cost of reaching the goal from n1: <em>*h(n1) ≤ c(n1, a, n2) + h(n2)</em></em></p>
</blockquote>
<p>A<em> has the following properties: the tree-search version of A</em> is optimal if h(n) is admissible, while the graph-search version is optimal if h(n) is consistent.</p>
<p>That A<em> search is complete, optimal, and optimally efficient among all such algorithms is rather satisfying. Unfortunately, it does not mean that A</em> is the answer to all our searching needs. The catch is that, for most problems, the number of states within the goal contour search space is still exponential in the length of the solution. And A<em> requires a high amount of space usage. This may be the biggest disadvantage of A</em>.</p>
<h3 id="Memory-bounded-heuristic-search"><a href="#Memory-bounded-heuristic-search" class="headerlink" title="Memory-bounded heuristic search."></a>Memory-bounded heuristic search.</h3><p>The simplest way to reduce memory requirements for A<em> is to adapt the idea of iterative deepening to the heuristic search context, resulting in the iterative-deepening A</em> (IDA*) algorithm. </p>
<p>The main difference between IDA<em> and standard iterative deepening is that the cutoff used is the f-cost (</em>g + h*) rather than the depth; at each iteration, the cutoff value is the smallest f-cost of any node that exceeded the cutoff on the previous iteration. RBFS is a great example in this search method. </p>
<p>RBFS is similar to that of a recursive depth-first search, but rather than continuing indefinitely down the current path, it uses the f limit variable to keep track of the f-value of the best alternative path available from any ancestor of the current node. If the current node exceeds this limit, the recursion unwinds back to the alternative path. As the recursion unwinds, RBFS replaces the f-value of each node along the path with a backed-up value—–the best f-value of its children. In this way, RBFS remembers the f-value of the best leaf in the forgotten subtree and can therefore decide whether it’s worth reexpanding the subtree at some later time. RBFS is somewhat more efficient than IDA<em>, but still suffers from excessive node re-generation. (RBFS的优点在于，A</em>是一种在结构上与BFS有某些相同之处的算法，在探索树的过程中，如果足够深的话将会需要存储O(b<sup>d</sup>的nodes，这往往超过了我们能够容忍的space complexity，故我们采用RBFS，因为RBFS按照相同的原理选择下一个探索的点，但是一旦RBFS发现当前的路线的cost不是最优，就会unwind(先朝向root的方向然后再向下找当前最优cost的位置)，到达当前的最优的node，这样似乎没有产生什么好处，但是恰恰相反，在unwind的过程中，RBFS会更新路径上的点的h，因为这些h欺骗了RBFS的感情，当前的路径并不是最优的！同时RBFS也并不储存哪些点已经被expand了，下次如果revisit了这个点，那么重新计算就是了，RBFS就是使用这种方法来牺牲time来换取space。)</p>
<h3 id="Learning-to-search-better"><a href="#Learning-to-search-better" class="headerlink" title="Learning to search better"></a>Learning to search better</h3><h2 id="3-6-Heuristic-Functions"><a href="#3-6-Heuristic-Functions" class="headerlink" title="3.6 Heuristic Functions"></a>3.6 Heuristic Functions</h2><p>In this part, we are going to discuss how to find a heuristic function and the importance of a good heuristic function.</p>
<h2 id="3-7-SUMMARY"><a href="#3-7-SUMMARY" class="headerlink" title="3.7 SUMMARY"></a>3.7 SUMMARY</h2><p>Before an agent can start searching for solutions, a goal must be identified and a well- defined problem must be formulated.</p>
<p>• A problem consists of five parts: the initial state, a set of actions, a transition model describing the results of those actions, a goal test function, and a path cost function. The environment of the problem is represented by a state space. A path through the state space from the initial state to a goal state is a solution.</p>
<p>• Search algorithms treat states and actions as atomic: they do not consider any internal structure they might possess.</p>
<p>• A general TREE-SEARCH algorithm considers all possible paths to find a solution, whereas a GRAPH-SEARCH algorithm avoids consideration of redundant paths.</p>
<p>• Search algorithms are judged on the basis of completeness, optimality, time complexity, and space complexity. Complexity depends on b, the branching factor in the state space, and d, the depth of the shallowest solution.</p>
<p>• Uninformed search methods have access only to the problem definition. The basic algorithms are as follows:</p>
<ul>
<li><p>Breadth-first search expands the shallowest nodes first; it is complete, optimal for unit step costs, but has exponential space complexity.</p>
</li>
<li><p>Uniform-cost search expands the node with lowest path cost, g(n), and is optimal for general step costs.</p>
</li>
<li><p>Depth-first search expands the deepest unexpanded node first. It is neither com- plete nor optimal, but has linear space complexity. Depth-limited search adds a depth bound.</p>
</li>
<li><p>Iterative deepening search calls depth-first search with increasing depth limits until a goal is found. It is complete, optimal for unit step costs, has time complexity comparable to breadth-first search, and has linear space complexity.</p>
</li>
<li><p>Bidirectional search can enormously reduce time complexity, but it is not always applicable and may require too much space.</p>
</li>
</ul>
<p>• Informed search methods may have access to a heuristic function h(n) that estimates the cost of a solution from n.</p>
<ul>
<li><p>The generic best-first search algorithm selects a node for expansion according to an evaluation function.</p>
</li>
<li><p>Greedy best-first search expands nodes with minimal h(n). It is not optimal but is often efficient.</p>
</li>
<li><p>A∗ search expands nodes with minimal f (n) = g(n) + h(n). A∗ is complete and optimal, provided that h(n) is admissible (for TREE-SEARCH) or consistent (for GRAPH-SEARCH). The space complexity of A∗ is still prohibitive.</p>
</li>
<li><p>RBFS (recursive best-first search) and SMA∗ (simplified memory-bounded A∗) are robust, optimal search algorithms that use limited amounts of memory; given enough time, they can solve problems that A∗ cannot solve because it runs out of memory. [<a href="https://www.slideshare.net/navidasadi1/an-example-of-using-rbfs-recursive-best-first-search-algorithm" target="_blank" rel="noopener">https://www.slideshare.net/navidasadi1/an-example-of-using-rbfs-recursive-best-first-search-algorithm</a>]</p>
</li>
</ul>
<p>• The performance of heuristic search algorithms depends on the quality of the heuristic function. One can sometimes construct good heuristics by relaxing the problem defi- nition, by storing precomputed solution costs for subproblems in a pattern database, or by learning from experience with the problem class.</p>
<h1 id="Chapter-V-ADVERSARIAL-SEARCH"><a href="#Chapter-V-ADVERSARIAL-SEARCH" class="headerlink" title="Chapter V: ADVERSARIAL SEARCH"></a>Chapter V: ADVERSARIAL SEARCH</h1><p>We try to plan ahead in a world where other agents are planning against us.</p>
<h2 id="5-1-Games"><a href="#5-1-Games" class="headerlink" title="5.1 Games"></a>5.1 Games</h2><p>Games is a problem that each agents needs to consider the actions of other agents and how they affact itw own welfare. Due to the great search space, the search algorithms introduced in Chapter III may not be applicable.</p>
<p>We begin with a definition of the optimal move and an algorithm for finding it. We then look at techniques for choosing a good move when time is limited. Pruning allows us to ignore portions of the search tree that make no difference to the final choice, and heuristic evaluation functions allow us to approximate the true utility of a state without doing a complete search. Section 5.5 discusses games such as backgammon that <strong>include an element of chance</strong>; we also discuss bridge, which <strong>includes elements of imperfect information</strong> because not all cards are visible to each player. Finally, we look at how state-of-the-art game-playing programs fare against human opposition and at directions for future developments.</p>
<p>We first consider games with two palyer, whom we call MAX and MIN. MAX moves first and then they take turns until the game is over. </p>
<blockquote>
<p>In formal language, It could be described as</p>
<p>S0: The initial state, which specifies how the game is set up at the start.<br>PLAYER(s): Defines which player has the move in state s.<br>ACTIONS(s): Returns the set of legal moves in state s.<br>RESULT(s,a): The transition model, which defines the result of a move, which is another state.<br>TERMINAL-TEST(s): A terminal test, which is true when the game is over and false otherwise. States where the game has ended are called terminal states.<br>UTILITY(s, p): A utility function (also called an objective function or payoff function), defines the final numeric value for a game that ends in terminal state s for a player p. <strong>In chess, the outcome is a win, loss, or draw, with values +1, 0, or 1</strong>. Some games have a wider variety of possible outcomes; Chess is zero-sum. “Constant-sum” would have been a better term, but zero-sum is traditional and makes sense if you imagine each player is charged an entry fee of 1/2, and end with 0 or 1.</p>
</blockquote>
<p>The formal definition above help us to build a tree, while in general games, this tree would be too large to build. And in fact the main idea is that <strong>we don’t need to know the complete tree, we just need to build tree examining enough nodes to make a smart move</strong>.</p>
<h2 id="5-2-Opttimal-decisions-in-games"><a href="#5-2-Opttimal-decisions-in-games" class="headerlink" title="5.2 Opttimal decisions in games"></a>5.2 Opttimal decisions in games</h2><p>Given a game tree, the optimal strategy can be determined from the minimax value of each node n, which we write as MINIMAX(n). This values of a terminal state is just its utility. Furthermore, given a choice, MAX prefers to move to a state of maximum value, while MIN prefers a state of minimum value. </p>
<img src="/2018/12/20/Artificial-Intelligence/2.png">
<p>[Here in the above picture, s means node n]</p>
<img src="/2018/12/20/Artificial-Intelligence/3.png">
<h3 id="The-minimax-algorithm"><a href="#The-minimax-algorithm" class="headerlink" title="The minimax algorithm"></a>The minimax algorithm</h3><p>minimax algorithm为每个state s都计算其MINIMAX(s)，从最底下的ternimal states开始，首先通过terminal state计算utility，然后向上根据min或者max更新父节点的utility，直至更新完完整的树，这种方法虽然在实际中是行不通的，但是本章所有的方法其实都建立在minimax algorithm的基础上。</p>
<h3 id="Mutipleplayer-games-gt-2"><a href="#Mutipleplayer-games-gt-2" class="headerlink" title="Mutipleplayer games (&gt;=2)"></a>Mutipleplayer games (&gt;=2)</h3><img src="/2018/12/20/Artificial-Intelligence/4.png">
<p>Actually this is vaery same like the minimax algorithm, while in each nodes we assign a vector (length equal to the number of players). And each level we choose the max/min by the vectors due to the values in certain dimension.</p>
<h2 id="5-3-Alpha-Beta-Pruning"><a href="#5-3-Alpha-Beta-Pruning" class="headerlink" title="5.3 Alpha-Beta Pruning"></a>5.3 Alpha-Beta Pruning</h2><p>minimax的问题在于game states的数量实在是过于庞大(exponential)，但、是其实我们可以通过pruning有效的减小树的规模，在adversial search中常用的方法是apha-beta pruning。对于一棵标准的minimax树，我们可以去除那些永远都不会影响到我们最终决定的子树。我们在上面的minmax的例子中不难看出，minimax的tree是我们需要每一个terminal state的utility，然后才得以建立的complete search tree。而alpha beta pruning的核心就是，假如我（MAX）目前的最好选择是3，那么某个action a3后如果对手有一种选择可能导致2，那么我们根本不需要考虑这个action a3，因为对手不是笨蛋，一定会做出那种让我们得到2的action a’，所以我们就将这个action a3给prune掉了（即不考虑掉了）。</p>
<img src="/2018/12/20/Artificial-Intelligence/5.png">
<p><a href="https://www.jianshu.com/p/3b464aeba078" target="_blank" rel="noopener">link1 for Alpha-Beta Pruning</a></p>
<p><a href="http://inst.eecs.berkeley.edu/~cs61b/fa14/ta-materials/apps/ab_tree_practice/" target="_blank" rel="noopener">link2 for Alpha-Beta Pruning</a></p>
<h2 id="5-4-Imperfect-Real-Time-Decisions"><a href="#5-4-Imperfect-Real-Time-Decisions" class="headerlink" title="5.4 Imperfect Real-Time Decisions"></a>5.4 Imperfect Real-Time Decisions</h2><p>在minimax算法中，我们需要创造一棵完整的树，尽管alpha-beta剪枝帮助我们缩减了这棵树的规模，但是通常情况下这棵树的深度依然过于庞大。所以在本节中，我们使用一个heuristic evaluation function来将那些non-terminal nodes转化成terminal leaves。</p>
<img src="/2018/12/20/Artificial-Intelligence/6.png">
<blockquote>
<p>Evaluation function:evaluation function的作用是对于一个given position of game(state)，返回一个estimation of the expected utility。</p>
</blockquote>
<h2 id="5-5-Stochastic-Games"><a href="#5-5-Stochastic-Games" class="headerlink" title="5.5 Stochastic Games"></a>5.5 Stochastic Games</h2><p>在实际中，我们常常需要面对受概率影响的随机情况，因此我们无法像是在之前的情况中一样构建树，我们需要构建的是一棵随机树。</p>
<img src="/2018/12/20/Artificial-Intelligence/7.png">
<p>为了作出最优的决定，我们需要为每个nodes计算expecti-minimax values。换而言之，我们的策略可以概括为<strong>尽人事知天命</strong>。</p>
<img src="/2018/12/20/Artificial-Intelligence/8.png">
<h2 id="5-7-State-Of-The-Art-Game-Programs"><a href="#5-7-State-Of-The-Art-Game-Programs" class="headerlink" title="5.7 State Of The Art Game Programs"></a>5.7 State Of The Art Game Programs</h2><h2 id="5-8-Alternative-Approaches"><a href="#5-8-Alternative-Approaches" class="headerlink" title="5.8 Alternative Approaches"></a>5.8 Alternative Approaches</h2><p>精准的计算optimal decision在大部分的情况下是无法处理的，实际中所有的算法都或多或少的进行了一定程度的近似和假设。</p>
<h2 id="5-9-Summary"><a href="#5-9-Summary" class="headerlink" title="5.9 Summary"></a>5.9 Summary</h2><p>• A game can be defined by the initial state (how the board is set up), the legal actions in each state, the result of each action, a terminal test (which says when the game is over), and a utility function that applies to terminal states.</p>
<p>• In two-player zero-sum games with perfect information, the minimax algorithm can select optimal moves by a depth-first enumeration of the game tree.</p>
<p>• The alpha–beta search algorithm computes the same optimal move as minimax, but achieves much greater efficiency by eliminating subtrees that are provably irrelevant.</p>
<p>• Usually, it is not feasible to consider the whole game tree (even with alpha–beta), so we need to cut the search off at some point and apply a heuristic evaluation function that estimates the utility of a state.</p>
<p>• Many game programs precompute tables of best moves in the opening and endgame so that they can look up a move rather than search.</p>
<p>• Games of chance can be handled by an extension to the minimax algorithm that eval- uates a chance node by taking the average utility of all its children, weighted by the probability of each child.</p>
<h1 id="Chapter-VI-CONSTRAINT-SATISFACTION-PROBLEMS"><a href="#Chapter-VI-CONSTRAINT-SATISFACTION-PROBLEMS" class="headerlink" title="Chapter VI: CONSTRAINT SATISFACTION PROBLEMS"></a>Chapter VI: CONSTRAINT SATISFACTION PROBLEMS</h1><p>This chapter describes a way to solve certain problems more efficiently. We used a factored representation for each state: a set of variables, each has a value. And a problem is solved when each variable has a value that satisfies all the constraints. A problem described this way is called a constraint satisfcation problem, CSP in short.</p>
<p>CSP search algorithms take advantage of the structure of states and use general-purpose rather than problem-specific heuristics to enable the solution of complex problems.(我们不需要根据每一个问题去设计一个heuristic function，我们只需要使用general的least remaining values策略进行搜索即可) The main idea is to eliminate large portions of the search space all at once by identifying variable/value combinations that violate the constraints.</p>
<h2 id="6-1-Defining-CSP"><a href="#6-1-Defining-CSP" class="headerlink" title="6.1 Defining CSP"></a>6.1 Defining CSP</h2><p>A constraint satisfaction problem consists of three components, X, D, and C : </p>
<ol>
<li>X is a set of variables, {X1,…,Xn}.</li>
<li>D is a set of domains, {D1, . . . , Dn}, one for each variable.</li>
<li>C is a set of constraints that specify allowable combinations of values.</li>
</ol>
<h2 id="6-2-Constraint-propagation-inference-in-CSPs"><a href="#6-2-Constraint-propagation-inference-in-CSPs" class="headerlink" title="6.2 Constraint propagation: inference in CSPs"></a>6.2 Constraint propagation: inference in CSPs</h2><p>In regular state-space search, an algorithm can do only one thing: search. In CSPs there is a choice: an algorithm can search (choose a new variable assignment from several possibilities) or <strong>do a specific type of inference called constraint propagation: using the constraints to reduce the number of legal values for a variable, which can reduce the legal values for another variables</strong>.</p>
<p>THe key idea is <strong>local consistency</strong>, If we treat each variable as a node in a graph and each binary constraint as an arc, then the process of enforcing local consistency in each part of the graph causes inconsistent values to be eliminated throughout the graph. </p>
<h3 id="Node-Consistency"><a href="#Node-Consistency" class="headerlink" title="Node Consistency"></a>Node Consistency</h3><p>A single variable (corresponding to a node in the CSP network) is node-consistent if all the values in the variable’s domain satisfy the variable’s unary constraints. (e.g.在地图染色问题中，我们使用红黄蓝将不同的区域染色，假如我们将一个区域A染色为红色，那么对于一个和A相邻的区域B来说，对于B的Domain本来是{红，黄，蓝}三种选择，但是为了使B node consistent,也就是对于B domain中任何一个value都满足我们的constraint-“相邻的区域颜色不同”，那么我们需要将B的domain修改为{黄，蓝}，这个时候我们说B是node consistent，如果对于graph中的每一个点都node cnsistent，那么我们说这个graph是node consistent的)</p>
<h3 id="Arc-Consistency"><a href="#Arc-Consistency" class="headerlink" title="Arc Consistency"></a>Arc Consistency</h3><p>A variable in a CSP is arc-consistent if every value in its domain satisfies the variable’s binary constraints. More formally, Xi is arc-consistent with respect to another variable Xj if for every value in the current domain Di there is some value in the domain Dj that satisfies the binary constraint on the arc (Xi,Xj). (e.g. 比如一个对于variable X和Y的constraint：Y=X<sup>2</sup>，为了使X相对于Y arc consistent，那么我们可以将X的domain设为{0,1,2,3}，将Y的domain设为{0,1,4,9})</p>
<p>The most popular algorithm for arc consistency is called AC-3. To make every variable arc-consistent, the AC-3 algorithm maintains a queue of arcs to consider.[<a href="https://stackoverflow.com/questions/28257422/ac-1-ac-2-and-ac-3-algorithms-arc-consistency" target="_blank" rel="noopener">https://stackoverflow.com/questions/28257422/ac-1-ac-2-and-ac-3-algorithms-arc-consistency</a>]</p>
<blockquote>
<p>AC-3: Initially, the queue contains all the arcs in the CSP. AC-3 then pops off an arbitrary arc (Xi , Xj ) from the queue and makes Xi arc-consistent with respect to Xj . If this leaves Di unchanged, the algorithm just moves on to the next arc. But if this revises Di (makes the domain smaller), then we add to the queue all arcs (Xk,Xi) where Xk is a neighbor of Xi. We need to do that because the change in Di might enable further reductions in the domains of Dk, even if we have previously considered Xk. If Di is revised down to nothing, then we know the whole CSP has no consistent solution, and AC-3 can immediately return failure. Otherwise, we keep checking, trying to remove values from the domains of variables until no more arcs are in the queue. At that point, we are left with a CSP that is equivalent to the original CSP—they both have the same solutions—but the arc-consistent CSP will in most cases be faster to search because its variables have smaller domains. (AC-3可以如下描述，我们对于一个graph而言，有诸多的node和arc需要去考虑，对于每一个node都对应一个domain，那么我们建立一个queue包含所有的arc，我们从queue中挑选一个arc (X<sub>i</sub>,X<sub>j</sub>)，检查这个arc是否consistent，如果不consistent，那么我们就修改domain，如果X<sub>i</sub>的domain D<sub>i</sub>被修改，那么就将所有的arc (X<sub>k</sub>,X<sub>i</sub>), k is a neighbor of i,添加进我们的queque中。如果D<sub>i</sub>为空，证明当前CSP没有consistent的solution，而AC-3也会返回一个failure，不然的话我们就可以一直进行这个过程，直到queue中不包含任何arc为止，此时我们得到的一个图，其拓扑结构没有任何改变，但是对于一个node而言，他的D<sub>i</sub>极大的减小了，这为我们后续的搜素提供了便利。)</p>
</blockquote>
<h3 id="Path-Consistency"><a href="#Path-Consistency" class="headerlink" title="Path Consistency"></a>Path Consistency</h3><p>Consider the map-coloring problem on Australia, but with only two colors allowed, red and blue. Arc consistency can do nothing because every variable is already arc consistent: each can be red with blue at the other end of the arc (or vice versa). But clearly there is no solution to the problem. we need at least three colors for them alone.</p>
<p>Arc consistency tightens down the domains (unary constraints) using the arcs (binary constraints). To make progress on problems like map coloring, we need a stronger notion of consistency. Path consistency tightens the binary constraints by using implicit constraints that are inferred by looking at triples of variables.</p>
<p>A two-variable set {Xi,Xj} is path-consistent with respect to a third variable Xm if, for every assignment {Xi = a, Xj = b} consistent with the constraints on {Xi , Xj }, there is an assignment to Xm that satisfies the constraints on {Xi , Xm } and {Xm , Xj }. This is called path consistency. (e.g. 我们上面提到了，在地图染色问题中，假如每一个node的domain都是{红，黄}，显然这个graph是arc consistent的，但是这个CSP问题也很明显是unsolvable，但是如果我们用path consistency去检验，那么我们对于三个相邻的区域A，B，C，我们可以看到{A,B}和C不是path consistency的，当A和B各取到红、黄的时候，对于C没有一个assignment可以满足我们的constraint。)</p>
<h3 id="K-consistency"><a href="#K-consistency" class="headerlink" title="K-consistency"></a>K-consistency</h3><p>Stronger forms of propagation can be defined with the notion of k-consistency. A CSP is k-consistent if, for any set of k − 1 variables and for any consistent assignment to those variables, a consistent value can always be assigned to any kth variable. (任意选取K-1个nodes，对于第K个node我们总能为他assign一个value使其consistent)。</p>
<h3 id="Global-Constraints"><a href="#Global-Constraints" class="headerlink" title="Global Constraints"></a>Global Constraints</h3><p>Remember that a global constraint is one involving <strong>an arbitrary number of variables</strong> (but not necessarily all variables). Global constraints occur frequently in real problems and can be handled by special-purpose algorithms that are more efficient than the general-purpose methods described so far.</p>
<h2 id="6-3-Backtracking-search-for-CSPs"><a href="#6-3-Backtracking-search-for-CSPs" class="headerlink" title="6.3 Backtracking search for CSPs"></a>6.3 Backtracking search for CSPs</h2><p>For a real Sudoku example, we could apply a standard depth limited search. While it is quite obvious that the states are too large to build.(CSP的核心思路就是，在知道我们当前的state后，如当前的格子是1，我们不应该探索那些不可能的choice，比如同一列中没有必要再去探索1的可能性，因为根据数独的性质，每行的数字都是唯一的)</p>
<p>The term <strong>backtracking search</strong> is used for a DFS that <strong>chooses values for one variables at a time, and backtracks when a variable has no legal values left to assign</strong>. </p>
<img src="/2018/12/20/Artificial-Intelligence/9.png">
<p>Just like we improve uninformed search, we could apply some techniques to improve the performance of backtracking with following directions:</p>
<ol>
<li>Which variable should be assigned next (SELECT-UNASSIGNED-VARIABLE), and in what order should its values be tried (ORDER-DOMAIN-VALUES)?</li>
<li>What inferences should be performed at each step in the search (INFERENCE)?</li>
<li>When the search arrives at an assignment that violates a constraint, can the search avoid repeating this failure?</li>
</ol>
<h3 id="Value-and-value-ordering"><a href="#Value-and-value-ordering" class="headerlink" title="Value and value ordering"></a>Value and value ordering</h3><h4 id="Which-variable-should-be-assigned-next"><a href="#Which-variable-should-be-assigned-next" class="headerlink" title="Which variable should be assigned next?"></a>Which variable should be assigned next?</h4><p>One of the most important step in Backtracking problems is that select unassigned variables and assign it certain values. And the most important strategy is called the <strong>minimum remaining value (MRV) search</strong>. It is also called the most constraint variable heuristic. The general idea is to <strong>choose the variable with the fewest legal values</strong>.</p>
<p>Another idea is known as <strong>degree heuristic</strong>. It attempts to <strong>select the variable that is involved in the largest number of constraints on other unassigned values</strong>.(比如在地图染色问题中，因为对于每一个node的domain都是{红，黄，蓝}，所以很难根据MRV做出选择，而实际上，我们会优先选择那些会对其neighbor施加更多的约束的node，比如更靠中心的区域，或者与更多区域接邻的区域)</p>
<h4 id="In-what-order-should-its-values-be-tried"><a href="#In-what-order-should-its-values-be-tried" class="headerlink" title="In what order should its values be tried?"></a>In what order should its values be tried?</h4><p>Once a variable has been selected, wthe algorithm has to decide on the order in which to examine values (constraints propagation). And the <strong>lest-constraining-value heuristic</strong> can be effective in some cases. It <strong>prefers the value that rule out/eliminate the fewest choices for the neighboring variables in the constraint graph</strong>. (为未来留出更多的可能性)</p>
<h3 id="Interleaving-search-and-inference"><a href="#Interleaving-search-and-inference" class="headerlink" title="Interleaving search and inference"></a>Interleaving search and inference</h3><p><strong>So far we have seen how AC-3 and other algorithms can infer reductions in the domain of variables before we begin the search</strong>. But inference can be even more powerful in the course of a search: every time we make a choice of a value for a variable, we have a brand-new opportunity to infer new domain reductions on the neighboring variables.</p>
<p>One of the simplest forms of inference is called <strong>forward checking</strong>. Whenever a variable X is assigned, the forward-checking process establishes arc consistency for it: <strong>for each unassigned variable Y that is connected to X by a constraint, delete from Y ’s domain any value that is inconsistent with the value chosen for X.</strong>(这与AC-3不同，AC-3检测的是整个graph中的arc consistency，然而forward checking只对于当前选择的node X进行arc consistency检测，删除那些与X通过constraint相连的nodes Y种的illegal values)</p>
<img src="/2018/12/20/Artificial-Intelligence/10.png">
<p>For many problems the search will be more effective if we combine the MRV heuristic with forward checking.(而在上图中，显然没有使用MRV)</p>
<p>Although forward checking detects many inconsistencies, it does not detect all of them. The problem is that it makes the current variable arc-consistent, but doesn’t look ahead and make all the other variables arc-consistent. For example, consider the third row of above picture. It shows that when WA is red and Q is green , both NT and SA are forced to be blue. <strong>Forward checking does not look far enough ahead</strong> to notice that this is an inconsistency: NT and SA are adjacent and so cannot have the same value.</p>
<p><em>The algorithm called MAC (for Maintaining Arc Consistency (MAC)) detects this inconsistency. After a variable Xi is assigned a value, the INFERENCE procedure calls AC-3, but instead of a queue of all arcs in the CSP, we start with only the arcs (Xj,Xi) for all Xj that are unassigned variables that are neighbors of Xi. From there, AC-3 does constraint propagation in the usual way, and if any variable has its domain reduced to the empty set, the call to AC-3 fails and we know to backtrack immediately.</em></p>
<h3 id="Intelligent-Backtracking-Looking-backward"><a href="#Intelligent-Backtracking-Looking-backward" class="headerlink" title="Intelligent Backtracking: Looking backward"></a>Intelligent Backtracking: Looking backward</h3><p>The BACKTRACKING-SEARCH algorithm in above picture has a very simple policy for what to do when a branch of the search fails: back up to the preceding variable and try a different value for it. This is called <strong>chronological backtracking</strong> because the most recent decision point is revisited. In this subsection, we consider better possibilities.</p>
<p>A more intelligent approach to backtracking is to backtrack to a variable that might fix the problem—a variable that was responsible for making one of the possible values of SA impossible. To do this, we will keep track of a set of assignments that are in conflict with some value for SA. The set (in this case {Q=red,NSW =green,V =blue,}), is called the conflict set for SA. The backjumping method backtracks to the most recent assignment in the conflict set; in this case, backjumping would jump over Tasmania and try a new value for V . This method is easily implemented by a modification to BACKTRACK such that it accumulates the conflict set while checking for a legal value to assign. If no legal value is found, the algorithm should return the most recent element of the conflict set along with the failure indicator. (正如同它的名字描述的那样，intelligent backtracking是一种基于backtracking更加智能的方法，在普通的back tracking中，我们知道每当侦测到一个failure，我们backtrack回到上一层，但是这样往往也不能够得到正确的solution，而intelligent backtracking是一种“更聪明的”backtracking方法，它能够backtrack到导致了当前矛盾的value assignment，然后重新search)</p>
<h1 id="Chapter-VII-LOGICAL-AGENTS"><a href="#Chapter-VII-LOGICAL-AGENTS" class="headerlink" title="Chapter VII: LOGICAL AGENTS"></a>Chapter VII: LOGICAL AGENTS</h1><p>How the intelligence of humans is achieved—<strong>not by purely reflex mechanisms but by processes of reasoning that operate on internal representations of knowledge</strong>. In AI, this approach to intelligence is embodied in knowledge-based agents.</p>
<h2 id="7-1-Knowledge-based-agents"><a href="#7-1-Knowledge-based-agents" class="headerlink" title="7.1 Knowledge-based agents"></a>7.1 Knowledge-based agents</h2><p>The central component of a knowledge-based agent is its knowledge base, or KB. A knowledge base is a set of sentences. Each sentence is expressed in a language called a <strong>knowledge representation language</strong> and represents some assertion about the world. Sometimes we dignify a sentence with the name axiom, when the sentence is taken as given without being derived from other sentences.</p>
<p>There must be a way to add new sentences to the knowledge base and a way to query what is known. The standard names for these operations are TELL and ASK, respectively. Both operations may involve inference—that is, <strong>deriving new sentences from old</strong>. Inference must obey the requirement that when one ASKs a question of the knowledge base, the answer should follow from what has been told (or TELLed) to the knowledge base previously.</p>
<p>Like every agents, a KB agents takes a percept as input and returns an action. The agent maintains a knowledge base KB, which is known as knowledge base.</p>
<p>Each time the agent is called, it does 3 things:</p>
<ol>
<li>it tells the KB what it perceives.</li>
<li>it asks the knowledge base what actions it should take</li>
<li>it tells the KB which action has been chosen and executes the action.</li>
</ol>
<h2 id="7-3-Logic"><a href="#7-3-Logic" class="headerlink" title="7.3 Logic"></a>7.3 Logic</h2><p>syntax:语言必须要遵守的规则</p>
<p>semantics:语句的实际含义(defines the truth of each sentence in the world)</p>
<p>model: <em>Informally, we may think of an example, having x men and y women sitting at a table playing bridge, and the sentence x + y = 4 is true when there are four people in total.</em> Formally, the possible models are just all possible assignments of real numbers to the variables x and y. Each such assignment fixes the truth of any sentence of arithmetic whose variables are x and y. If a sentence α is true in model m, we say that <strong>m satisfies α</strong> or <strong>m is a model of α</strong>. We use the notation M(α) to mean the set of all models of α.</p>
<p>logical entailment [α |= β]: α |= β if and only if, in every model in which α is true, β is also true. (α |= β iff M ( α ) ⊆ M ( β ) .)</p>
<p><a href="https://math.stackexchange.com/questions/655457/when-do-we-use-entailment-vs-implication" target="_blank" rel="noopener">entailment vs inference</a>:In understanding entailment and inference, it might help to think of the set of all consequences of KB as a haystack and of α as a needle. Entailment is like the needle being in the haystack; inference is like finding it. </p>
<blockquote>
<p>Logical inference</p>
<p>Model checking</p>
</blockquote>
<p>An inference algorithm that derives only entailed sentences is called sound or truth-preserving. Soundness is a highly desirable property. An unsound inference procedure essentially makes things up as it goes along—it announces the discovery of nonexistent needles.</p>
<p>The property of completeness is also desirable: an inference algorithm is complete if it can derive any sentence that is entailed. For real haystacks, which are finite in extent, it seems obvious that a systematic examination can always decide whether the needle is in the haystack.</p>
<h2 id="7-4-Propositional-Logic-A-very-simple-logic"><a href="#7-4-Propositional-Logic-A-very-simple-logic" class="headerlink" title="7.4 Propositional Logic: A very simple logic"></a>7.4 Propositional Logic: A very simple logic</h2><h3 id="Syntax"><a href="#Syntax" class="headerlink" title="Syntax"></a>Syntax</h3><p>The syntax of propositional logic defines the allowable sentences. The atomic sentences consist of a single proposition symbol. Each symbol stands for a propositional that can be true or false.</p>
<p>Complex sentences are constructed from simpler sentences, by parentheses and logical connectives(¬,∧,∨,⇒,⇔).</p>
<h3 id="Semantics"><a href="#Semantics" class="headerlink" title="Semantics"></a>Semantics</h3><img src="/2018/12/20/Artificial-Intelligence/11.png">
<h2 id="7-5-Propositional-Theorem-Proving"><a href="#7-5-Propositional-Theorem-Proving" class="headerlink" title="7.5 Propositional Theorem Proving"></a>7.5 Propositional Theorem Proving</h2><p>So far, we have shown how to determine entailment by model checking: enumerating models and showing that the sentence must hold in all models. In this section, we show how entailment can be done by theorem proving: applying rules of inference directly to the sentences in our knowledge base to construct a proof of the desired sentence without consulting models.</p>
<p><strong>Logical equivalence</strong>: two sentences α and β are logically equivalent if they are true in the same set of models.  [α≡β iff α|=β and β|=α]</p>
<p><strong>Validity</strong>: A sentence is valid if it is true in all models. For example, the sentence P ∨ ¬P is valid. </p>
<blockquote>
<p>For any sentences α and β, α |= β if and only if the sentence (α ⇒ β) is valid.</p>
</blockquote>
<p><strong>Satisfiability</strong>: A sentence is satisfiable if it is true in, or satisfied by some model.</p>
<h3 id="Inference-and-proof"><a href="#Inference-and-proof" class="headerlink" title="Inference and proof"></a>Inference and proof</h3><p><strong>Modus Ponens</strong>: α ⇒ β, α then β is true</p>
<h3 id="Proof-by-resolution"><a href="#Proof-by-resolution" class="headerlink" title="Proof by resolution"></a>Proof by resolution</h3><p>The current section introduces a single inference rule, resolution, that yields a complete inference algorithm when coupled with any complete search algorithm.</p>
<p><strong>Conjunctive normal form</strong>: a set of sentences connected by AND</p>
<blockquote>
<p>to show that KB |= α, we show that (KB ∧ ¬α) is unsatisfiable.</p>
</blockquote>
<h3 id="Forward-amp-Backward-chaining"><a href="#Forward-amp-Backward-chaining" class="headerlink" title="Forward&amp;Backward chaining"></a>Forward&amp;Backward chaining</h3><p><strong>The forward-chaining algorithm</strong> determines if a single proposition symbol q is entailed by a knowledge base of definite clauses. It begins from known facts (positive literals) in the knowledge base. If all the premises of an implication are known, then its conclusion is added to the set of known facts. For example, if L1,1 and Breeze are known and (L1,1 ∧ Breeze) ⇒ B1,1 is in the knowledge base, then B1,1 can be added. </p>
<p>It is easy to see that forward chaining is sound: every inference is essentially an application of Modus Ponens. Forward chaining is also complete: every entailed atomic sentence will be derived. Forward chaining is an example of the general concept of data-driven reasoning—that is, reasoning in which the focus of attention starts with the known data. </p>
<p><strong>The backward-chaining algorithm</strong>, as its name suggests, works backward from the query. If the query q is known to be true, then no work is needed. Otherwise, the algorithm finds those implications in the knowledge base whose conclusion is q. Backward chaining is a form of goal-directed reasoning. It is useful for answering specific questions such as “What shall I do now?” and “Where are my keys?”.</p>
<h1 id="Chapter-X-CLASSICAL-PLANNING"><a href="#Chapter-X-CLASSICAL-PLANNING" class="headerlink" title="Chapter X: CLASSICAL PLANNING"></a>Chapter X: CLASSICAL PLANNING</h1><h2 id="10-1-Definition-of-classical-planning"><a href="#10-1-Definition-of-classical-planning" class="headerlink" title="10.1 Definition of classical planning"></a>10.1 Definition of classical planning</h2><p>The problem-solving agent of Chapter 3 can find sequences of actions that result in a goal state. But it deals with atomic representations of states and thus needs good domain-specific heuristics to perform well.</p>
<p>The hybrid propositional logical agent of Chapter 7 can find plans without domain-specific heuristics because it uses domain-independent heuristics based on the logical structure of the problem. </p>
<p>In response to this, planning researchers have settled on a factored representation — one in which a state of the world is represented by a collection of variables. We use a language called PDDL, the Planning Domain Definition Language.</p>
<p>States: Each state is represented as a conjunction of fluents that are ground, functionless atoms. For example, a state in a package delivery problem might be At(Truck1,Melbourne) ∧ At(Truck2,Sydney). Database semantics is used: the closed-world assumption means that any fluents that are not mentioned are false, and the unique names assumption means that Truck1 and Truck2 are distinct.</p>
<blockquote>
<p>Closed world/ Open world assumption</p>
</blockquote>
<p>Actions: they are described by a set of action schema, for each action, it corresponds to one action schema, consists of Precondition and effect. For example, here is an example of flying a plane from one location to another:</p>
<img src="/2018/12/20/Artificial-Intelligence/12.png">
<p>We say that action a is <strong>applicable</strong> in state s if the preconditions are satisfied by s. </p>
<p>The result of executing action a in state s is defined as a state s which is represented by the set of fluents formed by starting with s, removing the fluents that appear as negative literals in the action’s effects (what we call the delete list or DEL(a)), and adding the fluents that are positive literals in the action’s effects (what we call the add list or ADD(a)):</p>
<blockquote>
<p>RESULT(s, a) = (s − DEL(a)) ∪ ADD(a)</p>
</blockquote>
<p>For example, with the action Fly(F22,SFO,JFK), we would remove At(F22,SFO) and add At(F22,JFK). (这表示一个动作“F22从SFO飞到了JFK”，这个动作必须在其对应的PRECONDITION都被满足的时候才是applicable的，也就是说在动作开始前需要满足“At(F22,SFO),Plane(F22),Airport(SFO),Airport(JFK)”，这意味着诸如Fly(Ironman, SFO, JFK)或者Fly(F22, Moon, Sun)的action是不行的，同时在动作结束后，F22已经抵达了JFK，我们需要修改状态，将At(F22,SFO)去掉，并且将At(F22,JFK)添加进来。)</p>
<p><strong>Initial State</strong>: the initial state is a conjunction of ground atoms.</p>
<h2 id="10-2-Algorithms-for-Planning-as-State-Space-Search"><a href="#10-2-Algorithms-for-Planning-as-State-Space-Search" class="headerlink" title="10.2 Algorithms for Planning as State-Space Search"></a>10.2 Algorithms for Planning as State-Space Search</h2><h3 id="Forward-progression-state-space-search"><a href="#Forward-progression-state-space-search" class="headerlink" title="Forward (progression) state-space search"></a>Forward (progression) state-space search</h3><p>Forward search is prone to exploring irrelevant actions. Consider the noble task of buying a copy of <em>AI: A Modern Approach</em> from an online bookseller. Suppose there is an action schema Buy(isbn) with effect Own(isbn). ISBNs are 10 digits, so this action schema represents 10 billion ground actions. An uninformed forward-search algorithm would have to start enumerating these 10 billion actions to find <strong>the one action</strong> that leads to the goal.(对于诸如如何将大象塞进冰箱里这种问题，我们也是很难去解决的，因为在每一个state都有太多的action需要去进行search，过于庞大的state space导致了这种search方法在大多数时候表现的并不好。)</p>
<h3 id="Backward-regression-relevant-states-search"><a href="#Backward-regression-relevant-states-search" class="headerlink" title="Backward (regression) relevant-states search"></a>Backward (regression) relevant-states search</h3><p>In regression search we start at the goal and apply the actions backward until we find a sequence of steps that reaches the initial state. It is called relevant-states search because we only consider actions that are relevant to the goal (or current state).(这种search方法也有其局限性，那就是我们在知道goal state的情况下，需要知道goal state g的前一个state g’是什么样子的，从而一步一步backward search找到那条从goal state朝向initial state的path，但是比如8-queens问题，我们并不知道goal state的前一个state是什么样子的，所以用这种方法在该类问题上是很困难的。)</p>
<h3 id="Heuristics-for-planning"><a href="#Heuristics-for-planning" class="headerlink" title="Heuristics for planning"></a>Heuristics for planning</h3><ol>
<li>Ignore preconditions heuristic: drops all the preconditions from actions</li>
<li>Ignore delete lists heuristic: create a relaxed version of original problem (goal state包含其他的一些axioms)</li>
<li>Decomposition: create a set of independent subgoals</li>
</ol>
<h2 id="10-4-Other-Classical-Planning-Approaches"><a href="#10-4-Other-Classical-Planning-Approaches" class="headerlink" title="10.4 Other Classical Planning Approaches"></a>10.4 Other Classical Planning Approaches</h2><p>Currently we have several solutions for classical planning, like translating into a Boolean satisfiability problem，or into CSPs, etc. And actually in the real practice we have more choices.</p>
<h1 id="APPENDIX"><a href="#APPENDIX" class="headerlink" title="APPENDIX"></a>APPENDIX</h1><h2 id="Monte-Carlo-Tree-Search"><a href="#Monte-Carlo-Tree-Search" class="headerlink" title="Monte Carlo Tree Search"></a>Monte Carlo Tree Search</h2><p>[<a href="https://www.zhihu.com/question/41176911" target="_blank" rel="noopener">https://www.zhihu.com/question/41176911</a>]</p>
]]></content>
      
        
        <tags>
            
            <tag> AI </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Natural Language Processing]]></title>
      <url>/2018/11/01/Natural-Language-Processing/</url>
      <content type="html"><![CDATA[<p><strong>This is a note for the course of POLIMI Natural Language Processing. Natural Language Processing: Words/Syntax/Meaning/Discourse.</strong></p>
<h1 id="Linguistic-Topics"><a href="#Linguistic-Topics" class="headerlink" title="Linguistic Topics"></a>Linguistic Topics</h1><h2 id="Lexical-and-Compositional-Semantics"><a href="#Lexical-and-Compositional-Semantics" class="headerlink" title="Lexical and Compositional Semantics"></a>Lexical and Compositional Semantics</h2><h3 id="Representing-Meanings-Linking-and-Roles"><a href="#Representing-Meanings-Linking-and-Roles" class="headerlink" title="Representing Meanings: Linking and Roles"></a>Representing Meanings: Linking and Roles</h3><p>每种语言都有一定的<em>subj-verb-complements</em>结构，比如“Someone wanting + want + something wanted”。</p>
<p>而为了represent meanings，我们需要语言能够表达如下的内容：</p>
<blockquote>
<p>Meaning of Utterances[表达方式的含义]:Semantic Networks/Logics/Frame-based representations/…</p>
<p>Meaning of Words[每个word的含义]:Lexical databases…</p>
</blockquote>
<h3 id="Semantic-Analysis"><a href="#Semantic-Analysis" class="headerlink" title="Semantic Analysis"></a>Semantic Analysis</h3><ol>
<li>Syntax-driven semantics analysis[Domain Independent]: <em>Input: Parse Tree/Feature structures/Lexical Dependency Diagrams</em> 对于输入，首先进行syntactic analysis，从这一步得到syntactic structures(也就是方法中的Input)，将syntactic sturctures输入semantic analysis，得到最终的meaning representations。</li>
<li>Semantic grammar[Domain Dependent]: Semantic grammars could solve the <strong>problem of mismatching</strong> in Syntax driven semantics analysis. However the reuse of these semantic grammar is really hard.</li>
<li>Information extraction: Detect the relationships and events, and then FILL THE TEMPLATE.</li>
</ol>
<h3 id="Lexical-Semantics"><a href="#Lexical-Semantics" class="headerlink" title="Lexical Semantics"></a>Lexical Semantics</h3><p>LEXEME is the smallest unit of written form/spoken form/sense. LEXICON is a collection of LEMMAs. </p>
<p>WordNet: Containing 150 000 terms(noun/verb/adj/…). 每个term都通过一系列的synset表示（比如对于beautiful这个term，它和gorgeous属于同一个synset），synsets之间又通过一些列的predefined relations来链接（比如beautiful所在的synset和ugly所在的synset通过一个<strong>反义词</strong>的relation链接）。</p>
<blockquote>
<p>Interal Structure of Words: </p>
<p>Themantic roles (roles associated with verb meaning)</p>
<p>Selectional restrictions (constraints decided by the words contraining the subj/obj): 比如动词【吃】，显然【桌子】不能作为吃这个动作的宾语。</p>
</blockquote>
<p>Word Sense Disambiguiation: Supervised Machine Learning/Naive Bayes</p>
<h2 id="Word-Level-Processing"><a href="#Word-Level-Processing" class="headerlink" title="Word Level Processing"></a>Word Level Processing</h2><h3 id="Morphology"><a href="#Morphology" class="headerlink" title="Morphology"></a>Morphology</h3><p>English Morphology(英语的构词法研究)【stems+affixes】:可以分为两类，inflectional-规律的，derivational-不规律的。</p>
<blockquote>
<p>Finite State Transducers: 将一个语义的组合变成一个实际上书写正确的组合（cat+N+PL转化成cats）。</p>
<p>Multi-Taped Machines: 处理比较复杂的情况，比如fox变复数需要加-es而不是-s。相当于是用多步骤进行翻译。</p>
</blockquote>
<h3 id="Error-Correction-Prediction-N-grams"><a href="#Error-Correction-Prediction-N-grams" class="headerlink" title="Error Correction/Prediction/N-grams"></a>Error Correction/Prediction/N-grams</h3><p>Bayes model for ERROR CORRECTION: 对单个单词进行correction</p>
<p>N-grams: 根据输入的多个单词进行prediction</p>
<p>Markov Assumption</p>
<p>Shannon’s Method: 通过训练得到的model生成随机的句子，使其和trainset使用的句子有着类似的形式。</p>
<p>Evaluation: Intrinsic/External</p>
<h2 id="Syntactic-Processing"><a href="#Syntactic-Processing" class="headerlink" title="Syntactic Processing"></a>Syntactic Processing</h2><h3 id="POS-Tagging-the-process-of-assigning-a-part-of-speech-or-lexical-class-marker-to-each-word-in-a-collection"><a href="#POS-Tagging-the-process-of-assigning-a-part-of-speech-or-lexical-class-marker-to-each-word-in-a-collection" class="headerlink" title="POS Tagging: the process of assigning a part of speech or lexical class marker to each word in a collection"></a>POS Tagging: the process of assigning a part of speech or lexical class marker to each word in a collection</h3><p>Closed/Open classes: whether new tag of POS could be created.</p>
<blockquote>
<p>POS:</p>
<p>prepositions(on/over/…)</p>
<p>determiners(a/an/the/…)</p>
<p>pronouns(she/who/I/…)</p>
<p>… …</p>
</blockquote>
<p>POS Tagging steps:</p>
<ol>
<li>Choosing sa standard Tagset to work with (a coarse tagset? Penn TreeBank tagset?…)</li>
<li>Use the tagset to assign each word one tag.</li>
</ol>
<blockquote>
<p>THE MOST IMPORTANT PROBLEM IN POS TAGGING - [words often have more than one POS]: 2 method - RULE BASED TAGGING(<em>write each rule by hand</em>)/STOCHASTIC(HMM/MEMMs)</p>
</blockquote>
<p>HMM[a special case of Bayesian inference]: Given an observation, find the tag sequences.</p>
<h3 id="Formal-Grammars"><a href="#Formal-Grammars" class="headerlink" title="Formal Grammars"></a>Formal Grammars</h3><p>Constituency[Internal structure/ External behavior]: <strong>Noun Phrases</strong> 可以是apple也可以是the reason he comes to University.</p>
<p>Context Free Grammars[Rules/Terminals/Non-terminals(<strong>the constituents in a language</strong>)]</p>
<p>Head: the critical stuff.</p>
<p>Dependency Parsing[Better performance, and catch the relationships of syntactic relations]</p>
<h3 id="Parsing-with-BottomUp-TopDown"><a href="#Parsing-with-BottomUp-TopDown" class="headerlink" title="Parsing with BottomUp/TopDown"></a>Parsing with BottomUp/TopDown</h3><p>Parsing means assign proper trees to input strings. [find all admissible trees and select the correct one]</p>
<p>表现并不好，因为对于一个句子，仅仅根据他的syntactic structure进行parsing可能得到多个正确的parsing tree，我们需要语义上的辅助，同时重复的parsing也带来一些问题。</p>
<h3 id="Shallow-Parsing-Probabilistic-Parsing-Dependency-Parsing"><a href="#Shallow-Parsing-Probabilistic-Parsing-Dependency-Parsing" class="headerlink" title="Shallow Parsing/Probabilistic Parsing/Dependency Parsing"></a>Shallow Parsing/Probabilistic Parsing/Dependency Parsing</h3><p>Shallow Parsing(Finite State Parsing): Use subset of CFG without recursion(rules like NP-&gt;NPVP is not allowed) / L-shape sliding window.</p>
<blockquote>
<p>Pos Tagging output: My/PRP$ dog/NN likes/VBZ his/PRP$ food/NN ./.</p>
<p>Chunking output: [NP My Dog] [VP likes] [NP his food]</p>
</blockquote>
<p>Probabilistic CFG: assign probabilities to parse trees. (Different rules, different probabilities)</p>
<p>Lexicalized PCFG: lexical meaning with PCFG.</p>
<p>Dependent Parsing: instead of constituent units, concentrate on the links from word to word.</p>
<h2 id="VOICE"><a href="#VOICE" class="headerlink" title="VOICE:"></a>VOICE:</h2><h3 id="vowels-consonants-silence"><a href="#vowels-consonants-silence" class="headerlink" title="vowels / consonants / silence"></a>vowels / consonants / silence</h3><p>Prosody: 韵律学，研究人们说话的韵律和节奏等。(Intonation语调/Pauses停顿/Rhythm节奏/Stress重音/Duration延长声音)</p>
<p>INFORMATION = PROSODY + LINGUISTIC INFORMATION</p>
<p>Perception: human’s ability to have what you know interact with what you see and hear. [1-Sensing/ 2-Orgnizing/ 3 Identifying &amp; Recognizing]</p>
<h3 id="General-Info-of-Automatic-Speech-Recognition-amp-Text-To-Speech"><a href="#General-Info-of-Automatic-Speech-Recognition-amp-Text-To-Speech" class="headerlink" title="General Info of Automatic Speech Recognition &amp; Text-To-Speech"></a>General Info of Automatic Speech Recognition &amp; Text-To-Speech</h3><p>Phonetics: study of phones (the units composing words)</p>
<p>Phonology: study of phonemes (an abstraction of a set of phones, the smallest contrastive linguistic unit)</p>
<blockquote>
<p>Phonetics研究人能够发出的声音，而Phonology研究他们的声音在不同的语言中的不同的意义。所以在每一种语言的研究中phonology更重要。</p>
</blockquote>
<p>Formants: the spectral peaks of the sound frequency spectrum of the voice.</p>
<h3 id="TTS-transforming-a-text-string-into-a-waveform"><a href="#TTS-transforming-a-text-string-into-a-waveform" class="headerlink" title="TTS: transforming a text string into a waveform"></a>TTS: transforming a text string into a waveform</h3><ol>
<li>Text analysis: text string -&gt; phonetic representation</li>
<li>Waveform synthesis: phonetic representation -&gt; waveform[这里phonetic represnetation类似于英语中的音标或者汉语中的拼音，只是音节的表示方式]</li>
</ol>
<p>Text Analysis: Text Normalization -&gt; Phonetics Analysis -&gt; Prosodic Analysis</p>
<h3 id="ASR-Starting-from-a-recorder-vocal-signal-recognize-the-corresponding-sequence-of-words"><a href="#ASR-Starting-from-a-recorder-vocal-signal-recognize-the-corresponding-sequence-of-words" class="headerlink" title="ASR: Starting from a recorder vocal signal, recognize the corresponding sequence of words"></a>ASR: Starting from a recorder vocal signal, recognize the corresponding sequence of words</h3><p>Given a vocal signal, composed of M MFCC vectors(generate from windowing of vocal signal), compute the right sequence of M subphones <em>s</em></p>
<p>Or we could use HMM for ASR, the input observations are MFCC vectors, while the output are subphone sequences.</p>
<h2 id="Pragmatics-研究语言具体的使用-：take-turns-in-conversations-text-orgnization-presupposition-Discourse-Processing-Discourse-Structure"><a href="#Pragmatics-研究语言具体的使用-：take-turns-in-conversations-text-orgnization-presupposition-Discourse-Processing-Discourse-Structure" class="headerlink" title="Pragmatics[研究语言具体的使用]：take turns in conversations/text orgnization/presupposition]-Discourse Processing/Discourse Structure"></a>Pragmatics[研究语言具体的使用]：take turns in conversations/text orgnization/presupposition]-Discourse Processing/Discourse Structure</h2><h3 id="Dialog-and-conversational-agents-PART-1"><a href="#Dialog-and-conversational-agents-PART-1" class="headerlink" title="Dialog and conversational agents PART 1"></a>Dialog and conversational agents PART 1</h3><p>ELIZA: search and substitude using memory(some human-designed rules). </p>
<blockquote>
<p>A: Men are all alike</p>
<p>ELIZA: [‘all’ detected, REPLY IN CERTAIN WAY] IN WHAT WAY</p>
<p>A: My boyfriend made me came here.</p>
<p>ELIZA: [‘my’ and ‘me’ detected, SUBSTITUTE] YOUR BOYFRIEND MADE YOU CAME HERE.</p>
</blockquote>
<p>HUMAN CONVERSATION</p>
<ol>
<li>Turn-taking:什么时候speaker知道应该轮到自己讲话了？[<em>An general example：current speaker A指定了一个next speaker B时，B speak next，如果没有指定next speaker，那么任何人都可以take next turn，如果没有人take next turn，那么current speaker A继续take next turn。</em>]</li>
<li>Speech acts:[each utterance is 3 acts] LOCUTIONARY ACT(语言行为), ILLOCUTIONARY ACT(言外行为), PERLOCUTIONARY ACT(言后行为). [<em>An general example: “CAN I HAVE THE REST OF YOUR SANDWICH?” L-Question, IL-Request, Pre-“You give me sandwich.”, “I WANT THE REST OF YOUR SANDWICH!” L-Declarative, IL-Request, Pre-“You give me sandwich”</em>], ILLOCUTIONARY ACTS可以分成5类，Assertives(swearing, concluding, suggesting, …) /Directives(asking, ordering, …) /Commissives(promising, betting, …) /Expressives(thanking, welcoming, …)/Declarations</li>
<li>Grounding: both speaker should achieve common ground (things mutually believed by both speaker).但是如何让speaker确认对方和自己有相同的共识呢？Continued attention, Relevant next contribution, Acknowledgement( mm-hmm ), Demonstration, Display. [ -“I need to travel in May.” -“What day <strong>in May</strong> did you want to travel?” 通过Display来表达已经知道了对方想要在五月出行的意愿]</li>
<li>Conversational structure:将一段对话分为多个部分，比如一段日常对话的structure可能是Greetings-Daily talking-Saying Bye.</li>
<li>Implicature:[例子：-“好的，请问您想定那一天的航班？” -“我在19日有一个会议…”] 4-GRICEAN-MAXIMS:在对话推断中的四个原则，原则1-relevant，我们在讨论航班的问题的时候我说我在19日有个会议这件事和我们讨论的航班日期时有关系的；原则2-quantity，假如对方告诉我现在有5个航班，在逻辑的角度出发，如果现在有更多的航班对方也可以这么回答，但是我们假设对方只会回答一个需要的数字，不多也不少；原则3-quality，对方说的事情时正确的，我们假设双方都不会对一个缺乏依据的事情进行评判；原则4-manner，我们假设双方都简明扼要，避免过度重复。</li>
<li>*Coherence:这个本来不在这里，但是在后面的部分，我认为将这部分放在这里是合适的，这部分表示了在语言中我们常常使用Next，Thanks，OK，Last of all等词语来“润滑”我们的对话，而这在NLP中也是非常重要的。</li>
</ol>
<p>Speech Recognition-&gt;Natural Language Understanding-&gt;Dialogue Manager/Task Manager-&gt;Natural Language Generation-&gt;Text-to-speech Synthesis</p>
<p>Speech Recognition: ASR-Input waveform, output strings of words</p>
<p>Natural Language Understanding: NLU-for speech dialogue systems, FRAME AND SLOT SEMANTIC are wildly used. </p>
<blockquote>
<p>Frame and slot semantic</p>
<p>“Show me the morning flights from Boston to LA on Tuesday”</p>
<p>SHOW: </p>
<p>  FLIGHTS:</p>
<pre><code>  ORIGIN:

      CITY: Boston

      DATE: Tuesday

      TIME: Morning

  DESTINATION:

      CITY: LA
</code></pre><p>Analysis:这种方式我们通过采用一种semantic grammar，然后将这句话解析成上述形式，比如ORIGIN-&gt;from CITY, CITY-&gt;NY|Boston|LA，这种语法规则往往不是通用的，而是根据某一种特殊的工作需求建立的。</p>
</blockquote>
<p>Dialogue Manager: controls the architecture and structure of dialogue. [Finite State/Frame Based/Information State/AI Planning]</p>
<blockquote>
<p>System Initiative Dialogue: system controls the dialogue and asks the user a lot of questions. [Easy but limited]</p>
<p>User Initiative Dialogue: user directs the system, asks a single question and system answers.</p>
<p>Mixed Initiative Dialogue: conversational initiative can shift between user and system.[open prompts(“<em>How may I help you?</em>“) vs directive prompts(“<em>Say yes if you accept this call, otherwise please say no.</em>“), restrictive(strong constraints on the AST system, based on the dialogue state) vs non-restrictive grammar]</p>
</blockquote>
<p>Natural Language Generation: choose the concepts to express to user. Exprsss concepts in words and assign prosody.</p>
<p>TTS: takes words and prosodic annotations, output waveform</p>
<h3 id="Dialog-and-conversational-agents-PART-2"><a href="#Dialog-and-conversational-agents-PART-2" class="headerlink" title="Dialog and conversational agents PART 2"></a>Dialog and conversational agents PART 2</h3><p>We want the system better than just form filling.</p>
<p>INFORMATION STATE: context/beliefs/user model/task context/…</p>
<p>DIALOGUE ACTS: conversational moves, incorporates ideas of grounding.</p>
<p>DIALOGUE ACTS AMBIGUITY:处理这种混淆是很复杂的，我们需要判断这一段对话属于什么部分，比如对一句话“你可以把她的微信给我嘛？”，表面上这是一个request动作，但是其实我们知道与其回答是或者否，这是一个directive动作，我们应该回答的是“这是她的微信号/她已经有男朋友了”。</p>
<p>CONVERSATIONAL ACT TYPES: turn-taking, grounding, core speech acts, argumentation.</p>
<p>DIALOGUE ACT INTERPRETER:</p>
<p>DIALOGUE ACT GENERATOR: confirmation(explicit/implicit confirmation   -“I want to go to Berlin” - “You said you want to go to Berlin?”/“When do you want to go to Berlin?”)/rejection</p>
<p>CORRECTION DETECTION:</p>
<p>SET OF UPDATE RULES: update dialogue state as acts are interpreted, generate dialogue acts.</p>
<p>CONTROL STRUCTURE TO SELECT WHICH UPDATE RULES TO APPLY</p>
<blockquote>
<p>对于一个特定的情景：订机票</p>
<p>Dialogue Acts：THANK/GREET/INTRODUCE/REJECT/CLARIFY/…</p>
</blockquote>
<p>Dialogue System Evaluation</p>
<blockquote>
<p>MAXIMIZE USER SATISFACTION, which means MAXIMIZE TASK SUCCESS(take completed rate, correctness, …) and MINIMIZE COSTS. The COSTS here means EFFICIENCY MEASURES(time cost, turns taken, …) and QUALITY MEASURES (number of rejections, time-out prompts, concept accuracy, …). Use some kinds of questionair could help us know this information.</p>
</blockquote>
<h3 id="Dialog-and-conversational-agents-PART-2-1"><a href="#Dialog-and-conversational-agents-PART-2-1" class="headerlink" title="Dialog and conversational agents PART 2"></a>Dialog and conversational agents PART 2</h3><p>Modelling a dialogue system as a probabilistic agent <states set="" s,="" actions="" a,="" goal="" g=""> with a policy pi(when should I confirm? when should I ask a directive prompt?). Our goal here is USER SATISFACTION, while sometimes this is hard to evaluate, we need a more helpful metric. Hence we introduce UTILITY. UTILITY is a function, the input is a state or state sequence, and the output is a user satisfaction represented by a real number.</states></p>
<p>Environment-&gt;”What the world is like”-&gt;”What it will be like if I do action A”-&gt;”How happy will the user be in such state”-&gt;”What the action I should do in conclusion”</p>
<p>Markov Assumption comes in here(knowledge in the reinforcement learning)</p>
<h3 id="Anaphora-Resolution-代词的解析（如it等）"><a href="#Anaphora-Resolution-代词的解析（如it等）" class="headerlink" title="Anaphora Resolution 代词的解析（如it等）"></a>Anaphora Resolution 代词的解析（如it等）</h3><blockquote>
<p>CONSTAINTS ON COREFERENCE</p>
<p>Number agreement:John has an Acura. It is red.</p>
<p>Person and case agreement:John and Mary have Acuras. We love them (where We=John and Mary)<br>Gender agreement: John has an Acura. He/it/she is attractive.<br>Syntactic constraints: John bought himself a new Acura (himself=John)/John bought him a new Acura (him = not John)</p>
</blockquote>
<p>SOLUTION</p>
<ol>
<li>Collect the potential referents (up to 4 sentences back)</li>
<li>Remove potential referents that do not agree in number or gender with the pronoun</li>
<li>Remove potential references that do not pass syntactic coreference constraints</li>
<li>Compute total salience value of referent from all factors, including, if applicable, role parallelism (+35) or cataphora (-175).</li>
<li>Select referent with highest salience value. In case of tie, select closest.</li>
</ol>
<h3 id="Coherence-Discourse-Structure"><a href="#Coherence-Discourse-Structure" class="headerlink" title="Coherence - Discourse Structure"></a>Coherence - Discourse Structure</h3><blockquote>
<p>John hid Bills car keys. He was drunk</p>
<p>John hid Bills car keys. He likes spaghetti</p>
</blockquote>
<p>What makes a text coherent? </p>
<ol>
<li>Appropriate use of coherence relations between subparts of the discourse – rhetorical structure</li>
<li>Appropriate sequencing of subparts of the discourse – discourse/topic structure</li>
<li>Appropriate use of referring expressions</li>
</ol>
<p>Coherence Relations: </p>
<ol>
<li>Result: John bought an Acura. His father went quite angry about that</li>
<li>Explanation: John hid Bills car keys. He was drunk</li>
<li>Parallel: John bought an Acura. Bill leased a BMW.</li>
<li>Elaboration: John bought an Acura this weekend. He purchased a beautiful new Integra for 20 thousand dollars at Bills dealership on Saturday afternoon.</li>
<li>Occasion: Dorothy picked up the oil-can. She oiled the Tin Woodman’s joints</li>
<li></li>
</ol>
<h1 id="Techniques"><a href="#Techniques" class="headerlink" title="Techniques"></a>Techniques</h1><h2 id="Regular-Languages"><a href="#Regular-Languages" class="headerlink" title="Regular Languages"></a>Regular Languages</h2><h2 id="Context-Free-Grammars"><a href="#Context-Free-Grammars" class="headerlink" title="Context Free Grammars"></a>Context Free Grammars</h2><h2 id="Finate-State-Methods"><a href="#Finate-State-Methods" class="headerlink" title="Finate State Methods"></a>Finate State Methods</h2><h2 id="Augmented-Grammars"><a href="#Augmented-Grammars" class="headerlink" title="Augmented Grammars"></a>Augmented Grammars</h2><h2 id="First-Order-Logic"><a href="#First-Order-Logic" class="headerlink" title="First Order Logic"></a>First Order Logic</h2><h2 id="Probability-Models"><a href="#Probability-Models" class="headerlink" title="Probability Models"></a>Probability Models</h2><h2 id="Supervised-Machine-Learning-Methods"><a href="#Supervised-Machine-Learning-Methods" class="headerlink" title="Supervised Machine Learning Methods"></a>Supervised Machine Learning Methods</h2><h2 id="Deep-Learning"><a href="#Deep-Learning" class="headerlink" title="Deep Learning"></a>Deep Learning</h2><p>Most current machine learning already works well, based on human designed representations and input features. However, it may be better to <strong>let the machine learn good features(representations)</strong>, which involves deep learning and neural networks.</p>
<p>Single Artificial Neuron-&gt;A layer of neurons-&gt;NN-&gt;Deep NN(with hidden layer)-&gt;Softmax output layer</p>
<p>Back propagation</p>
<p>Word2Vec: models that produce word embeddings. (which means input a V-dimension vector and output a Q-dimension vector, Q&lt;&lt;V)</p>
<p>N-gram language modelling</p>
<p>RNN</p>
<p>LSTM</p>
<p>POS with Bidirectional LSTM</p>
<p>RNN for parsing</p>
<p>TTR &amp; ASR: WaveNet</p>
<h1 id="Applications"><a href="#Applications" class="headerlink" title="Applications"></a>Applications</h1><h2 id="Spelling-Correction"><a href="#Spelling-Correction" class="headerlink" title="Spelling Correction"></a>Spelling Correction</h2><h2 id="Information-Retrieval-Summarization"><a href="#Information-Retrieval-Summarization" class="headerlink" title="Information Retrieval : Summarization"></a>Information Retrieval : Summarization</h2><ol>
<li>Single Document/Mutiple Document</li>
<li>Generic Summarization/Query-focused Summerization</li>
<li>Abstract/Extract[Extract is far more easier]</li>
</ol>
<p>Methods:</p>
<ol>
<li>Content Selection: What’s important and what’s not important?</li>
<li>Information Ordering: How to orgnize the informaiton? In what order so that the information I am going to represent is coherent?</li>
<li>Sentence Realization: How to made our sentence readable and reasonable?</li>
</ol>
<h2 id="Question-Answering"><a href="#Question-Answering" class="headerlink" title="Question Answering"></a>Question Answering</h2><h2 id="Conversational-Agents"><a href="#Conversational-Agents" class="headerlink" title="Conversational Agents"></a>Conversational Agents</h2><h2 id="Machine-Translation"><a href="#Machine-Translation" class="headerlink" title="Machine Translation"></a>Machine Translation</h2>]]></content>
      
        
        <tags>
            
            <tag> Natural Language Processing </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Basic Recommender Systems]]></title>
      <url>/2018/10/29/Recommender-Systems/</url>
      <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><h2 id="Recommender-Systems"><a href="#Recommender-Systems" class="headerlink" title="Recommender Systems"></a>Recommender Systems</h2><p>The main goal of a recommender system is to provide users with hints and suggestions about items that can meet their interest. </p>
<blockquote>
<p>The Internet, today, provides a large variety of examples: hotels recommended by Booking-dot-com, books recommended by Amazon, songs by Spotify, movies by Netflix, and many more.</p>
</blockquote>
<ol>
<li>Recommender systems algorithms need, as their main input, a set of available items (e.g., books, movies, hotels), enriched via a set of descriptive attributes. For the example of movies, these attributes could be: title, year of release, genre, director, actors, etc.</li>
<li>Recommender systems algorithms, beside the “items”, need to know about “users”, since each recommendation aims at an individual user. Demographic data, like age, nationality, gender, area of living, are possible attributes to describe a user. In addition, algorithms need to know about user preferences. For example (for movies): science fiction (genre), Harrison Ford (actor).</li>
<li>A third type of information that characterizes a user is the how she interacts with items: for instance, a user may have rated some movies. In this case, we explicitly know the opinion of the user of these movies. Alternatively, we may know which books a user has bought in the past, or which movies a user have watched. We can implicitly assume that, if a user watched a movie or bought a book, probably the user likes that movie or that book. Similarly, if a user stopped watching a movie after 5 minutes, we can implicitly assume that the user did not like that movie. Interactions have attributes as well. These attributes are called “the context”. Example of contextual attributes are: people, time, and weather.</li>
</ol>
<p>The same user may have different opinions on the same item, based on the context. For instance, when choosing a restaurant for dinner, the choice could be different if the user is planning a business dinner or a romantic dinner. Similarly, if the weather is sunny, the user might prefer a restaurant with an outdoor garden, while if the weather is cold, the user might prefer a restaurant with a fireplace.</p>
<h2 id="Data-Representation-ICM-amp-URM"><a href="#Data-Representation-ICM-amp-URM" class="headerlink" title="Data Representation: ICM&amp;URM"></a>Data Representation: ICM&amp;URM</h2><p>Data representation. We examine now how to represent the input for recommender systems. <strong>The ICM, Item Content Matrix, represents a table where each row is associated to one item, while each column corresponds to one attribute</strong>. In the simplest form, the possible values in the matrix are 1 (if the attribute-value belongs to the item) or 0 (if the attribute-value does not belong to the item). If, for example, actor “x” plays in the movie “y”, the value would be 1 for the row-corresponding to “y”, at the column corresponding to “x”. </p>
<p>In a more sophisticated version, the value are real numbers expressing the relevance of the attribute-value for the item. If an actor, for example, plays the major role in a movie, he may get value 1.0. If he plays a medium role, the value could be 0.5. <strong>Another important matrix is the User Rating Matrix: in the user rating matrix, rows represent users, and columns represent items. Numbers represent ratings assigned by each user to each item, either implicitly or explicitly.</strong></p>
<h1 id="Taxonomy-of-Recommender-Systems"><a href="#Taxonomy-of-Recommender-Systems" class="headerlink" title="Taxonomy of Recommender Systems"></a>Taxonomy of Recommender Systems</h1><p>This section takes into account three points: categorizing algorithms, content-based filtering and collaborative filtering.</p>
<img src="/2018/10/29/Recommender-Systems/1.png">
<h2 id="Categorizing-algorithms"><a href="#Categorizing-algorithms" class="headerlink" title="Categorizing algorithms"></a>Categorizing algorithms</h2><p>Recommender algorithms can be classified into two categories: <strong>personalized and non-personalized recommendations</strong>. With non-personalized recommendations, all users receive the same recommendations. </p>
<blockquote>
<p>Examples are: the most popular movies, the recent music hits, the best rated hotels. With personalized recommendations, different users receive different recommendations. </p>
</blockquote>
<p>The focus of this course is on personalized recommendations, although we will use non-personalized recommendations as baselines. The core idea for personalized recommenders is that they make “better” recommendations than non-personalized systems. However, we will see that <em>there are some scenarios in which non-personalized recommendations are still a good choice</em>. </p>
<blockquote>
<p>For instance, if you recommend the most popular movies, by definition, you will recommend movies that most users like.</p>
</blockquote>
<p>Techniques for personalized recommendations can be further classified in a number of different categories. The most important are: <strong>Content-Based Filtering and Collaborative Filtering</strong>. </p>
<h2 id="Content-Based-Filtering"><a href="#Content-Based-Filtering" class="headerlink" title="Content Based Filtering"></a>Content Based Filtering</h2><p>The basic idea with Content-Based recommendations is to recommend items similar to the items a user liked in the past. </p>
<blockquote>
<p>For instance, if you liked the movie “Indiana Jones”, the recommender system could recommend you other movies directed by the same director (Steven Spielberg), and/or with the same main actor (Harrison Ford). As a second example, when you are looking at a page describing a product on the Amazon web site, you receive recommendations listing products similar to the one you are looking at. </p>
</blockquote>
<p>Content-Based filtering has been one of the first approaches used to build recommender systems. One important prerequisite for Content-Based filtering to work is to have, for each product, a list of “good quality” attributes (such as genre, director, actors, in the case of movies). We will see later in the course what makes an attribute a good attribute.</p>
<h2 id="Collaborative-Filtering"><a href="#Collaborative-Filtering" class="headerlink" title="Collaborative Filtering"></a>Collaborative Filtering</h2><p><strong>Collaborative Filtering techniques do not require any item attribute to work, but relay on the opinions of a community of users.</strong> The first type of collaborative recommender system invented was based on user-user techniques (or user-based techniques). <strong>The basic idea is to search for users with a similar taste, that is, users sharing the same opinion on several items.</strong> </p>
<blockquote>
<p>As an example: if Bob and Alice have the same opinions on many movies, it is likely that, if Bob likes a movie, also Alice will like the same movie. </p>
</blockquote>
<p>This idea seems reasonable, but we will see later in the course that the user-user approach doesn’t always work well. In many scenarios, user-based techniques fail to provide good recommendations, or are not able to provide any type of recommendation at all. </p>
<p>The second type of collaborative recommenders are <strong>item-item or item-based algorithms</strong>. </p>
<p>Item-item collaborative filtering was first invented and used by Amazon.com in 1998. <strong>The basic idea is to calculate the similarity between each pair of items according to how many users have the same opinions on the two items</strong>. </p>
<blockquote>
<p>For instance, if most users who liked “Indiana Jones” also liked “Star Wars”, it is highly probable that a user who likes “Indiana Jones” will also appreciate “Star Wars”. Many commercial recommenders today rely on item-item algorithms. </p>
</blockquote>
<p>During the Netflix competition, a new family of collaborative filtering algorithms has been invented, based on a technique called <strong>matrix factorization</strong>, which is part of a more general family of algorithms called dimensionality reduction. Contrary to user-user and item-item algorithms, it is not easy to provide an intuitive explanation on how algorithms based on matrix factorization work.</p>
<h1 id="Ratings-Predictions-and-Recommendations"><a href="#Ratings-Predictions-and-Recommendations" class="headerlink" title="Ratings, Predictions and Recommendations"></a>Ratings, Predictions and Recommendations</h1><p>“Explicit rating” means that the user explicitly states her satisfaction with an item (typically using a 1 to 5 scale). Ratings by users are a very important input for recommender systems. </p>
<p>In many application scenarios, however, it is not possible (or advisable) to ask for the opinion of the user. Rating by users may be difficult for different reasons. Users are not always happy to “waste” their time with ratings. Annoyed users may provide “random feedback”. And, in fact, frequent rating requests may annoy users. (Reminder: when designing a Recommender System, it is important not to annoy the user with too many requests!). Some technologies do not allow to easily collect explicit ratings by the users (for example, traditional TV). </p>
<p>“Implicit rating” is an important alternative to explicit rating. Implicit rating attempts to “guess” the opinion of the user. For example: you buy a book from Amazon. I don’t know if you liked it. But I know that somehow you did something with it. I can assume that if you buy a book, probably it’s because you like something in the description, you like the story. I can assume that if you buy a product you like something in that product. </p>
<p>This assumption is not always true. Sometimes, the user buys a product, tries it, and is not happy about it. If there are no other options available, however, we’re obliged to make this assumption. Another example. Assume that Mary (a user) buys a movie on Netflix. We may assume, in general, that she likes that movie (since she bought it). If, however, Mary stops watching the movie after a few minutes, we may assume that she did not like it. </p>
<p>But this assumption could be true in general (and therefore statistically valid in the end), but wrong in specific cases (the user may have received a phone call, for example). For various reasons, implicit ratings are more reliable when applied to positive ratings (what users like), rather than to negative ratings (what users don’t like).</p>
<h1 id="Inferring-preferences"><a href="#Inferring-preferences" class="headerlink" title="Inferring preferences"></a>Inferring preferences</h1><p>This section describes the characteristics of the formal representation of input and discusses about the sparsity of User Rating Matrix.</p>
<h2 id="Formal-representation-of-input"><a href="#Formal-representation-of-input" class="headerlink" title="Formal representation of input."></a>Formal representation of input.</h2><p><em>Implicit or explicit ratings</em> can be collected in various way. In the following, we will discuss how to use ratings, independently from the way they were collected. </p>
<p>Let us assume that implicit ratings are in a scale from zero to one. Zero means you have no information. (be careful, not a bad rating but no information!). 1 means that a user is perfectly happy with the item. </p>
<p>More formally, URM (User Rating Matrix) is a matrix where each row represents a user and each column represents an item. rui is value for the row corresponding to user, “u”, and the column corresponding to item, “i”. </p>
<p>URM (or something similar) is the main input of almost all recommender systems. URM, however, is almost never implemented as a matrix, this matrix could be huge (and with too many 0 in it). <strong>Very very SPARSE.</strong></p>
<h1 id="Nonpersonalized-Recommenders"><a href="#Nonpersonalized-Recommenders" class="headerlink" title="Nonpersonalized Recommenders"></a>Nonpersonalized Recommenders</h1><p><strong>“Non-personalized” recommender systems suggest the same items to all users.</strong> The easiest and best way to make non-personalized recommendations is to <em>recommend the most popular items.</em> </p>
<ol>
<li>“Most Popular” items are those who have most ratings (whatever is their value); </li>
<li>“Best rated items” instead are those with the highest average values of ratings. </li>
</ol>
<p>In order to compute “popularity”, recommender systems have to count the number of zero elements of the columns. After counting all the non-zero elements for each column, we can take the columns with the highest result and those will be “the most popular items”. </p>
<p>There is a contradictory situation with popularity: <strong>the positive side is that users are likely to like the items recommended; the negative side is that there is little added value, since it is likely that users were already aware of those items.</strong> </p>
<p>“Best rated” items have the highest average ratings; they are, for non-personalized recommendations, an alternative to most popular items. </p>
<p>To compute the average ratings, we may use the standard notion of average; but in reality this does <strong>NOT</strong> work very well. The problem is that an average computed over several ratings is much more reliable than an average computed over a few ratings. </p>
<blockquote>
<p>For example: suppose that there is one restaurant which has only one rating. If the rating is 5, it may have been solicited by the owner. If the rating is 1, it may have been solicited by a competitor. In both cases the “average” is not a reliable measure. </p>
</blockquote>
<p>The number of users who rated an item is called the <strong>support</strong>; ratings with high support are more reliable than ratings with low support.</p>
<h1 id="Scales-and-Normalization"><a href="#Scales-and-Normalization" class="headerlink" title="Scales and Normalization"></a>Scales and Normalization</h1><p>In this section, we discuss about scales and normalization, taking into account ratings distribution and computing ratings.</p>
<h2 id="Ratings-distribution"><a href="#Ratings-distribution" class="headerlink" title="Ratings distribution."></a>Ratings distribution.</h2><p>In a typical scenario, in a scale 1 to 5, most of the ratings have value 3, and besides that, most of the ratings will be positive and there will be very few negative ones. </p>
<blockquote>
<p>Normally, <strong>people are more easily convinced to rate something if they liked it</strong>. Users are more willing to share their experience for products they liked and less for products they didn’t like. If we plot the distribution of ratings about all items (including good and bad ones) most users give a rating between 3 and 5. Very few users give ratings 1 and 2. </p>
</blockquote>
<p>This distribution doesn’t reflect the distribution of the quality of a product, and probably does not even represent the opinion of the users. It is somehow related to the way people are used to rate products: <strong>most users do not bother to provide negative ratings, while happy users are willing to share their experience.</strong> </p>
<h1 id="Computing-the-ratings"><a href="#Computing-the-ratings" class="headerlink" title="Computing the ratings."></a>Computing the ratings.</h1><p>Let’s suppose we want to compute the average rating of the item “i”,”bi” is the average rating of product “i”. </p>
<p>The simple definition of the rating an item “i” is: <strong>“The Average Rating of an item is equal to the sum of the received ratings divided by the number of received ratings</strong>“ </p>
<p>NU is the number of rows (for the column corresponding to i) with value other than 0, i.e. <em>the number of users that have provided a rating</em>. If very few users (or only one) has given a rating, this is not a reliable measure. </p>
<p>We can improve the reliability with the trick of adding a constant, <strong>shrink term</strong>, C at the divider.</p>
<p><strong>“The Average Rating of item is equal to the sum of the received ratings divided by the number of received ratings plus a shrink factor” </strong></p>
<p>If NU is high, the average will not be much affected; if NU is small, the average will lower significantly. </p>
<blockquote>
<p>For Example: Suppose we have two restaurants; one of them has 1 rating equal to 5; another one has 100 ratings, all of them 5. Without using a shrink term, both restaurants have the standard average rating of 5. Using a C=10 instead, the first restaurant has an average of 0.45 and the second of 4.54. </p>
</blockquote>
<p>The shrinking term is a crude technique that helps to take into account the bias implicit when there are only few ratings for one item. There are more sophisticated approaches, but often they generate results quite similar to those obtained with the shrinking term. A</p>
<blockquote>
<p>nother Example: Check on some recommender systems (e.g. Trip Advisor): you may verify that, for items with few ratings, the overall rating of an item is not based on the standard mathematical average.</p>
</blockquote>
<h1 id="Global-Effects"><a href="#Global-Effects" class="headerlink" title="Global Effects"></a>Global Effects</h1><p>This section describes the so-called algorithm global effects, giving a general overview and showing how to compute averages and biases.</p>
<h2 id="General-description"><a href="#General-description" class="headerlink" title="General description."></a>General description.</h2><p>The “global effects” technique is very important for two reasons: </p>
<ol>
<li>It is a non-personalized formula which is able to provide good quality recommendations. </li>
<li>Secondly, it is a building block for much more sophisticated techniques. And, in fact, advanced personalized techniques do not work well, unless we combine them with global effects. </li>
</ol>
<p>Here is the key idea: normally, <strong>most of the users tend to give (almost) the same ratings to different items.</strong></p>
<blockquote>
<p>Let’s show how in an extensive example: in order to detect “good movies” we can compare the average rating of each movie with respect to the average rating of all the movies. Now suppose that the average rating for all movies is 3.5. If a movie has an average rating of 3, it means that the quality of this movie is less than the average, while if it is 3.8, the movie is better than average.</p>
</blockquote>
<h2 id="Computing-averages-and-biases"><a href="#Computing-averages-and-biases" class="headerlink" title="Computing averages and biases"></a>Computing averages and biases</h2><p>There are six steps to be considered. </p>
<ol>
<li>We compute <strong>the average rating of all the movies</strong>. For each item, we sum together the rating given by all users for that item; then, we add these sums for all items; then, we divide by the number of explicit ratings other than zero. Zero means we have no information (it is not a bad rating). </li>
<li>We compute now for each non-zero rating a new normalized rating, subtracting the average computed in step one to the rating itself. So, if an item was rated four by the user, and the average rating for all the items is three point five, the new rating is 0.5. Applying this rule to all ratings (other than zero), we compute a new URM removing the global effect. </li>
<li>Now we compute a different rating for item by adding up all the normalized ratings by all users and dividing by the number of users who gave a rating. This new value is called the item bias: it tells us the bias of that item with respect to all items. </li>
<li>We compute yet another rating, creating a third version of U R M. For each item, we subtract the item bias from each normalized rating, obtaining another rating. </li>
<li>For each user, we compute the user bias. This is the sum of all her ratings (using the version we have computed before) divided by the number of items for which the user has provided a rating. <em>This step takes into account the fact that different people have psychologically different rating scales. Some people are very nice, optimistic people, so if they do not like something, they give a rating of four, while there are some other users that are not friendly and if they like much a product, they give three.</em><blockquote>
<p>Here is a funny example of a user bias: I was reading the reviews on Trip Advisor about a luxury hotel and there was a review from a user who gave a rating of two out of ten: the user was complaining because the coffee machine in the room was not an “Espresso” but it was of another kind. So, according to this user’s opinion, the score for the hotel would be two. This user probably was giving very low ratings to all the hotels. This is an example of a user bias. </p>
</blockquote>
</li>
<li>Step six: the final rating of user for item can be computed adding the three elements: overall average (for all items and all users) plus the item bias plus the user bias. This is the final formula for the Global Effects. </li>
</ol>
<p>Recap: </p>
<ol>
<li>Compute the average of the ratings (μ) from URM. </li>
<li>Remove this quantity from the URM. </li>
<li>Compute the average for each item (b<sub>i</sub>). </li>
<li>Remove this quantity from the URM. </li>
<li>Compute the average for each user (b<sub>u</sub>). </li>
<li>Compute new rating, summing the average of ratings to the item bias to the user bias. </li>
</ol>
<p>So now we have 3 terms: “u” is a scalar, “b<sub>i</sub>“ is a vector (1 for each product), “b<sub>u</sub>“ is a vector (1 for each user). This way, we can estimate the rating a user would give to an item. </p>
<p>This is <strong>not exactly non-personalized</strong>, because there is a term that depends on the user. Each user is receiving a different estimation. Technically speaking, this should be considered as a personalized recommendation, but since this technique is computed in a very basic way, by just computing the average, it is often classified as a non-personalized recommendation.</p>
<h1 id="Requirements"><a href="#Requirements" class="headerlink" title="Requirements"></a>Requirements</h1><p>This section presents basic concepts about requirements for recommender systems.</p>
<h2 id="Functional-vs-non-functional-requirements"><a href="#Functional-vs-non-functional-requirements" class="headerlink" title="Functional vs. non-functional requirements."></a>Functional vs. non-functional requirements.</h2><p>For all pieces of SW there is an important distinction between functional requirements (<em>what the SW does</em>) and non-functional requirements (<em>how the SW does its job</em>). </p>
<p>It is clear that functional requirements have the priority, since if a piece of SW fails in performing its functions, it is useless. It may happen however, that the piece of SW, although it fully satisfies functional requirements, it is not acceptable, because non-functional requirements are not adequately satisfied.</p>
<h2 id="Non-functional-Requirements"><a href="#Non-functional-Requirements" class="headerlink" title="Non-functional Requirements"></a>Non-functional Requirements</h2><ol>
<li>Response time: Response time is a crucial non-functional requirement, since <strong>even the best recommender system would not be acceptable if the it takes too much time to get the recommendation</strong>. A concrete example: recommendations shown in webpages of online shops must be very fast; it is accepted today that users do not wait for a page to load more than 4 sec. If the recommender systems slow down the loading of the page, it will become useless or even negative.</li>
<li>Scalability: Scalability is an important non-functional requirement for recommender systems. Environment like Netflix, Amazon, or Google need to manage millions of users and to catalog millions of items. Millions of products. Recommender systems need to be scalable in the sense that <em>coping with growing users can be accomplished by simply adding new computers in the data center</em>. If applications are not scalable, however, adding new computing power will not help.</li>
<li>Privacy and Security: Privacy and security are important non-functional requirements. Regulations dictate that data about users and their behaviour need to be protected, and not accessible to outsiders. General regulations exist everywhere; in Europe we have European guidelines and national regulations. A typical concern is about reverse engineering; recommendations are often based on past actions of users; it must be prevented that outsiders can steel information about recommendations and from there can induce the behaviour of users.</li>
<li>User Interface: The interface of a recommender system, is a very important nonfunctional requirement. One example. <em>What is the best moment to show a recommendation? As soon as the user logs in into the system, or when she is surfing in the catalog of products, or when she is reading the description of a product, or when she is doing the checkout? Also, how many products, how many items should be shown to the user? One, two, five, 10? Also, how should recommendations be shown to the users using stars? (one to three, one to five, one to 10?). Thumbs up thumbs down?</em></li>
</ol>
<h2 id="Quality-Overall"><a href="#Quality-Overall" class="headerlink" title="Quality Overall"></a>Quality Overall</h2><p>A recommender system needs data in order to provide recommendations. Data about users, data about items, data about attributes describing the items, etc. </p>
<p>If data are faulty, or missing or incorrect, the quality of a recommender system will be poor. The quality of algorithms for providing recommendations is a main concern of this course; we should be, however, of the relevance of the other aspects. </p>
<p>Experimental data indicate that the quality of algorithms count for 20% (more or less), of the total quality perceived by the user. So designing a full environment of a recommender systems (from data to the user interface), the designer should balance the effort across the various elements, being aware that algorithms are just a part of the whole system.</p>
<h1 id="Quality-Indicators"><a href="#Quality-Indicators" class="headerlink" title="Quality Indicators"></a>Quality Indicators</h1><ol>
<li>Relevance and Coverage: Relevance is the ability of recommending items that very likely most users will like. One way to design a good recommender in terms of relevance is to <strong>never recommend those products that few people like</strong>. Coverage is the ability of recommending most of the items of (a possibly very large) set of items. <strong>Coverage is the percentage of items that a recommender system is able to recommend</strong>. Recommender systems with high relevance, may have a low coverage (since they recommend items that most users like), and vice versa.</li>
<li>Novelty and diversity: <strong>Novelty is the ability of recommending items unknown to the user</strong>. Recommending new items (e.g. new restaurants or new books) may be an added value for he users. <strong>Diversity is the ability to diversify the items recommended</strong>. If the user has known preferences (say that she likes chines restaurants or science fiction movies) it is safe to recommend items corresponding to the taste. But it can be boring, so it could be wise sometimes to “diversify” recommendations.</li>
<li>Consistency and Confidence: Consistency is about the stability of the recommendations. Some recommender systems are very dynamic, continuously updating the user profiles, and therefore modifying their recommendation. <em>An example: the recommender system suggests movies “x” and “y”. Assume that the user watches “x” and rates it very high. The recommender system may update her profile and exclude “y” from next recommendation. This inconsistency may confuse the user.</em> There are some recommender systems that can be too dynamic in their behavior. <strong>Confidence is the ability of measuring how much the system is sure about a recommendation</strong>. A confidence of 100% is practically impossible. What is the proper level of confidence? 90%? 60%? Is it wise to recommend an item with a level of confidence not very high? (may be for increasing diversification)</li>
<li>Serendipity: Serendipity is the ability of “surprising” the user surprise you. Surprising means to recommend something unusual for the user, who can “discover” something unexpected. A recommender algorithm is serendipitous if it recommends something that the user would never be able to find or would never search for.</li>
</ol>
<h1 id="Evaluation-Techiniques"><a href="#Evaluation-Techiniques" class="headerlink" title="Evaluation Techiniques"></a>Evaluation Techiniques</h1><ol>
<li>Direct User Feedback: ask some real users to define their level of satisfaction. </li>
<li>A/B Testing: Compare the behaviour of the users who receive recommendations with the behaviours of the uses who do not receive recommendations(如：收到推荐的人是否购买的product增加了？)</li>
<li>Controlled Experientments: Use NOT real-life users to test the satisfaction and give feedback.</li>
<li>Crowdsourcing: asking volunteers to answer online questionnaire.</li>
</ol>
<h1 id="Offline-Evaluation"><a href="#Offline-Evaluation" class="headerlink" title="Offline Evaluation"></a>Offline Evaluation</h1><p>Above the evaluation techniques we talked about are online evaluations, which evolve real users or models like real users. now we talk about offline evaluation.</p>
<ol>
<li>Ground Truth: Let us assume that several users (say 100000) have expressed their opinion about several items (say 10,000). In reality each user expresses an opinion about a few items, and each item is reviewed by few users. We call <strong>“ground truth”</strong> the opinion of the users about the items. In the field of recommender system there is the adoption of a peculiar terminology: <em>we call “relevant opinions” the positive ones, and “relevant users”, those who have expressed them</em>. The other users are the irrelevant ones.</li>
<li>Top-K recommendations: Let us assume that a recommender system computes in a given situation, for a given user, which products to recommend. We call “top-K” recommendation, the K items that the recommender system predicts to be liked most by the user. In order to assess the quality of the recommender system, we need to compare top-k recommendation with the ground truth, that is, opinions expressed by the users.</li>
<li>Error metrics: We use the “error metrics” to measure the difference between the rating estimated by a recommender system and the true rating provided by the <strong>ground truth</strong>. Given a user and an item we can ask the recommender system to provide a rating: say 7 out of 10, for example. Let us assume than the rating in the ground truth (for that user and that item) is 4. The difference between the two ratings is 3.</li>
<li>Classification metrics: Classification metrics assign a label to items. Let us assume that the recommender system has recommended 10 items. Some of them (let’s say 3) are actually liked by the user. Some of them (let’s say 2) are disliked. For the other items (let’s say 5) we have no opinion by the user. Generally speaking, we have four sets to consider: A, B, C, D. <strong>A is the whole dataset. B is the set of items that the user likes. C is the set of items that the user doesn’t like. D is the set of items that we are recommending.</strong></li>
<li>Advantages and disadvantages: The fact that for some items there is no opinion of the users, is a disadvantage for error metrics. <em>If some of the items belonging to D(recommended items), do not belong to either B(liked items) or C(disliked items), we can’t compute a difference in ratings.</em> Error metrics, in fact, despite being very popular, not always provides a good indicator of the quality of a recommender system. In the field of recommender systems, both methods can be uses: error metrics or classification metrics. Still, the fact that some items are not rated by the users create methodological problems.</li>
</ol>
<h1 id="Algorithms"><a href="#Algorithms" class="headerlink" title="Algorithms"></a>Algorithms</h1><h2 id="Recommender-Algorithm"><a href="#Recommender-Algorithm" class="headerlink" title="Recommender Algorithm"></a>Recommender Algorithm</h2><p>A recommender algorithm is a mathematical function. The input is the URM. The output is what we call the “model”, that is, a representation of the user preferences.</p>
<p>Recommender algorithms above described, are based upon two functions, <strong>F (build a model) and G (use the model)</strong>; they are called model-based algorithms. With memory-based algorithms, instead, there is no model. The algorithm uses past data to provide recommendations. A memory-based recommender system is able to provide recommendations only to users that exist when you build the model. It is not able to provide recommendations to other users. <em>Normally, memory-based algorithms provide better recommendations. But they are slow and therefore do not scale easily</em>.</p>
<h2 id="Relevant-Data-Sets"><a href="#Relevant-Data-Sets" class="headerlink" title="Relevant Data Sets"></a>Relevant Data Sets</h2><ol>
<li>The first dataset is the one used to build the model, that is, a guess of the taste for each one of several users. </li>
<li>The second set is about other users; the model is used to forecast the taste of these users. </li>
<li>The third dataset is created comparing the estimated ratings with the actual ratings provided by the users</li>
</ol>
<h1 id="Evaluation-Techniques"><a href="#Evaluation-Techniques" class="headerlink" title="Evaluation Techniques"></a>Evaluation Techniques</h1><h2 id="Hold-out-techniques"><a href="#Hold-out-techniques" class="headerlink" title="Hold-out techniques"></a>Hold-out techniques</h2><p>Let us consider the URM. The hold-out technique randomly removes some of the ratings from the matrix. The best practice is to remove, more or less, 20% of the ratings. The model is computed (function F) and recommendations are generated (function G). </p>
<p>Then the estimated ratings are compared with the true ratings that were removed. Though it is very popular, this technique is not an optimal one; one of the disadvantages is that you can evaluate the recommendations only for the users that are both in the training set and in the hold-out set.</p>
<h2 id="K-fold-evaluation"><a href="#K-fold-evaluation" class="headerlink" title="K-fold evaluation"></a>K-fold evaluation</h2><p>This technique partitions the URM in 3 portions, by selecting different users (and therefore different rows). One portion (obtained by selecting some users) is used to train the model. Two other portions are used to verify the quality of the recommendations. </p>
<p>It is important to notice that, while hold-out technique randomly removes ratings, k-fold evaluation removes all the ratings of some users. This technique is more difficult to implement: it is also difficult to test the quality of recommendations</p>
<h2 id="Leave-one-out-technique"><a href="#Leave-one-out-technique" class="headerlink" title="Leave-one-out technique."></a>Leave-one-out technique.</h2><p>When you use hold-out or K-fold, our sparse dataset represents a big problem because, for each user, we have just few ratings, but the average is still very low. </p>
<blockquote>
<p>Suppose, using hold-out, you take the user Paolo Cremonesi who rated only four products on Amazon. If we randomly remove only one rating from the user, we have three ratings that we can use to build his model and to understand his taste. So, we evaluate the quality of recommendations to a user, by using only one product and the only way to compare the quality of the recommendation is by comparing the true opinion of Paolo with the estimated opinion. Unfortunately, we can’t trust too much this rating. Now, suppose you remove three ratings from Paolo Cremonesi, using them to analyze the quality of the recommendation. However, there is only one rating that we can use to understand the user’s taste, not an easy way to realize the opinion of a person. So, because the number of ratings per user is normally very low, when you split your dataset you have not enough rating to keep the profile alone and to do a statistical significant quality measurement. </p>
</blockquote>
<p>By using leave-one-out, from one user profile you create four profiles by removing one rating, using it for testing. This technique, always used in normal situations, is not only a nice trick to try to solve the problem of having few ratings in the user profile, but probably also the best way to remove ratings. </p>
<p>Despite that, few people do it for a number of reasons. Firstly, it is difficult and boring to implement. <strong>Furthermore, it takes much more time to do the testing because you need to remove and reset, continuously.</strong> Clearly, if you have a dataset in which your users have a lot of ratings or your users on average have hundreds of ratings, you do not need leave-one-out.</p>
<h1 id="Error-Metrics"><a href="#Error-Metrics" class="headerlink" title="Error Metrics"></a>Error Metrics</h1><ol>
<li>Mean Absolute Error: For each rating, the absolute value of the difference between the actual rating and the estimated rating. The overall average is the MAE. </li>
<li>Root Mean Square Error: The Mean Square Error consists in computing the average of the squared difference between each actual rating and the estimated rating. Often, for normalization, the square root of the result is considered. Minimizing the root mean square error is (relatively) easier than MAE.</li>
</ol>
<h2 id="Limitations-of-error-metrics"><a href="#Limitations-of-error-metrics" class="headerlink" title="Limitations of error metrics."></a>Limitations of error metrics.</h2><p>There is an intrinsic problem: <strong>algorithms compute ratings for all items, but users only rate a few items, therefore it is not possible to compare the computed rating with the actual rating by users.</strong> In addition, users normally tend to rate items that they like. Typical distributions of ratings show this phenomenon; there are very few ratings for items that the users do not like.</p>
<h2 id="Comparing-the-distributions-of-ratings"><a href="#Comparing-the-distributions-of-ratings" class="headerlink" title="Comparing the distributions of ratings"></a>Comparing the distributions of ratings</h2><p><strong>Users, in general, take at items only if they have, at least, a mild interest for them. If we could have all users rating all items, the percentage of negative ratings would be much higher.</strong></p>
<h2 id="Assumption-of-error-metrics"><a href="#Assumption-of-error-metrics" class="headerlink" title="Assumption of error metrics"></a>Assumption of error metrics</h2><p>In essence the error metrics assumes that ratings are missing at random. This is why the quality measure with error metrics is not a good indicator of the quality of a system. <strong>Because in reality the missing ratings would much more negative than the available ratings.</strong> </p>
<h1 id="Classification-metrics"><a href="#Classification-metrics" class="headerlink" title="Classification metrics"></a>Classification metrics</h1><h2 id="Recall"><a href="#Recall" class="headerlink" title="Recall"></a>Recall</h2><p>The recall is the ratio between the number of items recommended (say N) and the number of items that the user would actually like (say K). <strong>If recall (N/K) is low, it means there a lot of possibly good items that we are not recommending. If the ratio is high, it means that the system is recommending most of the possibly good items.</strong></p>
<h2 id="Precision"><a href="#Precision" class="headerlink" title="Precision"></a>Precision</h2><p>Precision. Let us assume that the system recommends N items, and that X of these items are actually good for the user. “Precision” is the ratio between X and N. High precision means that most of the recommended items are good for the user; low precision means that several recommended items should have not been recommended. </p>
<blockquote>
<p>Recall and Precision are in general at odds, in the sense that optimizing recall may lead to a low precision, and viceversa. If the system, for example, recommends only the best item, precision is 100% but recall is very low. If the system recommends a lot of items, recall will be very high, but many of the items could be wrong, therefore the precision could be low. </p>
<p>Balancing Precision and Recall may be difficult, since both of them are important. For recommender system, overall, recall is (slightly) preferred; it is better to not miss any good items, even if the price is that some bad items come along.</p>
</blockquote>
<h2 id="Fallout"><a href="#Fallout" class="headerlink" title="Fallout"></a>Fallout</h2><p>Fallout is another important metrics. It is defined as the ratio between the bad items recommended and the total of items with poor rating by that user.</p>
<h1 id="Combining-metrics"><a href="#Combining-metrics" class="headerlink" title="Combining metrics"></a>Combining metrics</h1><h2 id="Precision-or-recall"><a href="#Precision-or-recall" class="headerlink" title="Precision or recall?"></a>Precision or recall?</h2><p>Recall is the most important metrics for Recommender systems. <em>Despite this, recall, by itself is not sufficient, but it must be combined either with precision or with fallout.</em> When we examine together precision and recall, we must take into account the value of N, that is, the number of items being recommended. </p>
<blockquote>
<p>A perfect recommender system has precision of 100% for all the values of recall. In reality however, for a large N we increase recall, since more good items are recommended, but precision decreases, since some of the items are not really relevant for the user. For a small value of N, most of the items recommended are relevant for the user, but some of the possibly relevant items are not recommended.</p>
</blockquote>
<h2 id="F-Measure-combining-precision-and-recall"><a href="#F-Measure-combining-precision-and-recall" class="headerlink" title="F-Measure: combining precision and recall."></a>F-Measure: combining precision and recall.</h2><p>F-measure is defined by multiplying “precision”, “recall” and the constant value 2.</p>
<h2 id="ROC-Curve"><a href="#ROC-Curve" class="headerlink" title="ROC Curve"></a>ROC Curve</h2><p>Plotting together Recall and Fallout, we obtain what is called which is called the ROC curve. Increasing the Value of N, recall increases, but also Fallout increases. If all the items are recommended, both recall and fallout have the maximum possible value. In practice however, recommender systems are interested only in small values of N. </p>
<p>In addition, measuring Fallout is not always possible; In an “implicit dataset” only the ratings by the user are represented, and the negative ratings are in general missing. </p>
<p>Fallout can be computed only if the negative ratings are explicitly defined. In order to summarize the ROC curve in a number, the area under the green line is computed. This number is called AUC(the area under the curve). For a perfect recommender system, the value of AUC will be one.</p>
<h2 id="Popularity-bias"><a href="#Popularity-bias" class="headerlink" title="Popularity bias."></a>Popularity bias.</h2><p>It is easier to collect opinions for items that are very popular and more difficult to collect opinions about items that the people do not care of. This create a problem called “popularity bias”.</p>
<h2 id="Utility"><a href="#Utility" class="headerlink" title="Utility."></a>Utility.</h2><p>Utility measure the value provided by a recommender algorithm. Recommending the most popular items, it is very likely that the user likes the recommendation; but it is not very useful, since the user is (probably) already aware of those items. </p>
<p>A useful recommendation combines two facts: the user likes the recommendation and the user gets something new. One possibility is to remove from the test set the most popular items. </p>
<blockquote>
<p>In an experiment we removed some of the most popular movies in Netflix: something like 60 movies out of 12,000 movies. As shown by the picture, the quality of the top popular items is the worst. So, generally when you are evaluating a recommender system you should build the test set by taking into account the popularity bias.</p>
</blockquote>
<h1 id="Ranking-Metrics"><a href="#Ranking-Metrics" class="headerlink" title="Ranking Metrics"></a>Ranking Metrics</h1><h2 id="Ranking-in-general"><a href="#Ranking-in-general" class="headerlink" title="Ranking in general."></a>Ranking in general.</h2><p>Classification metrics have the goal to determine if a user likes an item or not. Ranking evaluation metrics, instead, try to measure how much a user likes an item, compared to the other items. </p>
<p>In practice, ranking metrics are used when an order list of recommendations is presented to the users. Generally speaking, when presenting to a user a list of items, it is advisable to put high in the list the items that the user likes most. </p>
<p>So, in principle, a ranking algorithm, given two items, X and Y, should rank them, putting higher in the list the most liked one. In other words, the list of recommendations will present the most relevant items at the top, and the least relevant items at the bottom.</p>
<h2 id="Average-Reciprocal-Hit-Rank"><a href="#Average-Reciprocal-Hit-Rank" class="headerlink" title="Average Reciprocal Hit-Rank."></a>Average Reciprocal Hit-Rank.</h2><p>The Average Reciprocal Hit-Rank, ARHR, is a modified version of recall. <em>Recall, is defined as the number of items that the user likes, included in the recommendation, divided by the total number of items that the user likes.</em></p>
<p>With this technique the denominator is the same. For the numerator each item is “weighted” by a fraction: 1 divided by ranking, that is, the position in the list. The weight is equal to 1 if the item is in position 1; 0.5 if the item is in position 2; and so on. </p>
<p>This is a useful metrics, but technically speaking is not a ranking in strict sense, since it does not compare the ranking provided by the user with the ranking provided by the system.</p>
<h2 id="Mean-Average-Precision"><a href="#Mean-Average-Precision" class="headerlink" title="Mean Average Precision."></a>Mean Average Precision.</h2><p>The Mean Average Precision, or MAP, is a very important metric. With MAP we compute the average precision across several different levels of recall. </p>
<p>Precision and recall are computed for each item added to the list of recommended items.</p>
<p>In practice the first move is to take the first item: precision is 1 since the user likes the item; recall is 1/100, assuming that there are 100 items that the user likes. Let us consider the second item. Precision is again 1, if the user likes also the second movie. Recall this time is 2/100. </p>
<p>When K = 2 we can compute DELTA-R, is equal to the difference between the last recall, 2/100 and the previous one, 1/100. In order to compute the MAP for a value of K, we multiply the precision for each value of P(i) for DELTA-R.</p>
<h2 id="Spearman’s-Rho"><a href="#Spearman’s-Rho" class="headerlink" title="Spearman’s Rho."></a>Spearman’s Rho.</h2><p>Spearman’s Rho coefficient measures the consistency between the ranking as provided by the system and the ranking as provided by the user. It is considered a global ranking metrics, in the sense that all items are considered. Ranking items in a list means that the user puts them in a specific order: the first is the one the she likes most. The Spearman coefficient is 1 if the ranking of the system of exactly corresponds to the ranking provided by the user.</p>
<h2 id="Kendall’s-Tau"><a href="#Kendall’s-Tau" class="headerlink" title="Kendall’s Tau."></a>Kendall’s Tau.</h2><p>The Kendall’s Tau metric considers pairs of items, not individual ones. Let assume that we have two list of 10 items. There are 45 possible pairs; <strong>for each pair the user ranks it (which of the 2 does she prefer?) and the system ranks it. The pair is Consistent if User and System have the same opinion; it is Discordant otherwise.</strong> </p>
<p>In addition, we must consider the number of pairs for which the user could not express a preference; and analogously for the system. The Kendall Tau metrics takes into consideration these 4 numbers: consistent pairs; discordant pairs; pairs not ranked by the user; pairs not ranked by the system.</p>
<blockquote>
<p>Kendall’s Tau limitations: Kendall’s Tau closely represents the opinion of users, and therefore is a good technique. A major problem is the time required for computing it. </p>
</blockquote>
<h1 id="Evaluating-Diversity"><a href="#Evaluating-Diversity" class="headerlink" title="Evaluating Diversity"></a>Evaluating Diversity</h1><h2 id="Defining-diversity"><a href="#Defining-diversity" class="headerlink" title="Defining diversity."></a>Defining diversity.</h2><p>There are several possible definitions for the notion of “diversity”. </p>
<ol>
<li>“Intra-list diversity” means that all the items within the same list are quite different. </li>
<li>“Extra-list diversity”, means, instead, that the items in two different lists are different. This can be useful for two consecutive recommendations. </li>
</ol>
<h2 id="Measuring-distance"><a href="#Measuring-distance" class="headerlink" title="Measuring distance"></a>Measuring distance</h2><p>How is it possible to measure the dissimilarity between two items? <em>Let us consider the attributes used to describe an item: for a movie they can be the actors, the genre, the director, etc.</em> For a pair of items, if they have several attributes in common, they are similar; otherwise they are dissimilar. If no attributes are in common, they have the maximum distance.</p>
<h2 id="Balancing-quality-and-diversity"><a href="#Balancing-quality-and-diversity" class="headerlink" title="Balancing quality and diversity."></a>Balancing quality and diversity.</h2><p>A good recommendation system should balance quality (recommending items that users like) with diversity (recommending dissimilar items). </p>
<p>Playing “conservative” a recommender system may choose very similar items, improving precision, but probably lowering diversity. As it can be seen on the slide, improving diversity may decrease precision, and viceversa.</p>
<h1 id="Evaluating-Novelty"><a href="#Evaluating-Novelty" class="headerlink" title="Evaluating Novelty"></a>Evaluating Novelty</h1><h2 id="Defining-novelty"><a href="#Defining-novelty" class="headerlink" title="Defining novelty."></a>Defining novelty.</h2><p>Novelty is another important metrics. The definition of novelty: number of recommended relevant-and-unknown items divided by the number of relevant items. </p>
<h2 id="Estimating-novelty"><a href="#Estimating-novelty" class="headerlink" title="Estimating novelty."></a>Estimating novelty.</h2><p>Recommending a very popular item, there is the danger that the item is already known by the user. While recommending an item that is not popular, the probability that this recommendation is novel is very large. </p>
<p>A good approximation of novelty is the following. By popularity we mean the percentage of users who rated an item. The reciprocal popularity of an item is 1 over the popularity. </p>
<p>A way to improve the novelty, consists in using “diversity”. If the dissimilarity, between the movies recommended and the movies that the user watched in the past, is high, probably the novelty is also high.</p>
<h1 id="Content-Based-Filtering-1"><a href="#Content-Based-Filtering-1" class="headerlink" title="Content Based Filtering"></a>Content Based Filtering</h1><h2 id="Definition"><a href="#Definition" class="headerlink" title="Definition"></a>Definition</h2><p>CBF is to estimate how relevant an item is for a user, based on the items for which they have previously expressed a preference.</p>
<blockquote>
<p>Basic Logic: If a user expressed a preference for an item, it is likely that he will like similar items.</p>
</blockquote>
<h2 id="ICM-Item-Content-Matrix"><a href="#ICM-Item-Content-Matrix" class="headerlink" title="ICM - Item Content Matrix"></a>ICM - Item Content Matrix</h2><p>ICM is the fundamental of CBF. Each row represents an item and each column an attribute. And the value ranging from 0 to 1 in most cases.</p>
<h1 id="Cosine-Similarity"><a href="#Cosine-Similarity" class="headerlink" title="Cosine Similarity"></a>Cosine Similarity</h1><p>The simplest way to measure the similarity between two items is to count how many attributes they have in common. </p>
<p>If the item-vector are binary with 1 and 0, we could say that the product of two vectors could be a good measure of the distance between two items.</p>
<h2 id="The-cosine"><a href="#The-cosine" class="headerlink" title="The cosine"></a>The cosine</h2><p>Counting common attributes is not meaningfult if we are not working with binary values. Cosine similarity is the simplest way to measure the distance, <strong>by taking the dot product of item i and item j and dividing them by the product of the norm of the two items</strong>. </p>
<blockquote>
<p>The result measure the angle between two vectors. If the result is close to 1, it means two vectors are quite close (similar).</p>
</blockquote>
<h2 id="Shrinking"><a href="#Shrinking" class="headerlink" title="Shrinking"></a>Shrinking</h2><blockquote>
<p>PROBLEM: there are many cases in which we do not have the attributes or we have few of them. This represents a problem for computing the cosine similarity.</p>
<p>eg: 两部完全不相同的电影，同一个演员客串了非常小的一部分，且ICM只有一列，就是客串演员，显然两部电影的cosine similarity是1，但是这是与事实相悖的。</p>
</blockquote>
<p>A useful trick is to add a constant value (shrink term) in the denominator of the cosine similarity formula.</p>
<p>By adding a shrink term, we increase the reliability of our similarity. That means, that if we have a similarity close to one, we are sure that there are several attributes in common between the items, therefore we can trust that the items are actually similar.</p>
<h1 id="Estimating-ratings"><a href="#Estimating-ratings" class="headerlink" title="Estimating ratings"></a>Estimating ratings</h1><blockquote>
<p>PROBLEM: 当user对于多个（可能有很大差别的）item有一定的preference时，如何进行recommendation。</p>
</blockquote>
<p>GOAL: estimate how much user “u”, likes an item “i”, a item. The only information that you have is his opinion about other items “j”.</p>
<p>The simplest estimator, is the weighted average of the previous ratings, using the similarity between the item “i” and items “j” as the weight.</p>
<p>new_item_estimated_rating = SUM(previous_item_similarity*previous_item_rating)</p>
<blockquote>
<p>EG: <em>You know that Bob likes The Matrix and rated it 5 stars. He also likes ‘Forrest Gump’ and rated it 4 stars. We want to estimate the rating that Bob gives to ‘Star Wars’. We average these rating, giving more weight to ‘The Matrix’ since it shares a similar genre and themes with ‘Star Wars’, and giving very little or no weight to the rating of ‘Forrest Gump’, a very different kind of movie.</em></p>
</blockquote>
<h1 id="Similarity-Matrix"><a href="#Similarity-Matrix" class="headerlink" title="Similarity Matrix"></a>Similarity Matrix</h1><p>To build CBF, it is useful to build similarity matrix. Each row are items, and each column are items. The value is the similarity between different items. </p>
<p><strong>Similarity Matrix</strong> is sparse and really big. The solution of this is take <strong>k-nearest neighbors</strong>. It means instead of keeping all the matrix, for each item(row) we only keep k most similar items.</p>
<blockquote>
<p>Choice of k: </p>
<p>If “k” is too small, we get a very low quality, because you don’t keep enough similarities to compute an appropriate estimation. As you increase k, you have a better quality. </p>
<p>Then, if you go on increasing “k” too far, the quality start decreasing, because you are polluting the estimation with items that are not relevant to estimate the opinion of the user.</p>
</blockquote>
<h1 id="Improving-ICM"><a href="#Improving-ICM" class="headerlink" title="Improving ICM"></a>Improving ICM</h1><p>A standard good quality Content Based Recommender System estimates the rating a user would give to an item, based on cosine similarity improved with the shrink term, and considering the k-nearest neighbors.</p>
<ol>
<li>Non-binary values: Sometimes it is more accurate to have values in between zero and one, especially when one attribute only partially describes an item.</li>
<li>Attribute weights: How do we weigh each attribute? Based on how much important is an attribute in the ICM, the results of recommendation will be different.(eg:<em>what kind of sandwiches provided by the company to the actors during the break time is totally useless for a user to choosing a film!</em>)</li>
</ol>
<h1 id="TF-IDF-Term-Frequencies-Inverse-Document-Frequencies"><a href="#TF-IDF-Term-Frequencies-Inverse-Document-Frequencies" class="headerlink" title="TF-IDF: Term Frequencies - Inverse Document Frequencies"></a>TF-IDF: Term Frequencies - Inverse Document Frequencies</h1><p>Very often attribute is a piece of text written by anyone. It seems more a NLP problem, but we still have to solve this.</p>
<p>One possibility is that the keywords or tags generated by the users in the summary is an attribute. But to weight this attributes, we need to use TF-IDF. (Yes! The TF-IDF Technique used in NLP!)</p>
<blockquote>
<p>attribute weight=TF/IDF</p>
</blockquote>
<h2 id="Term-Frequency"><a href="#Term-Frequency" class="headerlink" title="Term Frequency"></a>Term Frequency</h2><blockquote>
<p>KEY IDEA: if a word appears a lot of time in a document, probably this term is important to describe the document. Term frequency is how many times specific term appears in current text.</p>
</blockquote>
<h2 id="Inversed-Document-Frequency"><a href="#Inversed-Document-Frequency" class="headerlink" title="Inversed Document Frequency"></a>Inversed Document Frequency</h2><p>IDF is computed as the logarithm, on any base you want, of the ratio between the number of items that are present in the data set divided by the number of items that contain attribute a.</p>
<blockquote>
<p>If attribute “a” is present in all items, you have the number of items in the catalog divided by the number of items that contain attribute “a”: the ratio is 1 and its logarithm 0. So, this attribute is weighted zero. </p>
</blockquote>
<p>The smaller is the number of items that contain this attribute, IDF is bigger, the more likely is that, if a user like an item with this attribute, he is going to like also other items with this attribute because it means that this attribute is a very peculiar one.</p>
<h1 id="User-Based-Filtering"><a href="#User-Based-Filtering" class="headerlink" title="User Based Filtering"></a>User Based Filtering</h1><p>An alternative approach to Content Based Filtering based on item similarity is to provide recommendations based on the similarity between the users.</p>
<blockquote>
<p>KEY IDEA: if a user likes an item, then similar users are likely to like the same item. The relative <em>user content matrix</em> attributes could be user age, gender, etc.</p>
</blockquote>
<p>suppose u the recommended user, and v are some similar users, and i is an item rated by v:</p>
<p>rating(u,i)= SUM(rating (v,i) * similarity (u,v))/SUM(similarity(u,v))</p>
<p>We could still apply K-nearest neighbours in this method as well.</p>
<h1 id="Collaborative-User-Based"><a href="#Collaborative-User-Based" class="headerlink" title="Collaborative User-Based"></a>Collaborative User-Based</h1><blockquote>
<p>KEY IDEA: compare the proifle of different users to identify similar tastes. We then provide recommendations to a user based on the ratings that similar users have given to an item.</p>
</blockquote>
<h2 id="User-Rating-Matrix-URM"><a href="#User-Rating-Matrix-URM" class="headerlink" title="User Rating Matrix - URM"></a>User Rating Matrix - URM</h2><p>The only input data for collaborative filtering is user rating matrix, URM. Differently from CBF, we do not consider the attributes of the items rated, we recommend only based on their ratings. </p>
<blockquote>
<p>If we could calculate how similar users tastes are, we could make recommendations just like CBF.  A rating for user “u” on item “i” is estimated as the rating of the k most similar users v times the similarity between “u” and “v”, all divided by the sum of the similarities between “u” and the “v”s.</p>
</blockquote>
<h2 id="User-Similarity"><a href="#User-Similarity" class="headerlink" title="User Similarity"></a>User Similarity</h2><p>If two users give similar rating to the same items, we may assume that these two users are similar. <strong>Therefore, we could take two rows from URM an compare their cosine similarity.</strong></p>
<blockquote>
<p>PROBLEM: For a explicit rating situation, we have positive users and negative users, they share the same taste while the rating of two group of people are very different. </p>
</blockquote>
<h2 id="Pearson-Correlation-Coefficient"><a href="#Pearson-Correlation-Coefficient" class="headerlink" title="Pearson Correlation Coefficient"></a>Pearson Correlation Coefficient</h2><p>To solve above problem, we need to normalize the data by removing the bias before apply collaborative rating. (for each row, remove the average of the non-zero ratings of current row) and then adapt cosine similarity.</p>
<img src="/2018/10/29/Recommender-Systems/2.png">
<blockquote>
<p>In short, it means that we check whether two users both agree that certain movie is above average. Based on this idea we could build a similarity matrix and then make recommendation.</p>
</blockquote>
<h2 id="The-Delta"><a href="#The-Delta" class="headerlink" title="The Delta"></a>The Delta</h2><blockquote>
<p>PROBLEM: 假设一个positive rating user与一群negative rating user有着相同的taste，那么根据CF我们可以向该user根据那群negative user推荐item I，但是I的rating由于是从negative user中得到的，故评分会比较低，那么这个评分对于该positive user可能会比较低。</p>
</blockquote>
<p>Our goal, now, is to estimate the delta between my average rating and the others average ratings. Delta is (the difference between <strong>the rating that I estimate for item i on user u</strong> and <strong>the average rating of user u</strong>). Delta of u is equal to the summation of the delta of user v, times the similarity between v and u, divided by the summation of the similarities. </p>
<h1 id="Item-Based-Collaborative-Filtering"><a href="#Item-Based-Collaborative-Filtering" class="headerlink" title="Item-Based Collaborative Filtering"></a>Item-Based Collaborative Filtering</h1><h2 id="IBCF"><a href="#IBCF" class="headerlink" title="IBCF"></a>IBCF</h2><p>The item-based collaborative filtering is a symmetric approach to user-based. The only input is URM. We consider two items are similar if a lot of usrers share the same opinions on them. </p>
<p>In case we only consider implicit ratings, we take two columns from the matrix and measure the cosine of the angle between them. </p>
<h2 id="IBCF-explicit-ratings"><a href="#IBCF-explicit-ratings" class="headerlink" title="IBCF explicit ratings"></a>IBCF explicit ratings</h2><p>If we still use the cosine of the two vectors, it means we make a computation over u on the rating that user u gave to item i, times the rating that user u gave to item j, divided by the square root of the rating that user u gave to item i squared, times the rating that user u gives to item j squared.</p>
<h2 id="The-adjusted-cosine"><a href="#The-adjusted-cosine" class="headerlink" title="The adjusted cosine"></a>The adjusted cosine</h2><blockquote>
<p>Problem 1 of cosine similarity: as an example, <em>take any pair of movies: most of the users will have not rated these movies, so most of the ratings are zero. Now, suppose that there are two movies and I am the only person who rated them, rating both with five: I liked both of them. The cosine between these two movies will be of one, because all users who rated these two movies, which is only me on the rating. So, we are claiming the two movies are identical based only on the opinion of one user. Of course we cannot trust this.</em></p>
</blockquote>
<p>We add a shrink term to the denominator of cosine formula to solve this problem. </p>
<blockquote>
<p>Poblem 2 of cosine similarity: prositive users vs negative users</p>
</blockquote>
<p>We apply the adjusted cosine: summation over the users of the rating that user u gave to item i, minus the average rating of the user, times the summation over u of the rating that user u gave to item j, minus the average rating of the user, divided by the square root of the summation of the ratings that user u gave to item i, minus the average of user ratings squared, times the summation over u, of the ratings that user u gave to item j, minus the average of the ratings of user u squared, plus the shrink.</p>
<img src="/2018/10/29/Recommender-Systems/3.png">
<h1 id="Some-considerations-about-CF"><a href="#Some-considerations-about-CF" class="headerlink" title="Some considerations about CF"></a>Some considerations about CF</h1><h2 id="Normalization"><a href="#Normalization" class="headerlink" title="Normalization"></a>Normalization</h2><p>Normalization is important if your goal is to estimate the rating, but, if the quality metric is an error metric or an accuracy metric, experience is telling us that you can safely remove the normalization without affecting the quality.</p>
<h2 id="K-nearest-neighbours"><a href="#K-nearest-neighbours" class="headerlink" title="K-nearest neighbours"></a>K-nearest neighbours</h2><p>Save memory and time.</p>
<h2 id="Choosing-between-user-based-or-item-based-CF"><a href="#Choosing-between-user-based-or-item-based-CF" class="headerlink" title="Choosing between user-based or item-based CF"></a>Choosing between user-based or item-based CF</h2><p>IBCF is better than UBCF. For the following reasons</p>
<ol>
<li>It is very difficult to find users similar to a given user. The computation of similarities between users is normally a problem because most of them will be zero. While, on the contrary, if you take two items and you try to see if there are users who rated both items, this probability is a little bit higher.</li>
<li>UBCF are not robust. If I rate a few new movies, it is very likely that the similarity between me and the other users will change dramatically.</li>
<li>If you have enough ratings that prove the two items are similar or dissimilar, even if you add more ratings, this similarity will not change much. In an item-based approach you can keep a model like this, without updating it for a lot of time. If you want, you can update the similar matrix once a day or a week or a month. From the practical point of view, it is impossible to create a real commercial recommender system that use a user-based approach on a large catalog of users and items. The performances are too low because you need to update continuously the model. It is time consuming.</li>
</ol>
<h1 id="Association-Rules"><a href="#Association-Rules" class="headerlink" title="Association Rules"></a>Association Rules</h1><p>The idea is to explore the data that you have in order trying to estimate the probability that something happens if something else happened in the past.</p>
<blockquote>
<p>KEY IDEA: if you like i, there is great possibility that you will like j.</p>
</blockquote>
<p>CONFIDENCE/SUPPORT/ASSOCIATION RULES/…</p>
]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Recommender Systems </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[3D Space Reconstruction]]></title>
      <url>/2018/08/09/3D-Space-Reconstruction/</url>
      <content type="html"><![CDATA[<h1 id="How-to-fulfill-the-function-of-3D-Space-Reconstruction-with-given-3-VIEW"><a href="#How-to-fulfill-the-function-of-3D-Space-Reconstruction-with-given-3-VIEW" class="headerlink" title="How to fulfill the function of 3D Space Reconstruction with given 3-VIEW"></a>How to fulfill the function of 3D Space Reconstruction with given 3-VIEW</h1><h2 id="Model-Parameter"><a href="#Model-Parameter" class="headerlink" title="Model Parameter"></a>Model Parameter</h2><p>Input: 3-Input, each is one channel picture (3-VIEW)<br>Output: 3d Object geometry information</p>
<h2 id="How-do-the-3d-objects-saved-as-a-file"><a href="#How-do-the-3d-objects-saved-as-a-file" class="headerlink" title="How do the 3d objects saved as a file"></a>How do the 3d objects saved as a file</h2><p><a href="https://all3dp.com/3d-file-format-3d-files-3d-printer-3d-cad-vrml-stl-obj/#geometry" target="_blank" rel="noopener">RELAITVE INFORMATION</a><br><a href="https://www.researchgate.net/publication/221129055_A_simple_and_efficient_approach_for_3D_mesh_approximate_convex_decomposition" target="_blank" rel="noopener">RELATIVE PAPER</a></p>
<p>A 3D file is used for stored information about 3D models. The basic purpose of 3D file format is to store information about 3D models as plain text. They encode the 3D model’s <strong>geometry, appearance, scene, animations</strong>.</p>
<p>Each 3D model has a unique geometry and the capability of encoding this geometry can be the most important and basic feature of 3D file format. There are three distinct ways of encoding surface geometry, they are known as <strong>approximate mesh, precise mesh, constructive solid geometry</strong>.</p>
<blockquote>
<p>THE APPROXIMATE MESH: The surface of a 3D model is covered with a mesh of tiny imaginary polygons. Triangles are the most commonly used shape. The vertices of the covering triangles and the outward normal verct to the triangles are stored in the file. The triangles approximate the smooth geometry of the surface, hence this is an approximate format.</p>
<p>THE PRECISE MESH: Precise mesh could replace the approximate mesh in the industrial when it comes to a situation that very high resolution models are required. It use non-uniform-rotional BSpline pathes instead of polygons. These surface are smoother.</p>
<p>CONSTRUCTIVE SOLID GEOMETRY (CSG): 3D shapes are built by performing boolean operations of primitive shapes like <strong>cubes, spheres, etc</strong>. This is more user friendly.</p>
</blockquote>
<p>In this research, though the approximate mesh could be one approperiate output (by some MonteCarlo methods, random sampling in the 3D space and select the vetices), however we need to consider the whole model, if we are going to build a model in a 3D space we are going to need an output of scale 10x10x10. This could be too large to train. So it maybe a better idea if we use CSG. The training set are the 3D object of basic shape, combination of basic spheres, cubes and cylinders and maybe with some degrees of ratation. Each object is saved as (<strong>absolute_location, shape_info, rotation</strong>).</p>
<blockquote>
<ol>
<li>Absolute location: the center of the object in the space</li>
<li>Shape Information: (<strong>shape, (length, width, height)/(radius)/(radius, height)</strong>)</li>
<li>Rotation: (x,y,z)</li>
</ol>
</blockquote>
<p>With these as the output, it would be far more easier to train the model. The input are still 3-VIEW.</p>
]]></content>
      
        
        <tags>
            
            <tag> CNN </tag>
            
            <tag> AI </tag>
            
            <tag> Machine Learning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Tensor Flow Session Run]]></title>
      <url>/2018/07/27/Tensor-Flow-Session-Run/</url>
      <content type="html"><![CDATA[<p><a href="https://www.tensorflow.org/api_docs/python/tf/Session" target="_blank" rel="noopener">Origianl TensorFlow.Session</a></p>
<img src="/2018/07/27/Tensor-Flow-Session-Run/1.png">
<h1 id="Session"><a href="#Session" class="headerlink" title="Session"></a>Session</h1><p>一个TensorFLow代码可以氛围两个部分，<strong>定义</strong>和<strong>运行</strong>，我们通过tf.matmul()以及tf.constant()方法定义了graph，而不会立即执行，为了让Tensor流动起来我们创建一个Session，调用run方法。（在执行完毕后将其用close方法关闭）</p>
<p>TensorFlow的run方法的参数如下：<em>run( fetches, feed_dict=None, options=None, run_metadata=None )</em></p>
<h2 id="feteches"><a href="#feteches" class="headerlink" title="feteches"></a>feteches</h2><p>fetches表示了计算图中的一个node，每当我们调用run方法的时候，TensorFlow找到这个node所依赖的所有操作，并且计算出这个node的值。</p>
<h2 id="feed-dict"><a href="#feed-dict" class="headerlink" title="feed_dict"></a>feed_dict</h2><img src="/2018/07/27/Tensor-Flow-Session-Run/2.png">
<p>feed_dict的作用是替换前部分中的某一个tensor的值，我们可以通过使用feed_dict来设置graph的输入量</p>
<h1 id="Placeholder"><a href="#Placeholder" class="headerlink" title="Placeholder"></a>Placeholder</h1><p>此处a并不是一个tensor而是一个placeholder，我们需要定义他的type和shape，但是毋需赋予他具体的值，而在后面的graph中我们可以把placeholder当成一个普通的tensor对象使用，并且只需要一个feed_dict的方法把具体的值提供给placeholder，达到了给graph提供input的目的。</p>
<h1 id="Variable"><a href="#Variable" class="headerlink" title="Variable"></a>Variable</h1><img src="/2018/07/27/Tensor-Flow-Session-Run/3.png">
<p>和之前不可改变的对象相比，我们可以通过tf.Variable()方法来建立一个变量，在机器学习中这个变量往往是我们需要优化的值，比如说weight w或者bias b，变量可以和Placeholder进行计算并且得到一个model，然后我们通过Optimize这个model来得到我们的目标模型。</p>
]]></content>
      
        
        <tags>
            
            <tag> TensorFlow </tag>
            
            <tag> MachineLearning </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Computer Security - Web&Network]]></title>
      <url>/2018/06/30/Computer-Security-Web-Network/</url>
      <content type="html"><![CDATA[<h1 id="Web-Application-Security"><a href="#Web-Application-Security" class="headerlink" title="Web Application Security"></a>Web Application Security</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>3 Tier Web Application Architecture: HTTP Client -&gt; HTTP Server -&gt; Application Server (Business logic) -&gt; Database Server</p>
<p>Untrustworthy Client: The golden rule of web application security is that <strong>the client is never trust worthy</strong>.</p>
<p>Conflicting requirements:</p>
<ol>
<li>Functional Requirement: we need to mix code with data(blog comments)</li>
<li>Security Requirement: never mix code with data</li>
</ol>
<h2 id="Validation"><a href="#Validation" class="headerlink" title="Validation"></a>Validation</h2><ul>
<li>Whitelisting: Effective but limited.</li>
<li>Blacklisting: Good but not safe enough.</li>
<li>Escaping: Transform some special char into something else.</li>
</ul>
<h2 id="Cross-Site-Scripting-XSS"><a href="#Cross-Site-Scripting-XSS" class="headerlink" title="Cross Site Scripting[XSS]"></a>Cross Site Scripting[XSS]</h2><p>Cross site scripting is a vulnerability by means of which client-side code can be injected in a page.</p>
<blockquote>
<p>Cookie theft or session hijack</p>
<p>Manipulation of a session and execution of fraudulent transaction</p>
<p>Snooping on private information</p>
<p>Effectively bypasses the same-origin policy</p>
<p>Drive by Download</p>
</blockquote>
<ol>
<li>Stored XSS: The attacker input is stored on the target server, such as in a database, in a message forum, visitor log, comment field, etc.存储型XSS，又称持久型XSS，他和反射型XSS最大的不同就是，攻击脚本将被永久地存放在目标服务器的数据库和文件中。这种攻击多见于论坛，攻击者在发帖的过程中，将恶意脚本连同正常信息一起注入到帖子的内容之中。随着帖子被论坛服务器存储下来，恶意脚本也永久地被存放在论坛服务器的后端存储器中。当其它用户浏览这个被注入了恶意脚本的帖子的时候，恶意脚本则会在他们的浏览器中得到执行，从而受到了攻击。比如用<code>&lt;script&gt;</code>镶嵌恶意脚本在某帖子，浏览者均会中招。可以看到，存储型XSS的攻击方式能够将恶意代码永久地嵌入一个页面当中，所有访问这个页面的用户都将成为受害者。如果我们能够谨慎对待不明链接，那么反射型的XSS攻击将没有多大作为，而存储型XSS则不同，由于它注入的往往是一些我们所信任的页面，因此无论我们多么小心，都难免会受到攻击。可以说，存储型XSS更具有隐蔽性，带来的危害也更大，除非服务器能完全阻止注入，否则任何人都很有可能受到攻击。</li>
<li>Reflected XSS:反射型XSS，又称非持久型XSS。之所以称为反射型XSS，则是因为这种攻击方式的注入代码是从目标服务器通过错误信息、搜索结果等等方式“反射”回来的。而称为非持久型XSS，则是因为这种攻击方式具有一次性。攻击者通过电子邮件等方式将包含注入脚本的恶意链接发送给受害者，当受害者点击该链接时，注入脚本被传输到目标服务器上，然后服务器将注入脚本“反射”到受害者的浏览器上，从而在该浏览器上执行了这段脚本。比如攻击者将如下链接发送给受害者： <code>http://www.targetserver.com/search.asp?input=&lt;script&gt;alert(document.cookie);&lt;/script&gt;</code>当受害者点击这个链接的时候，注入的脚本被当作搜索的关键词发送到目标服务器的search.asp页面中，则在搜索结果的返回页面中，这段脚本将被当作搜索的关键词而嵌入。这样，当用户得到搜索结果页面后，这段脚本也得到了执行。这就是反射型XSS攻击的原理，可以看到，攻击者巧妙地通过反射型XSS的攻击方式，达到了在受害者的浏览器上执行脚本的目的。由于代码注入的是一个动态产生的页面而不是永久的页面，因此这种攻击方式只在点击链接的时候才产生作用，这也是它被称为非持久型XSS的原因。</li>
<li>DOM Based XSS:通常这个页面作为用户欢迎页面, 例如:<code>http://www.vulnerable.site/welcome.html?name=Joe</code>,然而，如下的一个请求: <code>http://www.vulnerable.site/welcome.html?name=&lt;script&gt;alert(document.cookie)&lt;/script&gt;</code>将产生xss条件。让我们看看为什么：受害者的浏览器接收到这个链接，发送HTTP请求到www.vulnerable.site并且接受到上面的HTML页。受害者的浏览器开始解析这个HTML为DOM，DOM包含一个对象叫document，document里面有个URL属性，这个属性里填充着当前页面的URL。当解析器到达javascript代码，它会执行它并且修改你的HTML页面。倘若代码中引用了document.URL，那么，这部分字符串将会在解析时嵌入到HTML中，然后立即解析，同时，javascript代码会找到(alert(…))并且在同一个页面执行它，这就产生了xss的条件。\</li>
</ol>
<pre><code>SXSS
&lt;script&gt;
   alert(&#39;JavaScript Executed&#39;);
&lt;/script&gt;
</code></pre><pre><code>DBXSS
&lt;script&gt;
    document.write(&quot;&lt;b&gt;Current URL&lt;/b&gt; : &quot; + document.baseURI);
&lt;/script&gt;
</code></pre><blockquote>
<p>Same Origin Policy: all client-side code (e.g., JavaScript) loaded from origin A should only be able to access data from origin A[Origin = <protocol, host,="" port="">]</protocol,></p>
</blockquote>
<h2 id="Solution-of-XSS"><a href="#Solution-of-XSS" class="headerlink" title="Solution of XSS"></a>Solution of XSS</h2><h3 id="Blacklisting-BAD"><a href="#Blacklisting-BAD" class="headerlink" title="Blacklisting: BAD"></a>Blacklisting: BAD</h3><h3 id="Escaping"><a href="#Escaping" class="headerlink" title="Escaping"></a>Escaping</h3><h3 id="CSP"><a href="#CSP" class="headerlink" title="CSP"></a>CSP</h3><h2 id="SQL-Injection"><a href="#SQL-Injection" class="headerlink" title="SQL Injection"></a>SQL Injection</h2><pre><code>SELECT * FROM Users WHERE username=&#39;cesare&#39; AND password=&#39;secret;)&#39;;
</code></pre><p>But in SQL ‘–’ means comment! We could have username as <strong>cesare’;–</strong></p>
<pre><code>SELECT * FROM Users WHERE username=&#39;cesare&#39;;--&#39; AND password=&#39;&#39;;
</code></pre><p>Or even without a user name, we insert into username of <strong>‘ OR ‘1’=’1’;–</strong></p>
<pre><code>SELECT * FROM Users WHERE username=&#39;&#39; OR &#39;1&#39;=&#39;1&#39;;--&#39; AND password=&#39;&#39;;
</code></pre><p>Even Retrive more!</p>
<pre><code>SELECT name, phone, address FROM Users WHERE Id=&#39;&#39; UNION ALL SELECT name, creditCardNumber,CCV2 from CreditCardTable;--&#39;;
</code></pre><p>Or Insert! Here in the username we fill in <strong>cesare’, ‘30L’)–</strong></p>
<pre><code>INSERT INTO results VALUES (NULL, &#39;cesare&#39;, &#39;30L&#39;)--&#39;, &#39;18&#39;)
</code></pre><h2 id="Solution-of-SQL-Injection"><a href="#Solution-of-SQL-Injection" class="headerlink" title="Solution of SQL Injection"></a>Solution of SQL Injection</h2><h3 id="Filering-could-be-a-bad-for-the-password-field"><a href="#Filering-could-be-a-bad-for-the-password-field" class="headerlink" title="Filering: could be a bad for the password field"></a>Filering: could be a bad for the password field</h3><h2 id="URL-Tampering"><a href="#URL-Tampering" class="headerlink" title="URL Tampering"></a>URL Tampering</h2><p>Do the hacking by changing the url. Like insert a path in the url.</p>
<h2 id="Password-Security"><a href="#Password-Security" class="headerlink" title="Password Security"></a>Password Security</h2><h2 id="Cookies"><a href="#Cookies" class="headerlink" title="Cookies"></a>Cookies</h2><p>Cookies Store the client information.</p>
<blockquote>
<p>Original Idea: Site Customization</p>
<p>Abuse: Privacy Violations</p>
<p>Dangeous Idea: User Authentication and sessions</p>
</blockquote>
<img src="/2018/06/30/Computer-Security-Web-Network/1.png">
<p>Since HTTP is stateless, hijacking can occur:</p>
<ul>
<li>By stealing a cookie with an XSS attack </li>
<li>By brute forcing a weak session id parameter</li>
</ul>
<h2 id="Cross-Site-Request-Forgery-CSRF"><a href="#Cross-Site-Request-Forgery-CSRF" class="headerlink" title="Cross-Site Request Forgery (CSRF)"></a>Cross-Site Request Forgery (CSRF)</h2><p>Forces an user to execute unwanted actions (state-changing action) on a web application in which he is currently authenticated (e.g., with cookies).登录受信任网站A，并在本地生成Cookie。然后在不登出A的情况下，访问危险网站B。There should be state-changing action in the page that needs to be protected against CSRF.</p>
<p>Key Concept: malicious requests (e.g., crafted links) are routed to the vulnerable web application through the victim’s browser: Websites cannot distinguish if the requests coming from authenticated users have been originated by an explicit user interaction or not.</p>
<p>Solution: Use Session tokens, random challenge token, it could associated to user’s session (unique) and regenerated at each request (e.g., for form involving sensitive operations)</p>
<h1 id="Network-Protocal-Attacks"><a href="#Network-Protocal-Attacks" class="headerlink" title="Network Protocal Attacks"></a>Network Protocal Attacks</h1><h2 id="Denial-of-Service-against-availability-service-unavailablt-to-legitimate-users"><a href="#Denial-of-Service-against-availability-service-unavailablt-to-legitimate-users" class="headerlink" title="Denial of Service (against availability): service unavailablt to legitimate users"></a>Denial of Service (against availability): service unavailablt to legitimate users</h2><p>Examples: Killer Packets, SYN Flood, Smurf/multiplication/amplification attacks, Distributed DoS</p>
<h3 id="Killer-Packets"><a href="#Killer-Packets" class="headerlink" title="Killer Packets"></a>Killer Packets</h3><p>Ping of Death-攻击者故意发送大于65535字节的ip数据包给对方。</p>
<p>Teardop-向目标主机发送损坏的IP包，使其难以被目标主机重新组合。只需要几个数据包，就可以使目标主机卡死,蓝屏,重启。</p>
<p>Land Attack-srcIP==dstIP, loop and lock up a TCP/IP stack.</p>
<h3 id="SYN-Flood-Attacks"><a href="#SYN-Flood-Attacks" class="headerlink" title="SYN Flood Attacks"></a>SYN Flood Attacks</h3><p>Attacker generates a high volume of SYN requests with spoofed source address. Many half-open TCP/IP connections fill the queue.</p>
<p><strong>Solution</strong>: SYN-cookies avoid this: reply with SYN+ACK but discard the half-open connection, and wait for a subsequent ACK.</p>
<h3 id="Distributed-DoS"><a href="#Distributed-DoS" class="headerlink" title="Distributed DoS"></a>Distributed DoS</h3><p>Botnet: network of compromised computers, called bots (i.e., infected by malware).</p>
<p>C&amp;C: dedicated command-and-control infrastructure so that the attacker (botmaster) can send commands to the bots.</p>
<p>The attacker sends ICMP packets with spoofed sender (victim) to a broadcast address(并不是像上文中的攻击一样attacker向victim发送攻击包，而是attacker假装是victim发送多个包给很多的host,host回复给victim使victim的bandwidth被填满).<strong>注意Amplification Hell， 对于不同的protocol，很有可能发送的包的大小和ACK包的大小倍数相差很大。</strong></p>
<img src="/2018/06/30/Computer-Security-Web-Network/2.png">
<h2 id="Sniffing-against-confidentiality-abusive-reading-of-network-packets"><a href="#Sniffing-against-confidentiality-abusive-reading-of-network-packets" class="headerlink" title="Sniffing (against confidentiality): abusive reading of network packets"></a>Sniffing (against confidentiality): abusive reading of network packets</h2><p>Solution: Use switched networks as opposed to hub-based networks.</p>
<h2 id="Spoofing-against-integrity-and-authenticity-forging-network-packets"><a href="#Spoofing-against-integrity-and-authenticity-forging-network-packets" class="headerlink" title="Spoofing (against integrity and authenticity): forging network packets"></a>Spoofing (against integrity and authenticity): forging network packets</h2><p>First come, first trusted! An attacker can forge replies easily: lack of authentication.</p>
<h3 id="IP-address-spoofing"><a href="#IP-address-spoofing" class="headerlink" title="IP address spoofing"></a>IP address spoofing</h3><p>The IP source address is not authenticated. Changing it in UDP or ICMP packets is easy. However, the attacker will not see the answers, because they will be sent to the spoofed host (blind spoofing). But if the attacker is on the same network, s(he) can sniff the rest, or use ARP spoofing.</p>
<p>正常的三次握手</p>
<img src="/2018/06/30/Computer-Security-Web-Network/3.png">
<p>被劫持的三次握手</p>
<img src="/2018/06/30/Computer-Security-Web-Network/4.png">
<blockquote>
<p>TCP Session Hijack</p>
<p>Taking over an active TCP session if the attacker (C) can sniff the packets:</p>
<ol>
<li><p>C follows the conversation of A and B recording the sequence numbers.</p>
</li>
<li><p>C somehow disrupts B’s connection (e.g. SYN Flood): B sees only a “random” disruption of service.</p>
</li>
<li><p>C takes over the dialogue with A by spoofing B address and starting with a correct ISN. A suspects nothing.</p>
</li>
</ol>
</blockquote>
<p><strong>The attacker can avoid disrupting B’s session and just inject things in the flow only if s(he) is a man in the middle and can control/resync all the traffic flowing through.</strong></p>
<blockquote>
<p><strong>Man in the middle</strong>: A broad category comprising all the attacks where an attacker can impersonate the server with respect to the client and vice-versa</p>
</blockquote>
<h2 id="Spanning-Tree-Protocol"><a href="#Spanning-Tree-Protocol" class="headerlink" title="Spanning Tree Protocol"></a>Spanning Tree Protocol</h2><p>The STP (802.1d) avoids loops on switched networks by building a spanning tree (ST). Switches decide how to build the ST by exchanging BPDU (bridge protocol data unit) packets to elect the root node. BPDU packets are not authenticated, so, an attacker can change the shape of the tree for sniffing or ARP spoofing purposes.</p>
<h2 id="DNS-Poisoning"><a href="#DNS-Poisoning" class="headerlink" title="DNS Poisoning"></a>DNS Poisoning</h2><p>When a non-authoritative DNS server receives a request to resolve a domain name:</p>
<ul>
<li>If it cached the answer, it answers</li>
<li>If no answer in cache: Recursion - resolves the name on behalf of the client OR Iterative - gives the authoritative DNS address.</li>
</ul>
<p>How to Poison the Cache?</p>
<ol>
<li>The attacker makes a recursive query to the victim DNS server: it will contact the authoritative server.</li>
<li>The attacker spoofs the answer impersonating the authoritative DNS server. And the server will trust it</li>
</ol>
<h2 id="DHCP-Poisoning"><a href="#DHCP-Poisoning" class="headerlink" title="DHCP Poisoning"></a>DHCP Poisoning</h2><p>The attacker can intercept requests, be the first to answer, and client will believe that answer. It’s a denial of service attack, an attacker sends forged DHCP requests to the server and leases all the available IP’s thus the legitimate clients will not get an IP assigned; or the Attacker may send bogus request/replies luring the client to connect to attacker’s machine instead of valid DHCP server. It happens because the DHCP protocol does not support authentication, the client must blindly believe any DHCP offer that it sees; thus, an arbitrary client can race (and win) against the real DHCP Server.</p>
<h2 id="ICMP-Redirect"><a href="#ICMP-Redirect" class="headerlink" title="ICMP Redirect"></a>ICMP Redirect</h2><p>Tells an host that a better route exists for a given destination, and gives the gateway for that route.</p>
<p>The attacker can forge an ICMP redirect packet to elect his/her computer as the gateway.</p>
<h1 id="Secure-Network-Architectures"><a href="#Secure-Network-Architectures" class="headerlink" title="Secure Network Architectures"></a>Secure Network Architectures</h1><h2 id="Firewall"><a href="#Firewall" class="headerlink" title="Firewall"></a>Firewall</h2><p>Firewall is network access control system that verifies all the packets(traffic) flowing through it. It has to be the ONLY point between a network and outside network. It has two functions usually: <strong>IP Packet Filtering</strong>, <strong>Network Address Translation</strong>.</p>
<p>It may be powerless against insider attacks and unchecked path.</p>
<p>Firewall itself is a computer, but most times it is only an embedded appliance with just a firmware. </p>
<blockquote>
<p>Network layer firewall</p>
<p>Packet filters</p>
<p>Stateful packet filters</p>
<p>Application layer firewall</p>
<p>Circuit level firewall</p>
<p>Application proxies</p>
</blockquote>
<h2 id="Packet-Filters"><a href="#Packet-Filters" class="headerlink" title="Packet Filters"></a>Packet Filters</h2><p>Packet by packet processing. Decodes the IP header - <em>SRC and DST IP/port, Protocol Type, IP options</em>.</p>
<p>It is stateless and cannot track TCP connections, but it could sets a set of rules in the packet processing (block/allow/log).</p>
<h2 id="Stateful-Dynamic-Packet-Filters"><a href="#Stateful-Dynamic-Packet-Filters" class="headerlink" title="Stateful(Dynamic) Packet Filters"></a>Stateful(Dynamic) Packet Filters</h2><p>Include network packet filters, plus <strong>1. track the TCP state machine</strong>, <strong>2. track connections without adding response rule</strong>.</p>
<p>It could logging and accounting on connections. </p>
<h2 id="Session-Handling"><a href="#Session-Handling" class="headerlink" title="Session Handling"></a>Session Handling</h2><p>A session is an atomic transport layer exchange of application data between 2 hosts(TCP/UDP). It is fundamental for NAT.</p>
<h2 id="NAT-Session-Initialization"><a href="#NAT-Session-Initialization" class="headerlink" title="NAT Session Initialization"></a>NAT Session Initialization</h2><img src="/2018/06/30/Computer-Security-Web-Network/5.png">
<img src="/2018/06/30/Computer-Security-Web-Network/6.png">
<img src="/2018/06/30/Computer-Security-Web-Network/7.png">
<h2 id="Circuit-Firewalls"><a href="#Circuit-Firewalls" class="headerlink" title="Circuit Firewalls"></a>Circuit Firewalls</h2><p>Client connects to a specific TCP port on the firewall, which then connects to the address and port of the desired server (not transparent!). (EG: SOCKS)</p>
<h2 id="Application-Proxies"><a href="#Application-Proxies" class="headerlink" title="Application Proxies"></a>Application Proxies</h2><p>Same as circuit firewalls, but at application layer.</p>
<p>Inspect, validate, manipulate protocol application data (e.g., rewrite HTTP frames).</p>
<img src="/2018/06/30/Computer-Security-Web-Network/8.png">
<h2 id="Dual-Multi-Zone-Architectures"><a href="#Dual-Multi-Zone-Architectures" class="headerlink" title="Dual/Multi Zone Architectures"></a>Dual/Multi Zone Architectures</h2><p><strong>Problem</strong>: if we mix externally accessible servers with internal clients, we lower the security of the internal network.</p>
<p><strong>Solution</strong>: we allow external access to the accessible servers, but not to the internal network.</p>
<p><strong>General idea</strong>: split the network by privileges levels. Firewalls to regulate access.</p>
<p>DMZ - demilitarized zone: On the DMZ no critical or irreplaceable data. The DMZ is almost as risky as the Internet.</p>
<img src="/2018/06/30/Computer-Security-Web-Network/9.png">
<h2 id="Virtual-Private-Network-VPN"><a href="#Virtual-Private-Network-VPN" class="headerlink" title="Virtual Private Network: VPN"></a>Virtual Private Network: VPN</h2><p><strong>Target</strong>: Ensure CIA to data transmitted over a public network (i.e., the Internet).</p>
<p><strong>Solution: VPN</strong>, an encrypted overlay connection over a (public) network.</p>
<img src="/2018/06/30/Computer-Security-Web-Network/10.png">
<blockquote>
<p>TWO MODES OF VPN</p>
<p>Full tunnelling: Every packet goes through the tunnel/ Traffic multiplication, could be inefficient/ Single point of control and application of all security policies as if the client were in the corporate network.</p>
<p>Split tunnelling: Traffic to the corporate network: in VPN/ traffic to the Internet: directly to ISP/ More efficient, less control./ Just similar to the case of the PC connected via 3G.</p>
</blockquote>
<h1 id="Network-Security-SSL-and-SET"><a href="#Network-Security-SSL-and-SET" class="headerlink" title="Network Security: SSL and SET"></a>Network Security: SSL and SET</h1><h2 id="Introduction-1"><a href="#Introduction-1" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>Problems of remoteness</strong>: Trust factor between parties/Use of sensitive data/Atomicity of transaction</p>
<p><strong>Internet protocol problems</strong>: Authentication//Confidentiality/Transparence and critical mass problem</p>
<h2 id="HTTP-over-SSL-Secure-Socket-Layer-or-HTTPS"><a href="#HTTP-over-SSL-Secure-Socket-Layer-or-HTTPS" class="headerlink" title="HTTP over SSL (Secure Socket Layer), or HTTPS"></a>HTTP over SSL (Secure Socket Layer), or HTTPS</h2><p>Communication confidentiality and integrity/Mutual authentication/No guarantees on data usage/No strict authentication of client (in practice)</p>
<h3 id="SSL"><a href="#SSL" class="headerlink" title="SSL"></a>SSL</h3><p>SSL enforces: Confidentiality and integrity of the communications/Server authentication/Client authentication (optionally)/Uses both symmetric and asymmetric cryptography for performance reasons</p>
<img src="/2018/06/30/Computer-Security-Web-Network/11.png">
<p><strong>SSL is by design resistant to MITM!</strong></p>
<p>PROS: Protects transmissions: Confidentiality/Integrity/Ensures authentication of server/client (optionally)</p>
<p>CONS: No protection before or after transmission on server/client (e.g. trojan)/By abuser (e.g. non-honest merchant)/Relies on PKI/Not foolproof</p>
<h2 id="SET-Secure-Electronic-Transaction"><a href="#SET-Secure-Electronic-Transaction" class="headerlink" title="SET (Secure Electronic Transaction)"></a>SET (Secure Electronic Transaction)</h2><p>Guarantees on data usage and transaction security enforcement/Missing critical mass support. Uses the concept of a dual signature(将两条消息hash各自hash成一个digest，然后将两个digest hash成一个digest来确保两条消息都没有被修改过).</p>
<p>Approach</p>
<ol>
<li>Customer browses website and decides on what to purchase</li>
<li>Customer sends order and payment information, which includes 2 parts in one message: <em>a. Purchase Order – this part is for merchant</em>,<em>b. Card Information – this part is for merchant’s bank only.</em></li>
<li>Merchant forwards card information (part b) to their bank</li>
<li>Merchant’s bank checks with Issuer for payment authorization</li>
<li>Issuer send authorization to Merchant’s bank</li>
<li>Merchant’s bank send authorization to merchant</li>
<li>Merchant completes the order and sends confirmation to the customer</li>
<li>Merchant captures the transaction from their bank</li>
<li>Issuer prints credit card bill (invoice) to customer</li>
</ol>
<img src="/2018/06/30/Computer-Security-Web-Network/12.png">
<p>hash 1: hash of order information</p>
<p>hash 2: hash of pay instruction</p>
]]></content>
      
        
        <tags>
            
            <tag> Computer Securit </tag>
            
            <tag> Web Application </tag>
            
            <tag> Network Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Advanced Computer Architectures]]></title>
      <url>/2018/05/16/Advanced-Computer-Architectures/</url>
      <content type="html"><![CDATA[<p>A note for the course of <em>Advanced Computer Architectures</em>.</p>
<h1 id="L00-Intro"><a href="#L00-Intro" class="headerlink" title="L00 Intro"></a>L00 Intro</h1><h1 id="L01-Pipelining-Basic-Concepts"><a href="#L01-Pipelining-Basic-Concepts" class="headerlink" title="L01 Pipelining: Basic Concepts"></a>L01 Pipelining: Basic Concepts</h1><h2 id="MIPS"><a href="#MIPS" class="headerlink" title="MIPS"></a>MIPS</h2><ul>
<li>ALU Instructions: add $s1, $s2, $s3</li>
<li>Load/Store Instructions: lw/sw $s1 offset($s2)</li>
<li>Branch Instructions: beq/bne $s1, $s2, L1</li>
</ul>
<p>R-Format for Instructions</p>
<img src="/2018/05/16/Advanced-Computer-Architectures/1.png">
<p>Phase of execution of MIPS Instructions:</p>
<ol>
<li>Instruction Fetch</li>
<li>Instruction Decode and Register Read</li>
<li>Execution</li>
<li>Memory Access</li>
<li>Write Back Cycle</li>
</ol>
<p>Different type of Instructions(R/I/J) may require different execution phase. In an ALU R-Instruction, there is no needs for the memory access.</p>
<h2 id="Pipelining"><a href="#Pipelining" class="headerlink" title="Pipelining"></a>Pipelining</h2><p><strong>Basic idea</strong>: The execution of an instruction is divided into different phases (pipelines stages), requiring a fraction of the time necessary to complete the instruction.</p>
<blockquote>
<p><strong>The pipeline stages must besynchronized</strong>: the duration of a clock cycle is defined by the time requested by the slower stage of the pipeline.The goal is to balance the length of each pipeline stage.</p>
<p>一个MIPS Instruction可能需要8ns，但是为了在宏观上实现pipelining，我们把5个阶段分开，并且将最长事件的阶段作为一个clock cycle，虽然每一个Instruction花费的时间变多了，但是由于pipelining，整体的output提高了。</p>
</blockquote>
<img src="/2018/05/16/Advanced-Computer-Architectures/2.png">
<h2 id="Pipeline-Hazards"><a href="#Pipeline-Hazards" class="headerlink" title="Pipeline Hazards"></a>Pipeline Hazards</h2><ol>
<li>Structural Hazards: Use the same resource from different instructions simultaneously</li>
<li>Data Hazards: Attempt to use a result before it is ready</li>
<li>Control Hazards: Attempt to make a decision on the next instruction to execute before the condition is evaluated.</li>
</ol>
<blockquote>
<p>No s-hazards in MIPS<br>While d-hazard in very possible (RAW)<br>WAW/WAR occur more easily when instructions are executed out-of-order.</p>
</blockquote>
<p>Data Hazards Solution:</p>
<ol>
<li>Insertion of nop</li>
<li>Rescheduling to avoid correlating instruction too close</li>
<li>Insertion of stalls</li>
<li>data forward or bypassing (uses temporary results stored in the pipeline registers instead of waiting for the write back of results in the RF)</li>
</ol>
<blockquote>
<p>The differnce between nop and stalls is that nop is an instruction, while stalls is only stalled for one clk</p>
<p>Forwarding Paths<br>EX/EX path<br>MEM/EX path<br>MEM/ID path<br>MEM/MEM path (for load/stores)</p>
<p>To avoid the read/write RF in one clk, we assume the RF read occurs in the second half of clock cycle and the RF write in the first half of clock cycle.</p>
</blockquote>
<h2 id="Performance-Metrics-in-Pipelining"><a href="#Performance-Metrics-in-Pipelining" class="headerlink" title="Performance Metrics in Pipelining"></a>Performance Metrics in Pipelining</h2><p>IC = Instruction Cound</p>
<p>Clk Cycles = IC + #Stalls + 4</p>
<p>CPI = Clk Cycles/IC</p>
<p>MIPS = f<sub>clock</sub>/(CPI*10<sup>6</sup>)</p>
<p>The ideal CPI on a pipelined processor would be 1, but stalls cause the pipeline performance to degrade form the ideal performance.</p>
<h1 id="L02-Branch-Prediction-Techiniques"><a href="#L02-Branch-Prediction-Techiniques" class="headerlink" title="L02 Branch Prediction Techiniques"></a>L02 Branch Prediction Techiniques</h1><p>Control hazards: Attempt to make a decision on the next instruction to fetch before the branch condition is evaluated.</p>
<h2 id="Branch-Hazards-Solution"><a href="#Branch-Hazards-Solution" class="headerlink" title="Branch Hazards Solution"></a>Branch Hazards Solution</h2><p><strong>Conservative Assumption</strong>: stall the pipeline until the branch decision is taken, and then fetch the correct instruction.</p>
<p><strong>Conservative Assumption with Forwarding</strong></p>
<p><strong>Early Evaluation of the PC</strong>: get the result of the branch prediction in the end of ID state.</p>
<h2 id="Branch-Prediction-Techniques"><a href="#Branch-Prediction-Techniques" class="headerlink" title="Branch Prediction Techniques"></a>Branch Prediction Techniques</h2><h3 id="Static-Branch-Prediction-Techniques"><a href="#Static-Branch-Prediction-Techniques" class="headerlink" title="Static Branch Prediction Techniques"></a>Static Branch Prediction Techniques</h3><p>The actions for a branch are fixed for each branch during the entire execution. The actions are fixed at compile time.</p>
<ol>
<li>Branch Always Not Taken: if the branch is actually taken, make the fetched instruction a nop.</li>
<li>Branch Always Taken</li>
<li>Backward Taken Forward Not Taken: backward-going branches are predicted as taken, while forward-going branches are predicted as not taken.</li>
<li>Profile-Driven Prediction</li>
<li>Delayed Branch: The MIPS compiler always schedules a branch independent instruction after the branch. (there are 4 ways in Delayed Branch: From Before/From Target/From fall-throuogh/From After)</li>
</ol>
<h3 id="Dynamic-Branch-Prediction-Techniques"><a href="#Dynamic-Branch-Prediction-Techniques" class="headerlink" title="Dynamic Branch Prediction Techniques"></a>Dynamic Branch Prediction Techniques</h3><p>The decision causing the branch prediction can dynamically change during the program execution.</p>
<p>Schemes:</p>
<blockquote>
<p>Branch Outcome Predictor<br>Branch Target Predictor/Branch Target Buffer</p>
</blockquote>
<ol>
<li>Branch History Table</li>
<li>Correlating Branch Predictor: Branch predictors that use the behavior of other branches to make a prediction are called Correlating Predictors or 2-level Predictors.</li>
<li>Two-level Adaptive Branch Predictor: The first level history is recorded in one (or more) k-bit shift register called Branch History Register (BHR), which records the outcomes of the k most recent branches. The second level history is recorded in one (or more) tables called Pattern History Table (PHT) of two-bit saturating counters.</li>
<li>Branch Target Buffer</li>
</ol>
<h1 id="L03-Instruction-Level-Parallelism-Part-I-Introduction"><a href="#L03-Instruction-Level-Parallelism-Part-I-Introduction" class="headerlink" title="L03 Instruction Level Parallelism Part I - Introduction"></a>L03 Instruction Level Parallelism Part I - Introduction</h1><h2 id="Dependencies"><a href="#Dependencies" class="headerlink" title="Dependencies"></a>Dependencies</h2><ol>
<li>Data Dependencies(True Data Dependences): RAW-data dependence/WAR-anti dependence/WAW-output dependence</li>
<li>Name Dependencies: 2 instructions use the same register or memory location, but there are no flow of data between the instruction associated with that name.</li>
<li>Control Dependencies</li>
</ol>
<h2 id="Multi-cycles-Basic-Assumptions"><a href="#Multi-cycles-Basic-Assumptions" class="headerlink" title="Multi-cycles: Basic Assumptions"></a>Multi-cycles: Basic Assumptions</h2><ul>
<li>We consider single-issue processors.</li>
<li>Instructions are then issued in-order.</li>
<li>Execution stage might require multiple cycles, depending on the operation type.</li>
<li>Memory stage might require multiple cycles access time due to data cache misses.</li>
</ul>
<blockquote>
<p>ILP = Exploit potential overlap of execution among unrelated instructions<br>While overlapping possible only if: NO structural/RAW/WAR/WAW/Control hazards</p>
</blockquote>
<p>In a multiple-issue pipelined processor, the ideal CPI would be CPI ideal &lt; 1. (Dual issue means there are two lanes to execute the two pipeline simutanously)</p>
<p>The <strong>issue width</strong> is the number of instructions that can be issued in a single cycle by a multiple issue processor</p>
<h2 id="Two-Strategies-to-support-ILP-Dynamic-Scheduling-Static-Scheduling"><a href="#Two-Strategies-to-support-ILP-Dynamic-Scheduling-Static-Scheduling" class="headerlink" title="Two Strategies to support ILP: Dynamic Scheduling/Static Scheduling"></a>Two Strategies to support ILP: Dynamic Scheduling/Static Scheduling</h2><p>Hazards due to data dependences that cannot be solved by forwarding cause stalls of the pipeline: no new instructions are fetched nor issued even if they are not data dependent.</p>
<p><strong>Solution</strong>: Allow data independent instructions behind a stall to proceed. (Enables out-of-order execution and completion/commit)</p>
<h3 id="Dynamic-Scheduling-Superscalar-Processor-Expensive"><a href="#Dynamic-Scheduling-Superscalar-Processor-Expensive" class="headerlink" title="Dynamic Scheduling: Superscalar Processor [Expensive]"></a>Dynamic Scheduling: Superscalar Processor [Expensive]</h3><p>Dynamic Scheduling: The hardware reorder dynamically the instruction execution to reduce pipeline stalls while maintaining data flow and exception behavior.</p>
<ul>
<li>Basically: Instructions are fetched and issued in program order (in-order-issue)</li>
<li>Execution begins as soon as operands are available – possibly, out of order execution – note: possible even with pipelined scalar architectures.</li>
<li>Out-of order execution introduces possibility of WAR and WAW data hazards.</li>
<li>Out-of order execution implies out of order completion unless there is a re-order buffer to get in- order completion</li>
</ul>
<h3 id="Static-Scheduling-VLIW"><a href="#Static-Scheduling-VLIW" class="headerlink" title="Static Scheduling: VLIW"></a>Static Scheduling: VLIW</h3><p>VLIW (Very Long Instruction Word) processors expect dependency-free code generated by the compiler</p>
<h1 id="L04-Instruction-Level-Parallelism-Part-II-Scoreboard"><a href="#L04-Instruction-Level-Parallelism-Part-II-Scoreboard" class="headerlink" title="L04 Instruction Level Parallelism Part II - Scoreboard"></a>L04 Instruction Level Parallelism Part II - Scoreboard</h1><blockquote>
<p>Basic Assumptions<br>Single Issue processors<br>IF might fetch either into an IR or into a queue of pending instructions<br>Instructions are then issued from the IR or from the queue<br>EX stage may require multiple cycles<br>MEM stage may require multiple cycles</p>
</blockquote>
<h2 id="Scoreboard-Pipeline-in-order-issue-but-out-of-order-execution-completion"><a href="#Scoreboard-Pipeline-in-order-issue-but-out-of-order-execution-completion" class="headerlink" title="Scoreboard Pipeline: in-order issue but out-of-order execution/completion"></a>Scoreboard Pipeline: in-order issue but out-of-order execution/completion</h2><p>Due to out-of-order completion WAR and WAW hazards can occur.</p>
<p>Scoreboard has 4 stages</p>
<ul>
<li>Issue (decode and check no WAW) [INORDER]</li>
<li>Read Operands (wait until no RAW) } [OUT OF ORDER]</li>
<li>Execution [OUT OF ORDER]</li>
<li>Write result (check no WAR) [OUT OF ORDER]</li>
</ul>
<blockquote>
<p>Optimisations:<br>check for WAW postponed in WRITE Stage instead of in ISSUE Stage<br>forwarding</p>
</blockquote>
<h1 id="L05-Instruction-Level-Parallelism-Part-III-Tomasulo"><a href="#L05-Instruction-Level-Parallelism-Part-III-Tomasulo" class="headerlink" title="L05 Instruction Level Parallelism Part III - Tomasulo"></a>L05 Instruction Level Parallelism Part III - Tomasulo</h1><h2 id="Scheme"><a href="#Scheme" class="headerlink" title="Scheme"></a>Scheme</h2><ul>
<li>ISSUE: [IN ORDER] check for structural hazards in RESERVATION STATIONS (not in FU)</li>
<li>EXECUTION: [OUT OF ORDER] When operands ready (Check for RAW hazards solved)/When FU available (Check for structural hazards in FU)</li>
<li><p>WRITE RESULT: [OUT OF ORDER] Execution completion depends on latency of FUs</p>
</li>
<li><p>REGISTER RENAMING based on Reservation Stations to avoid WAR and WAW hazards</p>
</li>
<li>Results dispatched to RESERVATION STATIONS and to RF through the Common Data Bus</li>
<li>Control is distributed on Reservation Stations</li>
<li>Reservation Stations offer a sort of data forwarding!</li>
</ul>
<h1 id="L06-Instruction-Level-Parallelism-Part-IV-Register-Renaming"><a href="#L06-Instruction-Level-Parallelism-Part-IV-Register-Renaming" class="headerlink" title="L06 Instruction Level Parallelism Part IV - Register Renaming"></a>L06 Instruction Level Parallelism Part IV - Register Renaming</h1><p>Tomasulo: Implicit Register Renaming<br>Explicit Register Renaming</p>
<h2 id="Implicit-Register-Renaming"><a href="#Implicit-Register-Renaming" class="headerlink" title="Implicit Register Renaming"></a>Implicit Register Renaming</h2><p>Register renaming provided by Reservation Stations (which buffer the operands of instructions) to eliminate WAR and WAW hazards</p>
<p>Out-of-order commit really messes up our chance to get precise exceptions!</p>
<h2 id="Explicit-Register-Renaming"><a href="#Explicit-Register-Renaming" class="headerlink" title="Explicit Register Renaming"></a>Explicit Register Renaming</h2><p>Use physical register file that is larger than number of registers specified by the ISA.</p>
<p>对于每一个Function Unit由于其可能具有潜在的WAW等可能性，故我们可以分配一个新的Register给他，比如两个连续的指令:</p>
<blockquote>
<p>DIVD F10 F0 F6<br>ADDD F6 F8 F2<br>由于下面的指令很可能在上面的完成前就完成了，我们为了避免WAR，我们讲ADDD的结果储存在P42中（假设原来的F6是在P32），这就解决了WAR问题。</p>
</blockquote>
<h1 id="L07-Instruction-Level-Parallelism-Part-V-VLIW"><a href="#L07-Instruction-Level-Parallelism-Part-V-VLIW" class="headerlink" title="L07 Instruction Level Parallelism Part V - VLIW"></a>L07 Instruction Level Parallelism Part V - VLIW</h1><p>Single-Issue Processors: Scalar processors that fetch and issue max one operation in each clock cycle.</p>
<p>Multiple-Issue Processors require: Fetching more instructions in a cycle (higher bandwidth from the instruction cache) </p>
<p>Multiple-Issue Processors can be: </p>
<ul>
<li>Dynamically scheduled (issue a varying number of instructions at each clock cycle).</li>
<li>Statically scheduled (issue a fixed number of instructions at each clock cycle).</li>
</ul>
<h2 id="VLIW"><a href="#VLIW" class="headerlink" title="VLIW"></a>VLIW</h2><p>VLIW approach advantages:</p>
<ul>
<li>Simpler hardware because the complexity of the control unit is moved to the compiler</li>
<li>Low power consumption</li>
<li>Good performance through extensive compiler optimization</li>
</ul>
<p>VLIW approach disadvantages:</p>
<ul>
<li>Early VLIWs were quite rigid in the instruction format and they required recompilation of programs for different versions of the hardware</li>
</ul>
<h2 id="Dependencies-1"><a href="#Dependencies-1" class="headerlink" title="Dependencies"></a>Dependencies</h2><ul>
<li><p>RAW Hazards: Scalars/superscalars generate NOPs/stalls or execute successive instructions (dynamic scheduling or instruction reordering)</p>
</li>
<li><p>WAR and WAW Hazards: they are statically solved by the compiler by correctly selecting temporal slots for the operations or by register renaming.</p>
</li>
<li><p>Structural hazards: they are also solved by the compiler.</p>
</li>
<li><p>Control hazards are solved dynamically by the hardware by flushing the execution of instructions due to a mispredicted branch.</p>
</li>
</ul>
<h1 id="L08-VLIW-Code-Scheduling"><a href="#L08-VLIW-Code-Scheduling" class="headerlink" title="L08 VLIW Code Scheduling"></a>L08 VLIW Code Scheduling</h1><h2 id="Dependence-Graph"><a href="#Dependence-Graph" class="headerlink" title="Dependence Graph"></a>Dependence Graph</h2><h2 id="Ready-List"><a href="#Ready-List" class="headerlink" title="Ready List"></a>Ready List</h2><h1 id="L09-Reorder-Buffer"><a href="#L09-Reorder-Buffer" class="headerlink" title="L09 Reorder Buffer"></a>L09 Reorder Buffer</h1><h2 id="ReOrder-Buffer-ROB"><a href="#ReOrder-Buffer-ROB" class="headerlink" title="ReOrder Buffer (ROB)"></a>ReOrder Buffer (ROB)</h2><ul>
<li>Buffer to hold the results of instructions that have finished execution but non committed</li>
<li>Buffer to pass results among instructions that can be speculated</li>
<li>Support out-of-order execution but in-order commit</li>
</ul>
<h2 id="Four-Steps-of-Speculative-Tomasulo-Algorithm"><a href="#Four-Steps-of-Speculative-Tomasulo-Algorithm" class="headerlink" title="Four Steps of Speculative Tomasulo Algorithm"></a>Four Steps of Speculative Tomasulo Algorithm</h2><ol>
<li>Issue — get instruction from FP Op Queue: If reservation station and ROB slot free, issue instr &amp; send operands &amp; ROB no. for destination(this stage sometimes called “dispatch”)</li>
<li>Execution — operate on operands (EX): When both operands ready then execute; if not ready, watch CDB for result; when both operands in reservation station, execute; checks RAW (sometimes called “issue”)</li>
<li>Write result — finish execution (WB) Write on Common Data Bus to all awaiting FUs &amp; ROB; mark reservation station available.</li>
<li>Commit — update register with ROB resultWhen instr. at head of ROB &amp; result present, update register with result (or store to memory) and remove instr from ROB. Mispredicted branch flushes ROB (sometimes called “graduation”)</li>
</ol>
<blockquote>
<p>3 different possible sequences in COMMIT</p>
<ol>
<li>Normal Commit</li>
<li>Store Commit</li>
<li>Instruction is a branch with incorrect prediction</li>
</ol>
</blockquote>
<h1 id="L10-Beyond-ILP-Multithreading"><a href="#L10-Beyond-ILP-Multithreading" class="headerlink" title="L10 Beyond ILP Multithreading"></a>L10 Beyond ILP Multithreading</h1><h1 id="L11-Memory-Hierarchy"><a href="#L11-Memory-Hierarchy" class="headerlink" title="L11 Memory Hierarchy"></a>L11 Memory Hierarchy</h1><h2 id="Main-Goal"><a href="#Main-Goal" class="headerlink" title="Main Goal"></a>Main Goal</h2><p>To increase the performance of a computer through the memory system in order to:</p>
<ul>
<li>Provide the user the illusion to use a memory that is simultaneously large and fast</li>
<li>Provide the data to the processor at high frequency</li>
</ul>
<h2 id="Locality"><a href="#Locality" class="headerlink" title="Locality"></a>Locality</h2><ul>
<li>Temporal Locality: when there is a reference to one memory element, the trend is to refer again to the same memory element soon (i.e., instruction and data reused in loop bodies)</li>
<li>Spatial Locality: when there is a reference to one memory element, the trend is to refer soon at other memory elements whose addresses are close by (i.e., sequence of instructions or accesses to data organized as arrays or matrices)</li>
</ul>
<p>– Exploit temporal locality by keeping the contents of recently accessed locations.<br>– Exploit spatial locality by fetching blocks of data around recently accessed locations.</p>
<p>Levels of memory hierarchy: Registers-&gt;L1 Cache-&gt;L2 Cache-&gt; Main Memory</p>
<h2 id="Basic-Concepts"><a href="#Basic-Concepts" class="headerlink" title="Basic Concepts"></a>Basic Concepts</h2><p>The memory hierarchy is composed of several levels, but data are copied between two adjacent levels. Let us consider two levels: cache and main memory</p>
<p>The cache level is smaller, faster and more expensive</p>
<p>The minimum chunk of data that can be copied in the cache is the <strong>block</strong> or <strong>cache line</strong>.</p>
<p>Cache hit/miss: whether the requested data is found in the one of the cache blocks</p>
<blockquote>
<p><strong>Hit Rate</strong>: Number of memory accesses that find the data in the upper level with respect to the total number of memory accesses[Hit Rate=#hits/#memory access]<br><strong>Hit Time</strong>: time to access the data in the upper level of the hierarchy, including the time needed to decide if the attempt of access will result in a hit or miss<br><strong>Miss Rate</strong>: number of memory accesses not finding the data in the upper level with respect to the total number of memory accesses[Miss Rate=#misses/#memory accesses]<br><strong>Miss Penalty</strong>: time needed to access the lower level and to replace the block in the upper level<br><strong>Miss Time</strong>: miss time= hit time+ miss penalty[typically hit time《miss penalty]<br><strong>Average Memory Access Time/AMAT</strong>: AMAT = HitRate<em>HitTime+MissRate</em>MissTime<br><strong>Average Memory Access Time/AMAT</strong>: AMAT = HitTime+MissRate*MissPenalty</p>
</blockquote>
<h2 id="Cache-Structure"><a href="#Cache-Structure" class="headerlink" title="Cache Structure"></a>Cache Structure</h2><ol>
<li>Valid bit: indicate if this position contains valid data or not. At the bootstrap, all the entries in the cache are marked as INVALID</li>
<li>Cache Tag: contains the value that uniquelly identifies the memory address corresponding to the stored data.</li>
<li>Cache Data: contains a copy of data (block or cache line)</li>
</ol>
<h2 id="Cache-Architecture"><a href="#Cache-Architecture" class="headerlink" title="Cache Architecture"></a>Cache Architecture</h2><ol>
<li>Direct Mapped Cache</li>
<li>Fully Associative Cache</li>
<li>n-way Set-Associative Cache</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Advanced Computer Architectures </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[SVM]]></title>
      <url>/2018/05/06/SVM/</url>
      <content type="html"><![CDATA[<p>This is a note of SVM. The original reading material is <a href="https://blog.csdn.net/v_july_v/article/details/7624837" target="_blank" rel="noopener">here</a></p>
<img src="/2018/05/06/SVM/1.png">
<img src="/2018/05/06/SVM/2.png">
<img src="/2018/05/06/SVM/3.png">
<img src="/2018/05/06/SVM/4.png">
<img src="/2018/05/06/SVM/5.png">
<img src="/2018/05/06/SVM/6.png">]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> SVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[EyePhone]]></title>
      <url>/2018/05/02/Papers-EyePhone/</url>
      <content type="html"><![CDATA[<p>This blog aims to record some relative information about EYEPHONE.</p>
<h1 id="What’s-EyePhone"><a href="#What’s-EyePhone" class="headerlink" title="What’s EyePhone"></a>What’s EyePhone</h1><p>EyePhone is a personal built project, aims to help blind people with their cellphone to detect the obstacles on the road. EyePhone focus on the common road scenes in the city. It has a quite simple use - “Hold the phone, whenever there is a obstacle in the road, remind the user.”</p>
<blockquote>
<p>Obstacles could have following categrories: Stairs, Bicycle, Street Lights, Cars, Other People, and other obstacles.</p>
</blockquote>
<p>There are some basic idea of how to build this babe:)</p>
<p>Updated at 2018.5.2</p>
<ol>
<li><p><strong>Pure empirical method of CNN</strong>: We trust our CNN methods, and offer tons of data (input: images output: obstacles detected y/n) to train it, and later given specific input it could make a decision.</p>
</li>
<li><p><strong>Combine Machine Learning with Prior Knowledge</strong>: We have some prior knowledge in the obstacle detection, like when something is far it would be small in our sight, while close make it bigger in the sights. </p>
</li>
<li><p><strong>Combine CNN with RNN</strong>: This is a very promising idea while I have no idea of where to start now. I found one interesting fact occasionally, that in a badly scaled picture, sometimes it is hard even for human to find what’s in the picture. While it all the pictures are played fast, it would be easily found! (Imagine watching a badly scaled .gif picture!). So maybe we could combine CNN and RNN and contribute to a better performance. </p>
</li>
</ol>
<p>Updated at 2018.5.7 - Start from detection, and build the distance measure on the experience of object detection</p>
<ol>
<li><p><strong>Analysis based on the high precision images</strong>: use F R-CNN to analysis the position of the obstalces.</p>
</li>
<li><p><strong>Analysis based on the low precision images</strong>: use TPN for the temporal information.</p>
</li>
</ol>
<p>Generally speaking, according to the previous papers, it takes more or less 40 seconds to detect some obstacles in the picture. While here it is more promising to use the method with a low precision image and continous temporal information. It we could combine the knowledge of the conteinous temporal information into some sharing information, it would require a far more less computation.</p>
<p>Updated at 2018.5.10 - Maybe a detection will be good enought to get the Regions of Interests in the picture, and we could only train it to get the ability of distance detection.</p>
<ol>
<li><strong>Analysis based on SS</strong>: use machine learning methods train the model the ability of distance detection, hence there are two conditions we have to reach first. First, we have to make sure Select Search method is good enough to extract all the important information in the picture. Second, this method would have the advantages that it may need less information to train, this scale is handlable in a personal computer, while we have to make sure that we only analysis the RoI of greater weights. (Could we use a neural method to guide the selective search like we do in the AlphaZero?)</li>
</ol>
<h1 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h1><p>In this part, I would noted some useful information I found in some papers and their inspiration on this project. </p>
<h2 id="Paper-Object-Detection-from-Video-Tubelets-with-Convolutional-Neural-Networks"><a href="#Paper-Object-Detection-from-Video-Tubelets-with-Convolutional-Neural-Networks" class="headerlink" title="Paper: Object Detection from Video Tubelets with Convolutional Neural Networks"></a>Paper: Object Detection from Video Tubelets with Convolutional Neural Networks</h2><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S04-07.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO"><a href="#INTRO" class="headerlink" title="INTRO"></a>INTRO</h3><p>Method1: Detect obstacles frame by frame</p>
<p>Method2: Combine Method1 with object tracking</p>
<p>The framework consists of two main modules: 1)a tubelet proposal module that combines object detection and object tracking for tubelet object proposal; 2) a tubelet classification and re-scoring module that performs spatial max-pooling for robust box scoring and temporal convolution for incorporating temporal consistency.</p>
<h3 id="METHOD"><a href="#METHOD" class="headerlink" title="METHOD"></a>METHOD</h3><p>Objects in videos show temporal and spatial consistency. The same object in adjacent frames has similar appearances and locations. Using either (object detectors or object trackers) existing object detection methods or object tracking methods alone cannot effectively solve the VID problem.</p>
<p>The combined model has the discriminative ability from object detectors and the temporal consistency from object trackers. It has 2 following </p>
<ul>
<li>The tubelet proposal module has 3 major steps: </li>
</ul>
<blockquote>
<p>1) image object proposal <strong>(每一帧都进行分析，通过一个算法，将总共可能出现的object的种类从一个很大的类缩减到一个小范围)</strong> </p>
<p>2) object proposal scoring <strong>（对于每个proposal进行分析，根据他们的confidence从几百个proposal进一步削减到几十个proposal）</strong></p>
<p>3) high-confidence object tracking <strong>（对于每一个高confidence的proposal，我们以某一帧为anchor，向前和向后进行track，为了防止track的物体漂移到别的物体或者背景上，当confidence低于某个threshold后停止tracking）</strong>.</p>
</blockquote>
<ul>
<li>Tubelet classification and rescoring has 2 steps: </li>
</ul>
<blockquote>
<p>1) Tubelet box perturbation and max-pooling <strong>（使用这种方法将多个tubelet box进行pooling得到某一帧的boxes）</strong></p>
<p>2) Temporal convolution and re-scoring <strong>（建立一个时序的temporal convolution network 每一个输入x为每一个tubelet box在不同时间【连续输入】的一个三维向量（detection score,tracking score,anchor offset）得到该tubelet box的prediction scores）</strong>.</p>
</blockquote>
<h2 id="Paper-Object-Detection-in-Videos-with-Tubelet-Proposal-Networks"><a href="#Paper-Object-Detection-in-Videos-with-Tubelet-Proposal-Networks" class="headerlink" title="Paper: Object Detection in Videos with Tubelet Proposal Networks"></a>Paper: Object Detection in Videos with Tubelet Proposal Networks</h2><p><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Kang_Object_Detection_in_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO-1"><a href="#INTRO-1" class="headerlink" title="INTRO"></a>INTRO</h3><p>The contribution of this paper is that it propose a new deep learning framework that combines tubelet proposal generation and temporal classification with visual-temporal features. An efficient tubelet proposal generation algorithm is developed to generate tubelet proposals that capture spatiotemporal locations of objects in videos. A temporal LSTM model is adopted for classifying tubelet proposals with both visual features and temporal features. Such high-level temporal features are generally ignored by existing detection systems but are crucial for object detection in videos.</p>
<h3 id="Tubelet-proposal-networks-TPN"><a href="#Tubelet-proposal-networks-TPN" class="headerlink" title="Tubelet proposal networks TPN"></a>Tubelet proposal networks TPN</h3><ul>
<li>Preliminaries on ROI-pooling for regression</li>
</ul>
<p>FAST R-CNN/ROI POOLING</p>
<p>The object of this part is to use ROI-pooling finding the for a <em>t</em>, the corresponding b<sup>i</sup>=(x<sup>i</sup>,y<sup>i</sup>,w<sup>i</sup>,t<sup>i</sup>) denoting the ith box proposal(what could it be!) at time t, where x, y, w and h represent the two coordinates of the box center, width and height of the box proposal.</p>
<ul>
<li>Static object proposals as spatial anchors</li>
</ul>
<p>Let b<sup>i</sup>1 denote a static proposal of interest at time t =1. Particularly, to generate a tubelet proposal starting at b<sup>i</sup>1, visual features within the w-frame temporal window from frame 1 to w are pooled at the same location b<sup>i</sup>1 as r<sup>i</sup>1,r<sup>i</sup>2,…,r<sup>i</sup>w in order to generate the tubelet proposal. We call b<sup>i</sup>1 a “spatial anchor”.</p>
<p>The reason why we are able to pool multi-frame features from the same spatial location for tubelet proposals is that CNN feature maps at higher layers usually have large receptive fields. Even if visual features are pooled from a small bounding box, its visual context is far greater than the bounding box itself. Pooling at the same box locations across time is therefore capable of capturing large possible movements of objects.</p>
<ul>
<li>Supervisions for tubelet proposal generation</li>
</ul>
<p>Our goal is to generate tubelet proposals that have high object recall rates at each frame and can accurately track objects. Based on the pooled visual features r<sup>i</sup>1,r<sup>i</sup>2,…,r<sup>i</sup>w at box locations b<sup>i</sup>t, we train a regression network R(·) that effectively estimates the relative movements w.r.t. the spatial anchors.</p>
<p>Once we obtain such relative movements, the actual box locations of the tubelet could be easily inferred. Our key assumption is that the tubelet proposals should have consistent movement patterns with the ground-truth objects.</p>
<ul>
<li>Initialization for multi-frame regression layer</li>
</ul>
<h2 id="Paper-Fast-R-CNN"><a href="#Paper-Fast-R-CNN" class="headerlink" title="Paper: Fast R-CNN"></a>Paper: Fast R-CNN</h2><p><a href="https://arxiv.org/pdf/1504.08083.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO-2"><a href="#INTRO-2" class="headerlink" title="INTRO"></a>INTRO</h3><p>Object detection is a more challenging task compared with image classification. It has 2 primary challenges:</p>
<p>1) numerous candidate object locations (often called “proposals”) must be processed.<br>2) these candidates provide only rough localization that must be refined to achieve precise localization</p>
<p>While in this paper, based on the work of R-CNN, faster R-CNN has a better performance while at the same time decrease the amout of calculation in the whole process.</p>
<h3 id="R-CNN-Drawback"><a href="#R-CNN-Drawback" class="headerlink" title="R-CNN Drawback"></a>R-CNN Drawback</h3><p>1) Training is a multi-stage pipeline<br>2) Training is expensive in space and time<br>3) Object detection is slow</p>
<p>SPPnet(Spatial pyramid pooling networks) soleve the problem that <strong>R-CNN does not have sharing computation</strong>, it accelerates R-CNN.</p>
<h3 id="FINE-TUNING"><a href="#FINE-TUNING" class="headerlink" title="FINE-TUNING"></a>FINE-TUNING</h3><h3 id="Faster-R-CNN-advantages"><a href="#Faster-R-CNN-advantages" class="headerlink" title="Faster R-CNN advantages"></a>Faster R-CNN advantages</h3><p><a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="noopener">github source</a></p>
<ol>
<li>Higher detection quality (mAP) than R-CNN, SPPnet</li>
<li>Training is single-stage, using a multi-task loss</li>
<li>Training can update all network layers</li>
<li>No disk storage is required for feature caching</li>
</ol>
<h3 id="Faster-R-CNN-architecture"><a href="#Faster-R-CNN-architecture" class="headerlink" title="Faster R-CNN architecture"></a>Faster R-CNN architecture</h3><p>A Fast R-CNN network takes as input an entire image and a set of object proposals. The network first processes the whole image with several convolutional (conv) and max pooling layers to produce a conv feature map. Then, for each object proposal a region of interest (RoI) pooling layer extracts a fixed-length feature vector from the feature map. Each feature vector is fed into a sequence of fully connected (fc) layers that finally branch into two sibling output layers: one that produces softmax probability estimates over K object classes plus a catch-all “background” class and another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes refined bounding-box positions for one of the K classes</p>
<p>对于一个Faster R-CNN来说，输入为<strong>输入图片</strong>和<strong>相关区域（RoI）</strong>，输入图片通过一个CNN进行处理得到一个<strong>卷积特征图（conv feature map）</strong>，而RoI在这张feature map上找到对应的区域，每个相关区域可以被映射到一个固定长度的<strong>特征向量（feature vector）</strong>，这个feature vector会进入下一步的处理（一个fully connected layer），得到两个output：<br>1) softmax probability： K个object分类以及background class的可能性<br>2) per-class bounding box regression offsets： 对每个object class的bounding box位置预测（一个4维向量）</p>
<p>A Fast R-CNN network has two sibling output layers. The first outputs a discrete probability distribution (per RoI), p = (p<sub>0</sub>, . . . , p<sub>K</sub>), over K + 1 categories. As usual, p is computed by a softmax over the K+1 outputs of a fully connected layer. The second sibling layer outputs bounding-box regression offsets, t<sub>k</sub>(t<sup>k</sup><sub>x</sub>,t<sup>k</sup><sub>y</sub>,t<sup>k</sup><sub>w</sub>,t<sup>k</sup><sub>h</sub>) for each of the K object classes, indexed by k.t<sub>k</sub> specifies a scale-invariant translation and log-space height/width shift relative to an object proposal.</p>
<h2 id="Paper-R-CNN-Object-detection"><a href="#Paper-R-CNN-Object-detection" class="headerlink" title="Paper: R-CNN: Object detection"></a>Paper: R-CNN: Object detection</h2><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf?spm=5176.100239.blogcont55892.8.pm8zm1&amp;file=Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" target="_blank" rel="noopener">Click here for the orginal text</a><br><a href="https://blog.csdn.net/shenxiaolu1984/article/details/51066975" target="_blank" rel="noopener">CSDN Relative information</a></p>
<h3 id="INTRO-3"><a href="#INTRO-3" class="headerlink" title="INTRO"></a>INTRO</h3><p>TWO KEY INSIGHTS:</p>
<p>1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects<br>2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost.</p>
<p>Since in this thesis region proposals is combined with CNNs, this method is known as method R-CNN: Regions with CNN features. </p>
<p>TWO CHALLENGE AND THE CONTRIBUTIONS:</p>
<p>1) 速度: 经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上提取特征，进行判断。<br>2) 训练集(the labeled data is scarce and the amount currently available is insufficient for training a large CNN.): 经典的目标检测算法在区域中提取人工设定的特征（Haar，HOG）。本文则需要训练深度网络进行特征提取。可供使用的有两个数据库： <strong>一个较大的识别库（ImageNet ILSVC 2012）</strong>：标定每张图片中物体的类别。一千万图像，1000类。       <strong>一个较小的检测库（PASCAL VOC 2007）</strong>：标定每张图片中，物体的类别和位置。一万图像，20类。本文使用识别库进行预训练，而后用检测库调优参数。最后在检测库上评测。</p>
<p>Combine the object detection and image classification together</p>
<blockquote>
<p>Object detection is what is needed in EyePhone</p>
</blockquote>
<h3 id="Objection-Detection"><a href="#Objection-Detection" class="headerlink" title="Objection Detection"></a>Objection Detection</h3><p>Our object detection system consists of three modules. </p>
<blockquote>
<p>The first generates category-independent region proposals. These proposals define the set of candidate detections available to our detector. </p>
<p>The second module is a large convolutional neural network that extracts a fixed-length feature vector from each region. </p>
<p>The third module is a set of classspecific linear SVMs.</p>
</blockquote>
<p>使用Seletive Search找到region proposals，然后对于每一个region，把他转化成一个固定大小的CNN输入。</p>
<p>对于一个test sample，通过Selective Search得到约2000个region proposals，然后每一个region proposal通过forwad propagation通过一个CNN，在得到每一个region的score之后，我们基于贪心算法，当一个region和另一个region重合，并且那个新的region的score高于某一个threshold，那么选择那个新的region代替两个region。</p>
<h2 id="Paper-Selective-Search"><a href="#Paper-Selective-Search" class="headerlink" title="Paper: Selective Search"></a>Paper: Selective Search</h2><p><a href="https://koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="noopener">Click here for the orginal text</a><br><a href="https://github.com/CesareMJLi/selectivesearch" target="_blank" rel="noopener">Click here for the project</a></p>
<p>由于该篇文章和本工程的相关性，该篇论文的注释将会用中文进行。</p>
<p><strong>Selective search is a algorithm in object detection! (not recognition)</strong></p>
<h3 id="INTRO-分割与穷举"><a href="#INTRO-分割与穷举" class="headerlink" title="INTRO 分割与穷举"></a>INTRO 分割与穷举</h3><p>在图片的物体识别领域，我们发现很难用一种统一的方法对所有的图片进行分类，我们需要考虑纹理，颜色以及这个物体的真实属性（一个轮子是单独的么？还是说这个轮子属于一辆车？），虽然在一张图片中往往其中一个就可以给出一个分类或者探测，但是在宏观上我们需要将多个元素进行考虑，而且还有一个问题是，往往我们用分割的方法（a unique partitioning of the image through a generic algorithm, where there is one part for all object silhouettes in the image.）很难得到一个正确的结论，在很多图片中，它的结构是intrinsic iherachical的，比如一个桌子上有若干个杯子，杯子里放着乒乓球或者羽毛球，我们需要考虑的是一个hierachical的模型。</p>
<p>通常情况下，我们在考虑object recognition的时候往往需要先进行object detection，然而在这篇论文中使用了另一种思路的方法，<strong>to do localisation through the identification of an object</strong>，比如以下这个情景，<em>在一张图片中出现了一个穿西装上衣的人，模型可以识别在西装上面有一张脸，然而为了识别整体的人的概念，我们需要模型对于这个概念有了解（prior recognition）。</em></p>
<p>一个解决方案是穷举法（对于每一个box boundary，它可能包含人/自行车/航空母舰嘛？），显而易见这种方法几乎是computatianal impossible，在这篇文章中提出的selective search的方法结合了segmentation和exhausive search，通过Bottom up segmentation获取图片的结构和每个object的位置【生成对象位置】，通过exhausive search捕捉每一个可能的object的位置信息【捕捉可能的对象的位置】。</p>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><ul>
<li>Exhaustive Search</li>
</ul>
<p>As an object can be located at any position and scale in the image, it is natural to search everywhere [8, 16, 36]. However, the visual search space is huge, making an exhaustive search computationally expensive. This imposes constraints on the evaluation cost per location and/or the number of locations considered. Hence most of these <strong>sliding window techniques</strong> use a coarse search grid and fixed aspect ratios, using weak classifiers and economic image features such as HOG.</p>
<p>While still, HIGH COST! EVEN WITH SOME IMPROVEMENTS, A EXHAUSTIVE SEARCH MAY STILL VISIT OVER 100,000 WINDOWS PER IMAGE.</p>
<p>Instead of a blind exhaustive search or a branch and bound search, we propose selective search. We use the underlying image structure to generate object locations. In contrast to the discussed methods, this yields a completely class-independent set of locations and generating less locations, which means saving a lot of computer power.</p>
<ul>
<li>Segmentation</li>
</ul>
<p>In the previous segmentation research, there are some approaches by segmenting and recognizing objects in parts. They first generate a set of part hypotheses using a grouping method based on Arbelaez. Each part hypothesis is described by both appearance and shape features. Then, an object is recognized and carefully delineated by using its parts, achieving good results for shape recognition.</p>
<p>In their work, the segmentation is hierarchical and yields segments at all scales. However, they use a single grouping strategy whose power of discovering parts or objects is left unevaluated. In this work, we use multiple complementary strategies to deal with as many image conditions as possible.</p>
<h3 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h3><blockquote>
<p>the selective search should fulfill 3 considerations</p>
<p><strong>捕获全部scale上的Objects</strong>：因为一个object可能在一张图片上的任意scale出现，甚至有些objects可能会具有模糊的边界。【通过using a hierachical algorithm解决】</p>
<p><strong>多样化</strong>：不存在一种最好的策略将不同的region进行group。每个区域可能通过颜色，纹理等等形成一个object，所以与其采用一种在大部分情况下都行得通的单一的策略，我们想找到一系列策略来对应全部的情形。</p>
<p><strong>易于计算</strong></p>
</blockquote>
<ul>
<li>Selective Search by Hierarchical Grouping</li>
</ul>
<p>Bottom-up grouping is a popular approach to segmentation, hence we adapt it for selective search. This is a hierarchicalmethods, which means that we could naturally generate locations at all scales by continueing the grouping process until the whole image becomes a single region.</p>
<img src="/2018/05/02/Papers-EyePhone/1.png">
<p>Bottom-up grouping is a popular approach to segmentation, we use this to get the initial regions</p>
<p>输入为一张照片，首先通过the fast method of Felzenszwalb and Huttenlocher创建initial regions R，然后我们使用贪心算法迭代的将regions组合起来，具体的过程为首先，【<em>建立一个空集合S，首先对于每一对region pair，我们计算similarity，然后将他们的相似性放在集合S中</em>】，然后【<em>从S中取出最高的相似性的region pair，将两个融合成为新的region，并且移除与久的region有关的相似性并且计算新的region和它的周围的部分的相似性</em>】，重复第二个步直到S成为空集。</p>
<blockquote>
<p>在计算相似性的时候，我们必须保证新的r的特章必须可以通过原来的r计算得到而不需要回到pixel level重新计算。</p>
</blockquote>
<ul>
<li>Diversification Strategies</li>
</ul>
<p>Create <strong>a set of complementary strategies</strong> whose locations are combined afterwards. Some popular strategies are (1) by using a variety of colour spaces with different invariance properties, (2) by using different similarity measures s<sub>ij</sub>, and (3) by varying our starting regions.</p>
<blockquote>
<p>Complementary Colour Spaces</p>
<p>Complementary Similarity Measures(s<sub>colour</sub>,s<sub>texture</sub>,s<sub>size</sub>,s<sub>fill</sub>)</p>
<p>Complemenetart Starting Regions</p>
</blockquote>
<ul>
<li>Combining Locations</li>
</ul>
<h2 id="Felzenswalb-Algorithm-in-image-segmentation"><a href="#Felzenswalb-Algorithm-in-image-segmentation" class="headerlink" title="Felzenswalb Algorithm in image segmentation"></a>Felzenswalb Algorithm in image segmentation</h2><p><a href="http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf" target="_blank" rel="noopener">Click here for the original paper text</a><br><a href="https://blog.csdn.net/ttransposition/article/details/38024557" target="_blank" rel="noopener">Click here for the Chinese comments</a></p>
<p>本质上这种算法提供了图像分割的一种非AI的解决方法，对于图中的每一个像素进行考虑，设定超参数约束分割的granularity，然后得到一个分割后的图像，该算法的核心是图像中的颜色分布，所以就导致在其眼中分布是一块一块的，不能对一个对象进行有效的分割和识别。</p>
<h1 id="Another-idea-for-EyePhone"><a href="#Another-idea-for-EyePhone" class="headerlink" title="Another idea for EyePhone"></a>Another idea for EyePhone</h1><p>Maybe we could choose the result of selective search as the input for the detection of some certain objects like <strong>Bicycle/Stairs/Trees or other Vertical Cylindrical Objects/Horizontal Cylindrical Objects/Box/</strong></p>
<p>Here’s some further information about this modification. Now it could use selective search to output some potential areas for the object detection. We have two things to do:</p>
<blockquote>
<p><strong>Object detection:</strong> We have to detect the objects in the area, so we have two problems to solve here, first thing is that we are going to extract all the usefull information from the image. The SS method works quite well when we are trying to find the objects, and we could use BaiduCloud Recognition API to recognize the objects. </p>
<p><strong>Distance calculation:</strong> The problem left is that we are going to set a set of principles for the model, to calculate the distance of the objects between the user and the objects. In the beginning I put some efforts on help the model to get the idea of building the sense of objects and space. While this requires tons of calculations which is not possible for the individual developers. Hence we have to take the plan B and set the rules by hand (of course this rule could be learned by the model as well. It only depends on whether we have enough trainning sets)</p>
</blockquote>
]]></content>
      
        
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Machine Learning </tag>
            
            <tag> EyePhone </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning V Recurrent Neural Network & Other Methods]]></title>
      <url>/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/</url>
      <content type="html"><![CDATA[<h1 id="RNN"><a href="#RNN" class="headerlink" title="RNN"></a>RNN</h1><h2 id="Intro"><a href="#Intro" class="headerlink" title="Intro"></a>Intro</h2><p>循环神经网络(recurrent neural network)或 RNN (Rumelhart et al., 1986c) 是一类用于处理序列数据的神经网络。就像卷积网络是专门用于处理网格化数据 X (如一个图像)的神经网络，循环神经网络是专门用于处理序列 x(1),…,x(τ) 的神 经网络。正如卷积网络可以很容易地扩展到具有很大宽度和高度的图像，以及处理 大小可变的图像，循环网络可以扩展到更长的序列(比不基于序列的特化网络长得多)。大多数循环网络也能处理可变长度的序列。</p>
<h2 id="展开计算图"><a href="#展开计算图" class="headerlink" title="展开计算图"></a>展开计算图</h2><img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/1.png">
<p>当训练循环网络根据过去预测未来时，网络通常要学会使用 h(t) 作为过去序列 (直到 t)与任务相关方面的有损摘要。此摘要一般而言一定是有损的，因为其映射 任意长度的序列 (x(t), x(t−1), x(t−2), . . . , x(2), x(1)) 到一固定长度的向量 h(t)。根据不 同的训练准则，摘要可能选择性地精确保留过去序列的某些方面。例如，如果在统 计语言建模中使用的 RNN，通常给定前一个词预测下一个词，可能没有必要存储时 刻 t 前输入序列中的所有信息;而仅仅存储足够预测句子其余部分的信息。最苛刻 的情况是我们要求 h(t) 足够丰富，并能大致恢复输入序列。</p>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/2.png">
<h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><blockquote>
<p>通用设计模式</p>
<p>其中h表示激活函数，其中包含了输入的加权过程，o表示非标准化对数概率，y表示标准化输出</p>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/6.png">
<ol>
<li>每个时间步都有输出，并且隐藏单元之间有循环连接的循环网络</li>
</ol>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/3.png">
<ol>
<li>每个时间步都产生一个输出，只有当前时刻的输出到下个时刻的隐藏单元之间有循环连接的循环网络</li>
</ol>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/4.png">
<ol>
<li>隐藏单元之间存在循环连接，但读取整个序列后产生单个输出的循环网络</li>
</ol>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/5.png">
</blockquote>
<p>通常情况下设计模式1为最常用的设计模式。</p>
<h3 id="导师驱动过程和输出循环网络（设计模式2）"><a href="#导师驱动过程和输出循环网络（设计模式2）" class="headerlink" title="导师驱动过程和输出循环网络（设计模式2）"></a>导师驱动过程和输出循环网络（设计模式2）</h3><img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/7.png">
<p>这种方式使训练过程可以并行的进行，因为我们不需要每次都将上次的train得到的o输入到下一层，而是将正确的y输入，故很大程度的减小了梯度下降的难度。</p>
<h3 id="神经网络梯度计算"><a href="#神经网络梯度计算" class="headerlink" title="神经网络梯度计算"></a>神经网络梯度计算</h3><h2 id="双向RNN"><a href="#双向RNN" class="headerlink" title="双向RNN"></a>双向RNN</h2><img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/8.png">
<h2 id="基于编码-解码的序列到序列架构"><a href="#基于编码-解码的序列到序列架构" class="headerlink" title="基于编码-解码的序列到序列架构"></a>基于编码-解码的序列到序列架构</h2><p>我们经常将RNN的输入称为”上下文”。我们希望产生此上下文的表示C。这个上下文C可能是一个概括输入序列 X = (x(1) , . . . , x(n)) 的向量或者向量序列。</p>
<img src="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/9.png">
<h2 id="深度循环网络"><a href="#深度循环网络" class="headerlink" title="深度循环网络"></a>深度循环网络</h2><h2 id="递归神经网络"><a href="#递归神经网络" class="headerlink" title="递归神经网络"></a>递归神经网络</h2><h1 id="实践方法论"><a href="#实践方法论" class="headerlink" title="实践方法论"></a>实践方法论</h1><h2 id="性能度量"><a href="#性能度量" class="headerlink" title="性能度量"></a>性能度量</h2><h2 id="默认基准模型"><a href="#默认基准模型" class="headerlink" title="默认基准模型"></a>默认基准模型</h2><h2 id="更多数据？"><a href="#更多数据？" class="headerlink" title="更多数据？"></a>更多数据？</h2><h2 id="超参数选择"><a href="#超参数选择" class="headerlink" title="超参数选择"></a>超参数选择</h2><h1 id="相关应用"><a href="#相关应用" class="headerlink" title="相关应用"></a>相关应用</h1>]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Recurrent Neural Network </tag>
            
            <tag> RNN </tag>
            
            <tag> Machine Learning Methods </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning IV Optimization & CNN]]></title>
      <url>/2018/04/19/Deep-Learning-IV-Optimization-CNN/</url>
      <content type="html"><![CDATA[<h1 id="Optimization"><a href="#Optimization" class="headerlink" title="Optimization"></a>Optimization</h1><p>本章主要关注这一类特定的优化问题:寻找神经网络上的一组参数θ，它能显著地降低代价函数J(θ)，该代价函数通常包括整个训练集上的性能评估和额外的正则化项。</p>
<h2 id="学习和纯优化"><a href="#学习和纯优化" class="headerlink" title="学习和纯优化"></a>学习和纯优化</h2><img src="/2018/04/19/Deep-Learning-IV-Optimization-CNN/1.png">
<p>J<sup>*</sup>这个式子可以这样去理解，(x,y)是关于p<sub>data的分布，L表示Loss Function，计算模型f根据输入x和当前参数θ得到的输出y‘与真实y之前的差，这个式子整体上表示了当前model的loss在真实x～y分布下的期望。</sub></p>
<p>机器学习算法和一般优化算法不同的一点是，机器学习算法的目标函数通常可 以分解为训练样本上的求和。机器学习中的优化算法在计算参数的每一次更新时通 常仅使用整个代价函数中一部分项来估计代价函数的期望值。</p>
<img src="/2018/04/19/Deep-Learning-IV-Optimization-CNN/2.png">
<p>使用整个训练集的优化算法被称为 批量(batch)或 确定性(deterministic)梯 度算法，因为它们会在一个大批量中同时处理所有样本。这个术语可能有点令人困 惑，因为这个词 “批量’’ 也经常被用来描述小批量随机梯度下降算法中用到的小批 量样本。通常，术语 “批量梯度下降’’ 指使用全部训练集，而术语 “批量’’ 单独出现 时指一组样本。例如，我们普遍使用术语 “批量大小’’ 表示小批量的大小。</p>
<p>每次只使用单个样本的优化算法有时被称为 随机(stochastic)或者 在线(on- line)算法。术语 “在线’’ 通常是指从连续产生样本的数据流中抽取样本的情况，而 不是从一个固定大小的训练集中遍历多次采样的情况。</p>
<p>大多数用于深度学习的算法介于以上两者之间，使用一个以上，而又不是全部 的训练样本。传统上，这些会被称为 小批量(minibatch)或 小批量随机(minibatch stochastic)方法，现在通常将它们简单地称为 随机(stochastic)方法。</p>
<h2 id="优化的挑战"><a href="#优化的挑战" class="headerlink" title="优化的挑战"></a>优化的挑战</h2><blockquote>
<p>病态</p>
<p>局部最小值</p>
<p>鞍点</p>
<p>悬崖和梯度爆炸</p>
<p>长期依赖</p>
</blockquote>
<h2 id="随机梯度下降方法"><a href="#随机梯度下降方法" class="headerlink" title="随机梯度下降方法"></a>随机梯度下降方法</h2><pre><code>Require: 学习率 ε&lt;sub&gt;k&lt;/sub&gt;
Require: 初始参数 θ
    while 停止准则未满足 do
        从训练集中采包含 m 个样本 {x(1),...,x(m)} 的小批量，其中 x(i) 对应目标为y(i)。
        计算梯度估计:gˆ ← + 1/m ∇&lt;sub&gt;θ&lt;/sub&gt; ∑ L(f(x(i); θ), y(i))
        应用更新:θ ← θ − εgˆ
    end while
</code></pre><p>SGD 算法中的一个关键参数是学习率。之前，我们介绍的 SGD 使用固定的学 习率。在实践中，有必要随着时间的推移逐渐降低学习率，因此我们将第k步迭代 的学习率记作 ε<sub>k</sub>。</p>
<h2 id="动量方法"><a href="#动量方法" class="headerlink" title="动量方法"></a>动量方法</h2><p>从形式上看，动量算法引入了变量 v 充当速度角色——它代表参数在参数空间 移动的方向和速率。速度被设为负梯度的指数衰减平均。名称 动量(momentum) 来自物理类比，根据牛顿运动定律，负梯度是移动参数空间中粒子的力。动量在物 理学上定义为质量乘以速度。在动量学习算法中，我们假设是单位质量，因此速度 向量 v 也可以看作是粒子的动量。超参数α ∈ [0, 1)决定了之前梯度的贡献衰减得有多快。更新规则如下:</p>
<img src="/2018/04/19/Deep-Learning-IV-Optimization-CNN/3.png">
<p>之前，步长只是梯度范数乘以学习率。现在，步长取决于梯度序列的大小和排 列。当许多连续的梯度指向相同的方向时，步长最大。如果动量算法总是观测到梯 度 g，那么它会在方向 −g 上不停加速，直到达到最终速度。</p>
<h2 id="Nesterov动量"><a href="#Nesterov动量" class="headerlink" title="Nesterov动量"></a>Nesterov动量</h2><h2 id="参数初始化策略"><a href="#参数初始化策略" class="headerlink" title="参数初始化策略"></a>参数初始化策略</h2><h2 id="自适应学习率算法"><a href="#自适应学习率算法" class="headerlink" title="自适应学习率算法"></a>自适应学习率算法</h2><h1 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h1>]]></content>
      
        
        <tags>
            
            <tag> CNN </tag>
            
            <tag> Deep Learning </tag>
            
            <tag> Optimization </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning III Deep Feedforward Network & Regularization]]></title>
      <url>/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/</url>
      <content type="html"><![CDATA[<h1 id="深度前馈网络-Deep-Feedforward-Network"><a href="#深度前馈网络-Deep-Feedforward-Network" class="headerlink" title="深度前馈网络 Deep Feedforward Network"></a>深度前馈网络 Deep Feedforward Network</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p><strong>深度前馈网络(deep feedforward network)</strong>,也叫作 前馈神经网络(feedforward neural network)或者 多层感知机(multilayer perceptron, MLP),是典型的深度学习模型。前馈网络的目标是近似某个函数 f<sup>∗</sup>。例如,对于分类器y=f<sup>∗</sup>(x) 将输入 x 映射到一个类别 y。</p>
<p>前馈网络定义了一个映射 y = f(x;θ),并且学习参数 θ 的值,使它能够得到最佳的函数近似。</p>
<p>这种模型被称为 前向(feedforward)的,是因为信息流过 x 的函数,流经用于定义 f 的中间计算过程,最终到达输出 y。在模型的输出和模型本身之间没有 反馈(feedback)连接。当前馈神经网络被扩展成包含反馈连接时,它们被称为 循环神经网络(recurrent neural network),在第十章介绍。</p>
<blockquote>
<p>Example</p>
<p>f(x)=f3(f2(f1(x)))</p>
</blockquote>
<p>这个名字。前馈网络的最后一层被称为<strong>输出层(output layer)</strong>。在神经网络训练的过程中,我们让 f(x) 去匹配 f<sup>∗</sup>(x)的值(也就是真实函数的值)。训练数据为我们提供了在不同训练点上取值的、含有噪声的f<sup>∗</sup>(x) 的近似实例。每个样本 x 都伴随着一个标签 y ≈ f<sup>∗</sup>(x)。</p>
<p>训练样本直接指明了输出层在每一点 x 上必须做什么;它必须产生一个接近 y 的值。但是训练数据并没有直接指明其他层应该怎么做。学习算法必须决定如何使用这些层来产生想要的输出,但是训练数据并没有说每个单独的层应该做什么。相反,学习算法必须决定如何使用这些层来最好地实现f<sup>∗</sup> 的近似。因为训练数据并没有给出这些层中的每一层所需的输出,所以这些层被称为<strong>隐藏层(hidden layer)</strong>。</p>
<p>为了扩展线性模型来表示 x 的非线性函数,我们可以不把线性模型用于 x 本身,而是用在一个变换后的输入φ(x) 上,这里 φ 是一个非线性变换。同样,我们可以使用核技巧,来得到一个基于隐含地使用 φ 映射的非线性学习算法。我们可以认为 φ 提供了一组描述 x 的特征,或者认为它提供了 x 的一个新的表示。</p>
<p>那么如何定义φ？深度学习的策略是去学习φ。在这种方法中,我们有一个模型 y = f(x; θ, w)=φ(x; θ)<sup>⊤</sup>w。我们现在有两种参数:用于从一大类函数中学习φ的参数 θ,以及用于将 φ(x) 映射到所需的输出的参数w</p>
<blockquote>
<p>  注意！φ不是参数</p>
</blockquote>
<h2 id="XOR"><a href="#XOR" class="headerlink" title="XOR"></a>XOR</h2><h2 id="基于梯度学习"><a href="#基于梯度学习" class="headerlink" title="基于梯度学习"></a>基于梯度学习</h2><p>我们到目前为止看到的线性模型和神经网络的最大区别,在于神经网络的非线性导致大多数我们感兴趣的代价函数都变得非凸（在多项式函数中的每一个函数都是凸的，如x^2,x^3,…）。这将会导致我们通过迭代的基于梯度的优化只能让代价函数达到一个很小的值而不一定是最小值，而训练算法也依然是基于梯度来使函数下降。</p>
<h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>在大多数情况下,我们的参数模型定义了一个分布p(y|x;θ)并且我们简单地使用最大似然原理。这意味着我们使用训练数据和模型预测间的交叉熵作为代价函数。</p>
<blockquote>
<p>使用最大似然学习条件分布</p>
</blockquote>
<h3 id="输出单元"><a href="#输出单元" class="headerlink" title="输出单元"></a>输出单元</h3><blockquote>
<p>sigmoid function</p>
<p>softmax function</p>
</blockquote>
<h2 id="隐藏单元"><a href="#隐藏单元" class="headerlink" title="隐藏单元"></a>隐藏单元</h2><p>大多数的隐藏单元都可以描述为接受输入向量x，计算仿射变换 z=W<sup>⊤</sup>x+b，然后使用一个逐元素的非线性函数g(z)。大多数隐藏单元的区别 仅仅在于激活函数g(z)的形式</p>
<blockquote>
<p>整流线型单元 g(z)=max{0,z}</p>
<p>logistic sigmoid function/双曲正切激活函数</p>
<p>其他隐藏单元</p>
</blockquote>
<h2 id="架构设计"><a href="#架构设计" class="headerlink" title="架构设计"></a>架构设计</h2><h2 id="万能近似性质"><a href="#万能近似性质" class="headerlink" title="万能近似性质"></a>万能近似性质</h2><p>乍一看，我们可能认为学习非线性函数需要为我们想要学习的那种非线性专 门设计一类模型族。幸运的是，具有隐藏层的前馈网络提供了一种万能近似框架。 具体来说， 万能近似定理(universal approximation theorem)(Hornik et al., 1989; Cybenko, 1989) 表明，一个前馈神经网络如果具有线性输出层和至少一层具有任何 一种 ‘‘挤压’’ 性质的激活函数(例如logistic sigmoid激活函数)的隐藏层，只要给予 网络足够数量的隐藏单元，它可以以任意的精度来近似任何从一个有限维空间到另 一个有限维空间的 Borel 可测函数。</p>
<p>万能近似定理意味着无论我们试图学习什么函数，我们知道一个大的MLP一定能够表示这个函数。然而，我们不能保证训练算法能够学得这个函数。即使MLP能够表示该函数，学习也可能因两个不同的原因而失败。<strong>首先，用于训练的优化算法可能找不到用于期望函数的参数值。其次，训练算法可能由于过拟合而选择了错误的函数</strong>。</p>
<p>具有单层的前馈网络足以表示任何函数，但是网络层可能大得不可实现， 并且可能无法正确地学习和泛化。在很多情况下，使用更深的模型能够减少表示期望函数所需的单元的数量，并且可以减少泛化误差。</p>
<h2 id="反向传播和其他微分算法"><a href="#反向传播和其他微分算法" class="headerlink" title="反向传播和其他微分算法"></a>反向传播和其他微分算法</h2><p><a href="https://www.cnblogs.com/charlotte77/p/5629865.html" target="_blank" rel="noopener">相关链接</a></p>
<h1 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h1><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>机器学习中的一个核心问题是设计不仅在训练数据上表现好，并且能在新输入 上泛化好的算法。在机器学习中，许多策略显式地被设计来减少测试误差(可能会 以增大训练误差为代价)。这些策略被统称为正则化。我们将在后文看到，深度学 习工作者可以使用许多不同形式的正则化策略。事实上，开发更有效的正则化策略 已成为本领域的主要研究工作之一。</p>
<p>将正则化定义为 ‘‘对学习算法的修改——旨在减少泛化误 差而不是训练误差’’。目前有许多正则化策略。有些策略向机器学习模型添加限制参 数值的额外约束。有些策略向目标函数增加额外项来对参数值进行软约束。如果我 们细心选择，这些额外的约束和惩罚可以改善模型在测试集上的表现。有时侯，这些 约束和惩罚被设计为编码特定类型的先验知识;其他时候，这些约束和惩罚被设计 为偏好简单模型，以便提高泛化能力。有时，惩罚和约束对于确定欠定的问题是必 要的。其他形式的正则化，如被称为集成的方法，则结合多个假说来解释训练数据。</p>
<p>通常情况下，面对一组数据和对应的训练，我们往往需要面对模型的三种情况</p>
<blockquote>
<ol>
<li><p>没有概括真实的数据生成过程–欠拟合/过大的bias</p>
</li>
<li><p>匹配真实的数据生成过程–完美！</p>
</li>
<li><p>除了包含了数据的生成过程，还包含了许多其他的生成过程–Variance主导的过拟合</p>
</li>
</ol>
</blockquote>
<p>正则化的目标是使模型从情况3转化为情况2</p>
<h2 id="参数范数惩罚"><a href="#参数范数惩罚" class="headerlink" title="参数范数惩罚"></a>参数范数惩罚</h2><img src="/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/1.png">
<p>注意，在神经网络中，参数包括每一层仿射变换的权重和偏置，然而我们通常只对权重做惩罚。</p>
<ul>
<li><p>L<sup>2</sup>参数正则化，添加一个正则项Ω(θ)=1/2||w||<sup>2</sup><sub>2，又被成为岭回归（Ridge Regression）</sub></p>
</li>
<li><p>L<sup>1</sup>参数正则化，添加一个正则项Ω(θ)=||w||<sub>1</sub>，即各个参数的绝对值之和，这个方法又被成为Lasso Regression。L<sup>1</sup>参数正则化往往可以产生更加稀疏的解法。</p>
</li>
</ul>
<p>在第 5.6.1 节，我们看到许多正则化策略可以被解释为 MAP 贝叶斯推断，特别<br>是 L2正则化相当于权重是高斯先验的 MAP 贝叶斯推断。对于 L1正则化，用于正则<br>化代价函数的惩罚项 αΩ(w) = α∑ |wi| 与通过 MAP 贝叶斯推断最大化的对数先 i<br>验项是等价的(w∈Rn 并且权重先验是各向同性的拉普拉斯分布(式(3.26)))</p>
<h2 id="作为约束的范数惩罚"><a href="#作为约束的范数惩罚" class="headerlink" title="作为约束的范数惩罚"></a>作为约束的范数惩罚</h2><h2 id="正则化和欠约束问题"><a href="#正则化和欠约束问题" class="headerlink" title="正则化和欠约束问题"></a>正则化和欠约束问题</h2><p>当输入的数据相对与输入特征的维数较少时，我们需要使用该种方法。</p>
<h2 id="数据集增强"><a href="#数据集增强" class="headerlink" title="数据集增强"></a>数据集增强</h2><p>让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练。当然，在 实践中，我们拥有的数据量是很有限的。解决这个问题的一种方法是创建假数据并 添加到训练集中。对于一些机器学习任务，创建新的假数据相当简单。</p>
<p>比如，在<a href="https://www.kaggle.com/cesareli/introduction-to-cnn-keras-0-997-top-6" target="_blank" rel="noopener">CNN识别数字</a>的过程中，我们采用了一种方法，对于每一个样本，我们可以考虑将其少量的平移或者旋转，来增强整个系统的泛化性。</p>
<p>在神经网络的输入层注入噪声 (Sietsma and Dow, 1991) 也可以被看作是数据增 强的一种方式。对于许多分类甚至一些回归任务而言，即使小的随机噪声被加到输 入，任务仍应该是能够被解决的。然而，神经网络被证明对噪声不是非常健壮 (Tang and Eliasmith, 2010)。改善神经网络健壮性的方法之一是简单地将随机噪声添加到 输入再进行训练。输入噪声注入是一些无监督学习算法的一部分，如去噪自编码 器(Vincent et al., 2008a)。向隐藏单元施加噪声也是可行的，这可以被看作在多个抽 象层上进行的数据集增强。</p>
<h2 id="噪声鲁棒性"><a href="#噪声鲁棒性" class="headerlink" title="噪声鲁棒性"></a>噪声鲁棒性</h2><p>对于某些模型而言， 向输入添加方差极小的噪声等价于对权重施加范数惩罚 (Bishop, 1995a,b)。在一般情 况下，注入噪声远比简单地收缩参数强大，特别是噪声被添加到隐藏单元时会更加强 大。向隐藏单元添加噪声是值得单独讨论重要的话题;在第 7.12 节所述 Dropout 算 法是这种做法的主要发展方向。</p>
<h2 id="半监督学习"><a href="#半监督学习" class="headerlink" title="半监督学习"></a>半监督学习</h2><p>在深度学习的背景下，半监督学习通常指的是学习一个表示 h = f(x)。学习表 示的目的是使相同类中的样本有类似的表示。无监督学习可以为如何在表示空间聚 集样本提供有用线索。在输入空间紧密聚集的样本应该被映射到类似的表示。在许 多情况下，新空间上的线性分类器可以达到较好的泛化 (Belkin and Niyogi, 2002; Chapelle et al., 2003)。这种方法的一个经典变种是使用主成分分析作为分类前(在 投影后的数据上分类)的预处理步骤。</p>
<h2 id="多任务学习"><a href="#多任务学习" class="headerlink" title="多任务学习"></a>多任务学习</h2><p>多任务学习 (Caruana, 1993) 是通过合并几个任务中的样例(可以视为对参数 施加的软约束)来提高泛化的一种方式。正如额外的训练样本能够将模型参数推向 具有更好泛化能力的值一样，当模型的一部分被多个额外的任务共享时，这部分将 被约束为良好的值(如果共享合理)，通常会带来更好的泛化能力。</p>
<p>这种方法将模型中的参数氛围两类</p>
<blockquote>
<ol>
<li><p>具体任务的参数-只能从各自任务的样本中实现比较好的泛化</p>
</li>
<li><p>所有任务共享的通用参数</p>
</li>
</ol>
</blockquote>
<h2 id="提前终止"><a href="#提前终止" class="headerlink" title="提前终止"></a>提前终止</h2><p>当训练有足够的表示能力甚至会过拟合的大模型时，我们经常观察到，训练误 差会随着时间的推移逐渐降低但验证集的误差会再次上升。图 7.3 是这些现象的一个 例子，这种现象几乎一定会出现。</p>
<p>这意味着我们只要返回使验证集误差最低的参数设置，就可以获得验证集误差 更低的模型(并且因此有希望获得更好的测试误差)。在每次验证集误差有所改善后，我们存储模型参数的副本。当训练算法终止时，我们返回这些参数而不是最新的参数。当验证集上的误差在事先指定的循环次数内没有进一步改善时，算法就会终止。</p>
<p>这种策略被称为 提前终止(early stopping)。这可能是深度学习中最常用的正 则化形式。它的流行主要是因为有效性和简单性。</p>
<p>然而这种方法也有两个缺点。</p>
<p>通过提前终止自动选择超参数的第一个显著的代价是 训练期间要定期评估验证集。在理想情况下，这可以并行在与主训练过程分离的机 器上，或独立的 CPU，或独立的 GPU 上完成。如果没有这些额外的资源，可以使用比训练集小的验证集或较不频繁地评估验证集来减小评估代价，较粗略地估算取得最佳的训练时间。</p>
<p>另一个提前终止的额外代价是需要保持最佳的参数副本。这种代价一般是可忽略的，因为可以将它储存在较慢较大的存储器上(例如，在 GPU 内存中训练，但将 最佳参数存储在主存储器或磁盘驱动器上)。由于最佳参数的写入很少发生而且从不在训练过程中读取，这些偶发的慢写入对总训练时间的影响不大。</p>
<p>提前终止需要验证集，这意味着某些训练数据不能被馈送到模型。为了更好地 利用这一额外的数据，我们可以在完成提前终止的首次训练之后，进行额外的训练。 在第二轮，即额外的训练步骤中，所有的训练数据都被包括在内。有两个基本的策略都可以用于第二轮训练过程（具体的策略请见深度学习书中的214页）。</p>
<h2 id="参数绑定和参数共享"><a href="#参数绑定和参数共享" class="headerlink" title="参数绑定和参数共享"></a>参数绑定和参数共享</h2><p>参数范数惩罚是正则化参数使其彼此接近的一种方式，而更流行的方法是使用 约束:强迫某些参数相等。由于我们将各种模型或模型组件解释为共享唯一的一组 参数，这种正则化方法通常被称为 参数共享(parameter sharing)。和正则化参数使 其接近(通过范数惩罚)相比，参数共享的一个显著优点是，只有参数(唯一一个集 合)的子集需要被存储在内存中。对于某些特定模型，如卷积神经网络，这可能可 以显著减少模型所占用的内存。</p>
<h2 id="系数表示"><a href="#系数表示" class="headerlink" title="系数表示"></a>系数表示</h2><p>前文所述的权重衰减直接惩罚模型参数。另一种策略是惩罚神经网络中的激活单元，稀疏化激活单元。这种策略间接地对模型参数施加了复杂惩罚。</p>
<img src="/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/2.png">
<h2 id="Bagging方法"><a href="#Bagging方法" class="headerlink" title="Bagging方法"></a>Bagging方法</h2><p>Bagging(bootstrap aggregating)是通过结合几个模型降低泛化误差的技术 (Breiman, 1994)。主要想法是分别训练几个不同的模型，然后让所有模型表决测 试样例的输出。这是机器学习中常规策略的一个例子，被称为<strong>模型平均(model averaging)</strong>。采用这种策略的技术被称为集成方法。</p>
<p>模型平均(model averaging)奏效的原因是不同的模型通常不会在测试集上产 生完全相同的误差。</p>
<img src="/2018/04/10/Deep-Learning-III-Deep-Feedforward-Network-Regularization/3.png">
<p>在误差完全相关即 c = v 的情况下，均方误差减少到 v，所以模型平均没有任何帮 助。在错误完全不相关即 c = 0 的情况下，该集成平方误差的期望仅为1/k*v。这意味着集成平方误差的期望会随着集成规模增大而线性减小。换言之，平均上，集成至少与它的任何成员表现得一样好，并且如果成员的误差是独立的，集成将显著地比其成员表现得更好。</p>
<p>具体来说，Bagging涉及构造 k 个不同的数据集。每个数据集从原始数据集中重复采样构成，和原始数据集具有相同数量的样例。这意味着，每个数据集以高概率 缺少一些来自原始数据集的例子，还包含若干重复的例子(如果所得训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 2/3 的实例)。模型 i 在数据集 i 上训练。每个数据集所含样本的差异导致了训练模型之间的差异。</p>
<p>神经网络能找到足够多的不同的解，意味着他们可以从模型平均中受益 (即使所 有模型都在同一数据集上训练)。神经网络中随机初始化的差异、小批量的随机选择、 超参数的差异或不同输出的非确定性实现往往足以使得集成中的不同成员具有部分独立的误差。</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><h2 id="对抗训练"><a href="#对抗训练" class="headerlink" title="对抗训练"></a>对抗训练</h2>]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Deep Feedforward Network </tag>
            
            <tag> Regularization </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[AlphaZero]]></title>
      <url>/2018/04/09/AlphaZero/</url>
      <content type="html"><![CDATA[<p>This is a reading notes based on the thesis <a href="https://www.nature.com/articles/nature24270.pdf" target="_blank" rel="noopener">Mastering the game of Go without human knowledge</a> and <a href="https://arxiv.org/pdf/1712.01815.pdf" target="_blank" rel="noopener">Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</a></p>
<h1 id="Mastering-the-game-of-Go-without-human-knowledge"><a href="#Mastering-the-game-of-Go-without-human-knowledge" class="headerlink" title="Mastering the game of Go without human knowledge"></a>Mastering the game of Go without human knowledge</h1><h2 id="AlphaGo-Fan-AlphaGo-Lee"><a href="#AlphaGo-Fan-AlphaGo-Lee" class="headerlink" title="AlphaGo Fan/AlphaGo Lee"></a>AlphaGo Fan/AlphaGo Lee</h2><p>AlphaGo was the first program to achieve superhuman performance in Go. The published version12, which we refer to as AlphaG Fan, defeated the European champion Fan Hui in October 2015. </p>
<p>AlphaGo Fan used two deep neural networks: a <strong>policy network</strong> that outputs move probabilities and a <strong>value network</strong> that outputs a position evaluation.</p>
<p>The policy network was trained initially by supervised learning to accurately predict human expert moves, and was subsequently refined by policy-gradient reinforcement learning. </p>
<p>The value network was trained to predict the winner of games played by the policy network against itself. </p>
<p>Once trained, these networks were combined with a Monte Carlo tree search (MCTS) to provide a lookahead search, using the policy network to narrow down the search to high-probability moves, and using the value network (in conjunction with Monte Carlo rollouts using a fast rollout policy) to evaluate positions in the tree.</p>
<p>A subsequent version, which we refer to as AlphaGo Lee, used a similar approach, and defeated Lee Sedol, the winner of 18 international titles, in March 2016.</p>
<h2 id="AlphaGo-Zero"><a href="#AlphaGo-Zero" class="headerlink" title="AlphaGo Zero"></a>AlphaGo Zero</h2><p>AlphaGo Zero, differs from AlphaGo Fan and AlphaGo Lee in several important aspects</p>
<blockquote>
<ol>
<li><p>It is trained solely by self-play reinforcement learning, starting from random play, without any supervision or use of human data.</p>
</li>
<li><p>It uses only the black and white stones from the board as input features.</p>
</li>
<li><p>Third, it uses a single neural network, rather than separate policy and value networks. </p>
</li>
<li><p>Finally, it uses a simpler tree search that relies upon<br>this single neural network to evaluate positions and sample moves,<br>without performing any Monte Carlo rollouts</p>
</li>
</ol>
</blockquote>
<h2 id="Reinforcement-learning-in-AlphaGo-Zero"><a href="#Reinforcement-learning-in-AlphaGo-Zero" class="headerlink" title="Reinforcement learning in AlphaGo Zero"></a>Reinforcement learning in AlphaGo Zero</h2><h3 id="Neural-Network"><a href="#Neural-Network" class="headerlink" title="Neural Network"></a>Neural Network</h3><p>f<sub>θ</sub>(s)=(p,v)</p>
<p>f<sub>θ</sub>: neural network with parameter θ</p>
<p>s: raw board representation, representing current game state</p>
<p>p: vector of move probabilities, represents the probability of selecting <strong>each move/action a</strong>, p<sub>a</sub>=Pr(a|s)</p>
<p>v: scalar evaluation, estimating the probability of current player winning from state s</p>
<blockquote>
<p>Combine the policy network and value network</p>
</blockquote>
<ul>
<li><p>Training:<br>  The neural network in AlphaGo Zero is trained from games of selfplay by a novel reinforcement learning algorithm. </p>
<p>  In each position s, an MCTS search is executed, guided by the neural network f<sub>θ</sub>. The MCTS search <strong>outputs probabilities π of playing each move</strong>.</p>
<blockquote>
<p>Here π is a vector! Stores the Probability for each action a.</p>
</blockquote>
<p>  These search probabilities usually select much stronger moves than the raw move probabilities p of the neural network fθ(s).</p>
<p>  MCTS may therefore be viewed as a powerful <strong>policy improvement operator</strong>. Self-play with search—using the improved MCTS-based policy to select each move, then using the <strong>game winner z</strong> as a sample of the value—may be viewed as a powerful <strong>policy evaluation operator</strong>. </p>
<p>  The main idea of our reinforcement learning algorithm is to use these search operators repeatedly in a policy iteration procedure: the neural network’s parameters are updated to make the move probabilities and value (p,v)= f<sub>θ</sub>(s) more closely match the improved search probabilities and selfplay winner (π, z); these new parameters are used in the next iteration of self-play to make the search even stronger.</p>
<blockquote>
<p>对于每一手（每一个当前状态），进行蒙特卡洛树搜索α<sub>θ</sub>，根节点为当前状态，蒙特卡洛树搜索是一种经验方法，可以根据之前的经验进行选择，我们在每个node s向下蔓延的edge a中选择，每个edge包含【prior probability P(s,a)/visit cound N(s,a)/ action value Q(s,a)】,<strong>在每一个node选择一个最大的（Q+U），当前选择的最大的Q+U不存在一个对应的node时，可以通过神经网络f<sub>θ</sub>生成他的子树（而不是使用Monte Carlo Rollout），产生对应的p和v，然后向root进行back propagate更新树的值（Q等）</strong>，并不断重复以上加粗字体过程，当搜索结束后，可以发挥一个search probabilities π，</p>
</blockquote>
<p>  At each time-step t, an MCTS search π = α<sub>θ of last step</sub>(s<sub>t</sub>) is executed using the previous iteration of neural network, and a move is played by sampling the search probabilities πt.</p>
<p>  A game terminates at step T when both players pass, when the search value drops below a resignation threshold or when the game exceeds a maximum length; the game is then scored to give a final reward of r<sub>T</sub>∈ {−1,+1}. </p>
<p>  The data for each time-step t is stored as (s<sub>t</sub>, π<sub>t</sub>, z<sub>t</sub>), where z<sub>t</sub>= ±r<sub>T</sub> is the game winner from the perspective of the current player at step t. </p>
<p>  In parallel, new network parameters θ<sub>i</sub> are trained from data (s, π, z) sampled uniformly among all time-steps of the last iteration(s) of self-play. The neural network f<sub>θ</sub> is adjusted to <strong>minimize the error between the predicted value v and the self-play winner z</strong>, and to <strong>maximize the similarity of the neural network move probabilities p to the search probabilities π</strong>.</p>
<blockquote>
<p>f<sub>θ</sub>(s)=(p,v)</p>
<p>loss function l = (z-v)<sup>2</sup> - π<sup>T</sup>logp + c||θ||<sup>2</sup></p>
</blockquote>
</li>
</ul>
<h2 id="Empirical-Analysis-of-AlphaGo-Zero-Training"><a href="#Empirical-Analysis-of-AlphaGo-Zero-Training" class="headerlink" title="Empirical Analysis of AlphaGo Zero Training"></a>Empirical Analysis of AlphaGo Zero Training</h2><p>Surprisingly, AlphaGo Zero outperformed AlphaGo Lee after just 36h. In comparison, AlphaGo Lee was trained over several months. </p>
<h2 id="Knowledge-learned-by-AlphaGo-Zero"><a href="#Knowledge-learned-by-AlphaGo-Zero" class="headerlink" title="Knowledge learned by AlphaGo Zero"></a>Knowledge learned by AlphaGo Zero</h2><p>AlphaGo Zero discovered a remarkable level of Go knowledge during its self-play training process. This included not only fundamental elements of human Go knowledge but also non-standard strategies beyond the scope of traditional Go knowledge.</p>
<h2 id="Final-performance-of-AlphaGo-Zero"><a href="#Final-performance-of-AlphaGo-Zero" class="headerlink" title="Final performance of AlphaGo Zero"></a>Final performance of AlphaGo Zero</h2><h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><h1 id="Mastering-Chess-and-Shogi-by-Self-Play-with-a-General-Reinforcement-Learning-Algorithm"><a href="#Mastering-Chess-and-Shogi-by-Self-Play-with-a-General-Reinforcement-Learning-Algorithm" class="headerlink" title="Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm"></a>Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm</h1><h2 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h2><p>The AlphaGo Zero program recently achieved superhuman performance in the game of Go, by tabula rasa reinforcement learning from games of self-play. In this paper, we generalise this approach into a single AlphaZero algorithm that can achieve, tabula rasa, superhuman performance in many challenging domains, starting from random play, and given no domain knowledge except the game rules.</p>
<p>The AlphaGo Zero algorithm achieved superhuman performance in the game of Go, by representing Go knowledge using <strong>deep convolutional neural networks</strong>, trained solely by reinforcement learning from games of self-play.</p>
<h2 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h2><p>Instead of a handcrafted evaluation function and move ordering heuristics, <strong>AlphaZero</strong> utilises a deep neural network (p, v) = f<sub>θ</sub>(s) with parameters θ. This neural network takes the board position s as an input and outputs a vector of move probabilities p with components p<sub>a</sub> = Pr(a|s) [the probability of each move a under the state s] for each action a, and a scalar value v estimating the expected outcome z from position s, v ≈ E[z|s]. AlphaZero learns these move probabilities and value estimates entirely from selfplay; these are then used to guide its search.</p>
<p>AlphaZero uses a generalpurpose Monte-Carlo tree search (MCTS) algorithm. Each search consists of a series of simulated games of self-play that traverse a tree from root s<sub>root</sub> to leaf. Each simulation proceeds by selecting in each state s a move a with low visit count, high move probability and high value<br>(<em>averaged over the leaf states of simulations that selected a from s</em>) according to the current neural network f<sub>θ</sub>. The search returns a vector π representing a probability distribution over moves, either proportionally or greedily with respect to the visit counts at the root state.</p>
<p>The parameters θ of the deep neural network in AlphaZero are trained by self-play reinforcement learning, starting from randomly initialised parameters θ. Games are played by selecting moves for both players by MCTS, a<sub>t</sub> ∼ π<sub>t</sub>. At the end of the game, the terminal position s<sub>T</sub> is scored according to the rules of the game to compute the game outcome z: −1 for a loss, 0 for a draw, and +1 for a win. The neural network parameters θ are updated so as to minimise the error between the predicted outcome v<sub>t</sub> and the game outcome z, and to maximise the similarity of the policy vector p<sub>t</sub><br>to the search probabilities π<sub>t</sub>. Specifically, the parameters θ are adjusted by gradient descent on a loss function l that sums over mean-squared error and cross-entropy losses respectively</p>
<blockquote>
<p>f<sub>θ</sub>(s)=(p,v)</p>
<p>loss function l = (z-v)<sup>2</sup> - π<sup>T</sup>logp + c||θ||<sup>2</sup></p>
</blockquote>
<p>where c is a parameter controlling the level of L2 weight regularisation. The updated parameters are used in subsequent games of self-play.</p>
<h2 id="Differences-between-AlphaZero-and-AlphaGo-Zero"><a href="#Differences-between-AlphaZero-and-AlphaGo-Zero" class="headerlink" title="Differences between AlphaZero and AlphaGo Zero"></a>Differences between AlphaZero and AlphaGo Zero</h2><ol>
<li><p>AlphaGo Zero estimates and optimises the probability of winning, assuming binary win/loss outcomes. AlphaZero instead estimates and optimises the expected outcome, taking account of draws or potentially other outcomes.</p>
</li>
<li><p>The rules of Go are invariant to rotation and reflection. This fact was exploited in AlphaGo and AlphaGo Zero in several ways.</p>
</li>
<li><p>In AlphaGo Zero, self-play games were generated by the best player from all previous iterations. After each iteration of training, the performance of the new player was measured against the best player; if it won by a margin of 55% then it replaced the best player and self-play games were subsequently generated by this new player. In contrast, AlphaZero simply maintains a single neural network that is updated continually, rather than waiting for an iteration to complete.</p>
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> AlphaGo </tag>
            
            <tag> Reinforcement Learning </tag>
            
            <tag> Artificial Neural Network </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning II Calculation & Basic Methods]]></title>
      <url>/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/</url>
      <content type="html"><![CDATA[<h1 id="Advanced-Mathematics"><a href="#Advanced-Mathematics" class="headerlink" title="Advanced Mathematics"></a>Advanced Mathematics</h1><h2 id="上溢"><a href="#上溢" class="headerlink" title="上溢"></a>上溢</h2><h2 id="下溢"><a href="#下溢" class="headerlink" title="下溢"></a>下溢</h2><h2 id="病态条件"><a href="#病态条件" class="headerlink" title="病态条件"></a>病态条件</h2><h2 id="基于梯度优化"><a href="#基于梯度优化" class="headerlink" title="基于梯度优化"></a>基于梯度优化</h2><h3 id="目标函数-代价函数-损失函数-误差函数"><a href="#目标函数-代价函数-损失函数-误差函数" class="headerlink" title="目标函数/代价函数/损失函数/误差函数"></a>目标函数/代价函数/损失函数/误差函数</h3><h3 id="局部极小点-局部极大点-全局最小点"><a href="#局部极小点-局部极大点-全局最小点" class="headerlink" title="局部极小点/局部极大点/全局最小点"></a>局部极小点/局部极大点/全局最小点</h3><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><h3 id="学习率"><a href="#学习率" class="headerlink" title="学习率"></a>学习率</h3><h3 id="Jacobian-Matrix-amp-Hessian-Matrix"><a href="#Jacobian-Matrix-amp-Hessian-Matrix" class="headerlink" title="Jacobian Matrix &amp; Hessian Matrix"></a>Jacobian Matrix &amp; Hessian Matrix</h3><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/1.jpg">
<h3 id="凸优化"><a href="#凸优化" class="headerlink" title="凸优化"></a>凸优化</h3><p>最成功的特定优化领域或许是 凸优化(Convex optimization)。凸优化通过更强 的限制提供更多的保证。凸优化算法只对凸函数适用，即 Hessian 处处半正定的函 数。因为这些函数没有鞍点而且其所有局部极小点必然是全局最小点，所以表现很 好。然而，深度学习中的大多数问题都难以表示成凸优化的形式。凸优化仅用作一 些深度学习算法的子程序。</p>
<p>凸函数:f(tx+(1-t)y)&lt;=tf(x)+(1-t)f(y)      0&lt;=t&lt;=1</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/2.png">
<h2 id="约束优化"><a href="#约束优化" class="headerlink" title="约束优化"></a>约束优化</h2><p>有时候，在 x 的所有可能值下最大化或最小化一个函数 f(x) 不是我们所希望 的。相反，我们可能希望在 x 的某些集合 S 中找 f(x) 的最大值或最小值。这被称 为 约束优化(constrained optimization)。</p>
<p>（注意，这里的x是一个广义上的未知量而不是我们之前在线性回归模型等方法中使用的Dataset的input，这里的x表示为w或者theta都更加合适）</p>
<h3 id="KKT方法"><a href="#KKT方法" class="headerlink" title="KKT方法"></a>KKT方法</h3><h1 id="Basic-Machine-Learning-Methods"><a href="#Basic-Machine-Learning-Methods" class="headerlink" title="Basic Machine Learning Methods"></a>Basic Machine Learning Methods</h1><h2 id="学习算法"><a href="#学习算法" class="headerlink" title="学习算法"></a>学习算法</h2><h3 id="任务T"><a href="#任务T" class="headerlink" title="任务T"></a>任务T</h3><p>机器学习任务定义为机器学习系统应该如何处理 样本(example)。样本是 指我们从某些希望机器学习系统处理的对象或事件中收集到的已经量化的 特征 (feature)的集合。</p>
<p>一些常见的机器学习任务列举：</p>
<blockquote>
<p>  分类/输入缺失分类/回归/转录/机器翻译/结构化输出/合成采样/缺失值填补/去噪/…</p>
</blockquote>
<h3 id="性能度量P"><a href="#性能度量P" class="headerlink" title="性能度量P"></a>性能度量P</h3><p>对于诸如分类、缺失输入分类和转录任务，我们通常度量模型的 准确率(accu- racy)。准确率是指该模型输出正确结果的样本比率。我们也可以通过 错误率(error rate)得到相同的信息。</p>
<p>通常，我们会更加关注机器学习算法在未观测数据上的性能如何，因为这将决 定其在实际应用中的性能。因此，我们使用 测试集(test set)数据来评估系统性能， 将其与训练机器学习系统的训练集数据分开。</p>
<h3 id="经验E"><a href="#经验E" class="headerlink" title="经验E"></a>经验E</h3><p>根据学习过程中的不同经验，机器学习算法可以大致分类为 无监督(unsuper- vised)算法和 监督(supervised)算法。</p>
<p>本书中的大部分学习算法可以被理解为在整个 数据集(dataset)上获取经验。 数据集是指很多样本组成的集合，如第 5.1.1 节所定义的。有时我们也将样本称为 数 据点(data point)。</p>
<p><strong>无监督学习算法(unsupervised learning algorithm)</strong>训练含有很多特征的数据 集，然后学习出这个数据集上有用的结构性质。在深度学习中，我们通常要学习生成数据集的整个概率分布，显式地，比如密度估计，或是隐式地，比如合成或去噪。 还有一些其他类型的无监督学习任务，例如聚类，将数据集分成相似样本的集合。</p>
<p><strong>监督学习算法(supervised learning algorithm)</strong>训练含有很多特征的数据集，不 过数据集中的样本都有一个 标签(label)或 目标(target)。</p>
<p>大致说来，无监督学习涉及到观察随机向量 x 的好几个样本，试图显式或隐式 地学习出概率分布 p(x)，或者是该分布一些有意思的性质;而监督学习包含观察随 机向量 x 及其相关联的值或向量 y，然后从 x 预测 y，通常是估计 p(y | x)。术语 监 督学习(supervised learning)源自这样一个视角，教员或者老师提供目标 y 给机器学习系统，指导其应该做什么。在无监督学习中，没有教员或者老师，算法必须学会在没有指导的情况下理解数据。</p>
<h3 id="数据表示"><a href="#数据表示" class="headerlink" title="数据表示"></a>数据表示</h3><p>大部分机器学习算法简单地训练于一个数据集上。数据集可以用很多不同方式 来表示。在所有的情况下，数据集都是样本的集合，而样本是特征的集合。</p>
<p>表示数据集的常用方法是 设计矩阵(design matrix)。设计矩阵的每一行包含 一个不同的样本。每一列对应不同的特征。</p>
<h2 id="容量"><a href="#容量" class="headerlink" title="容量"></a>容量</h2><p>机器学习的主要挑战是我们的算法必须能够在先前未观测的新输入上表现良好， 而不只是在训练集上表现良好。在先前未观测到的输入上表现良好的能力被称为 泛 化(generalization)。</p>
<p>通常情况下，当我们训练机器学习模型时，我们可以使用某个训练集，在训练 集上计算一些被称为 训练误差(training error)的度量误差，目标是降低训练误差。 目前为止，我们讨论的是一个简单的优化问题。机器学习和优化不同的地方在于，我 们也希望 泛化误差 (generalization error)(也被称为 测试误差(test error))很低。 泛化误差被定义为新输入的误差期望。这里，期望的计算基于不同的可能输入，这 些输入采自于系统在现实中遇到的分布。</p>
<p>训练集和测试集数据通过数据集上被称为 数据生成过程(data generating pro- cess)的概率分布生成。通常，我们会做一系列被统称为 独立同分布假设(i.i.d. assumption)的假设。该假设是说，每个数据集中的样本都是彼此 相互独立的(independent)，并且训练集和测试集是 同分布的(identically distributed)，采样自相 同的分布。这个假设使我们能够在单个样本的概率分布描述数据生成过程。然后相 同的分布可以用来生成每一个训练样本和每一个测试样本。我们将这个共享的潜在 分布称为 数据生成分布(data generating distribution)，记作 p<sub>data</sub>。这个概率框架 和独立同分布假设允许我们从数学上研究训练误差和测试误差之间的关系。</p>
<p>我们能观察到训练误差和测试误差之间的直接联系是，随机模型训练误差的期 望和该模型测试误差的期望是一样的。假设我们有概率分布 p(x, y)，从中重复采样 生成训练集和测试集。对于某个固定的 w，训练集误差的期望恰好和测试集误差的 期望一样，这是因为这两个期望的计算都使用了相同的数据集生成过程。这两种情 况的唯一区别是数据集的名字不同。</p>
<p>因此我们有两个因素来决定一个学习算法的好坏</p>
<blockquote>
<p>  降低训练误差-欠拟合（underfitting）</p>
<p>  缩小训练误差和测试误差的差距-过拟合（overfitting）</p>
</blockquote>
<p>通过调整模型的 容量(capacity)，我们可以控制模型是否偏向于过拟合或者欠 拟合。通俗地，模型的容量是指其拟合各种函数的能力。容量低的模型可能很难拟 合训练集。容量高的模型可能会过拟合，因为记住了不适用于测试集的训练集性质。</p>
<p>一种控制训练算法容量的方法是选择 假设空间(hypothesis space)，即学习算 法可以选择为解决方案的函数集。例如，线性回归算法将关于其输入的所有线性函 数作为假设空间。广义线性回归的假设空间包括多项式函数，而非仅有线性函数。这 样做就增加了模型的容量。</p>
<p>统计学习理论中最重要 的结论阐述了训练误差和泛化误差之间差异的上界随着模型容量增长而增长，但 随着训练样本增多而下降。</p>
<p>我们必须记住虽然更简单的函数更可能泛化(训练误差和测试误差的差距小)， 但我们仍然需要选择一个充分复杂的假设以达到低的训练误差。通常，当模型容量 上升时，训练误差会下降，直到其渐近最小可能误差(假设误差度量有最小值)。通 常，泛化误差是一个关于模型容量的 U 形曲线函数。</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/3.png">
<h3 id="Bayes-Error"><a href="#Bayes-Error" class="headerlink" title="Bayes Error"></a>Bayes Error</h3><p>理想模型假设我们能够预先知道生成数据的真实概率分布。然而这样的模型仍 然会在很多问题上发生一些错误，因为分布中仍然会有一些噪声。在监督学习中，从 x 到 y 的映射可能内在是随机的，或者 y 可能是其他变量(包括 x 在内)的确定性函数。从预先知道的真实分布 p(x, y) 预测而出现的误差被称为 贝叶斯误差(Bayes error)。</p>
<h3 id="No-Free-Lunch-Principle"><a href="#No-Free-Lunch-Principle" class="headerlink" title="No Free Lunch Principle"></a>No Free Lunch Principle</h3><h2 id="Linear-Regression"><a href="#Linear-Regression" class="headerlink" title="Linear Regression"></a>Linear Regression</h2><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/4.jpg">
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>至此，我们具体讨论修改学习算法的方法只有，通过增加或减少学习算法可选 假设空间的函数来增加或减少模型的表示容量。我们列举的一个具体示例是线性回 归增加或减少多项式的次数。目前为止讨论的观点都是过度简化的。</p>
<h3 id="权重衰减"><a href="#权重衰减" class="headerlink" title="权重衰减"></a>权重衰减</h3><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/5.png">
<p>在我们权重衰减的示例中，通过在最小化的目标中额外增加一项，我们明确地 表示了偏好权重较小的线性函数。有很多其他方法隐式或显式地表示对不同解的偏 好。总而言之，这些不同的方法都被称为 正则化(regularization)。<strong>正则化是指我们修改学习算法，使其降低泛化误差而非训练误差</strong>。正则化是机器学习领域的中心问 题之一，只有优化能够与其重要性相媲。</p>
<h2 id="超参数和验证集"><a href="#超参数和验证集" class="headerlink" title="超参数和验证集"></a>超参数和验证集</h2><p>大多数机器学习算法都有超参数，可以设置来控制算法行为。超参数的值不是 通过学习算法本身学习出来的，比如控制权重衰减成都的lamda以及控制容量的多项式最高次数。</p>
<p>有时一个选项被设为学习算法不用学习的超参数，是因为它太难优化了。更多 的情况是，该选项必须是超参数，因为它不适合在训练集上学习。这适用于控制模 型容量的所有超参数。如果在训练集上学习超参数，这些超参数总是趋向于最大可 能的模型容量，导致过拟合(参考图 5.3 )。例如，相比低次多项式和正的权重衰减 设定，更高次的多项式和权重衰减参数设定 λ = 0 总能在训练集上更好地拟合。</p>
<p>为了解决这个问题，我们需要一个训练算法观测不到的 验证集(validation set) 样本。它可以用来估计学 习过程完成之后的学习器的泛化误差。其重点在于测试样本不能以任何形式参与到 模型的选择中，包括设定超参数。基于这个原因，测试集中的样本不能用于验证集。 因此，我们总是从训练数据中构建验证集。特别地，我们将训练数据分成两个不相 交的子集。其中一个用于学习参数。另一个作为验证集，用于估计训练中或训练后 的泛化误差，更新超参数。</p>
<h3 id="Cross-Validation"><a href="#Cross-Validation" class="headerlink" title="Cross Validation"></a>Cross Validation</h3><h2 id="Bias-amp-Variance"><a href="#Bias-amp-Variance" class="headerlink" title="Bias &amp; Variance"></a>Bias &amp; Variance</h2><p>偏差和方差度量着估计量的两个不同误差来源。偏差度量着偏离真实函数或参数的误差期望。而方差度量着数据上任意特定采样可能导致的估计期望的偏差。</p>
<p>当我们可以在一个偏差更大的估计和一个方差更大的估计中进行选择时，会发 生什么呢?我们该如何选择?</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/6.png">
<p>偏差和方差的关系和机器学习容量、欠拟合和过拟合的概念紧密相联。用 MSE 度 量泛化误差(偏差和方差对于泛化误差都是有意义的)时，增加容量会增加方差，降低偏差。如图所示，我们再次在关于容量的函数中，看到泛化误差的 U 形曲线。</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/7.png">
<h2 id="Maximum-Likelihood"><a href="#Maximum-Likelihood" class="headerlink" title="Maximum Likelihood"></a>Maximum Likelihood</h2><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/8.png">
<p>一种解释最大似然估计的观点是将它看作最小化训练集上的经验分布 pˆ<sub>data</sub> 和模型分布之间的差异.</p>
<h2 id="Bayes-Method"><a href="#Bayes-Method" class="headerlink" title="Bayes Method"></a>Bayes Method</h2><p>当训练数据很有限时，贝叶斯方法通常泛化得更好，但是当训练样本数目很大 时，通常会有很大的计算代价。</p>
<h2 id="最大后验估计-MAP"><a href="#最大后验估计-MAP" class="headerlink" title="最大后验估计 MAP"></a>最大后验估计 MAP</h2><h2 id="Supervised-Learning"><a href="#Supervised-Learning" class="headerlink" title="Supervised Learning"></a>Supervised Learning</h2><h3 id="Linear-Regression-1"><a href="#Linear-Regression-1" class="headerlink" title="Linear Regression"></a>Linear Regression</h3><h3 id="Logistic-Regression"><a href="#Logistic-Regression" class="headerlink" title="Logistic Regression"></a>Logistic Regression</h3><h3 id="Support-Vector-Machine-不输出概率-只输出类别"><a href="#Support-Vector-Machine-不输出概率-只输出类别" class="headerlink" title="Support Vector Machine:不输出概率 只输出类别"></a>Support Vector Machine:不输出概率 只输出类别</h3><blockquote>
<p>Kernal Method</p>
</blockquote>
<h3 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h3><h2 id="Unsupervised-Learning"><a href="#Unsupervised-Learning" class="headerlink" title="Unsupervised Learning"></a>Unsupervised Learning</h2><p>一个经典的无监督学习任务是找到数据的 ‘‘最佳’’ 表示。‘‘最佳’’ 可以是不同的 表示，但是一般来说，是指该表示在比本身表示的信息更简单或更易访问而受到一 些惩罚或限制的情况下，尽可能地保存关于 x 更多的信息。</p>
<p>有很多方式定义较简单的表示。最常见的三种包括低维表示、稀疏表示和独立 表示。低维表示尝试将 x 中的信息尽可能压缩在一个较小的表示中。稀疏表示将数 据集嵌入到输入项大多数为零的表示中 (Barlow, 1989; Olshausen and Field, 1996; Hinton and Ghahramani, 1997)。稀疏表示通常用于需要增加表示维数的情况，使得 大部分为零的表示不会丢失很多信息。这会使得表示的整体结构倾向于将数据分布 在表示空间的坐标轴上。独立表示试图分开数据分布中变化的来源，使得表示的维 度是统计独立的。</p>
<h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p> PCA 学习一种比原始输入维数更低的表示。</p>
 <img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/9.png">
<h3 id="K均值聚类：-K-Clustering"><a href="#K均值聚类：-K-Clustering" class="headerlink" title="K均值聚类： K Clustering"></a>K均值聚类： K Clustering</h3><h2 id="随机梯度下降-Stochastic-Gradient-Descent-SGD"><a href="#随机梯度下降-Stochastic-Gradient-Descent-SGD" class="headerlink" title="随机梯度下降 Stochastic Gradient Descent, SGD"></a>随机梯度下降 Stochastic Gradient Descent, SGD</h2><p>机器学习中反复出现的一个问题是好的泛化需要大的训练集，但大的训练集的 计算代价也更大。</p>
<img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/10.png">
<h2 id="Build-a-Machine-Learning-Algorithm"><a href="#Build-a-Machine-Learning-Algorithm" class="headerlink" title="Build a Machine Learning Algorithm"></a>Build a Machine Learning Algorithm</h2><img src="/2018/04/07/Deep-Learning-II-Calculation-Basic-Methods/11.png">
<h2 id="Dimension-Disaster"><a href="#Dimension-Disaster" class="headerlink" title="Dimension Disaster"></a>Dimension Disaster</h2>]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Advanced Mathematics </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Deep Learning I Introduction, Probability, Algebra & Symbols]]></title>
      <url>/2018/04/07/Deep-Learning-I-Introduction-Symbols/</url>
      <content type="html"><![CDATA[<h1 id="Mathematical-Symbols"><a href="#Mathematical-Symbols" class="headerlink" title="Mathematical Symbols"></a>Mathematical Symbols</h1><h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/1.png">
<p>许多人工智能任务都可以通过以下方式解决:先提取一个合适的特征集，然后将这些特征提供给简单的机器学习算法。例如，对于通过声音鉴别说话者的任务来 说，一个有用的特征是对其声道大小的估计。这个特征为判断说话者是男性、女性还是儿童提供了有力线索</p>
<p>然而，对于许多任务来说，我们很难知道应该提取哪些特征。例如，假设我们想 写一个程序来检测照片中的车。我们知道，汽车有轮子，所以我们可能会想用车轮的存在与否作为特征。</p>
<p>解决这个问题的途径之一是使用机器学习来发掘表示本身，而不仅仅把表示映射到输出。这种方法我们称之为表示学习(representation learning)。学习到的表示往往比手动设计的表示表现得更好。并且它们只需最少的人工干预，就能让AI系统迅速适应新的任务。</p>
<p>从原始数据中提取如此高层次、抽象的特征是非常困难的。许多诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难，因此，乍一看，表示学习似乎并不能帮助我们。</p>
<p>深度学习(deep learning)通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。深度学习让计算机通过较简单概念构建复杂的概念。</p>
<p>深度学习的另一个最大的成就是其在 强化学习(reinforcement learning)领域 的扩展。在强化学习中，一个自主的智能体必须在没有人类操作者指导的情况下，通 过试错来学习执行任务。DeepMind 表明，基于深度学习的强化学习系统能够学会玩 Atari 视频游戏，并在多种任务中可与人类匹敌 (Mnih et al., 2015)。深度学习也显 著改善了机器人强化学习的性能 (Finn et al., 2015)。</p>
<h1 id="Linear-Algebra"><a href="#Linear-Algebra" class="headerlink" title="Linear Algebra"></a>Linear Algebra</h1><h2 id="标量Scalar：一个数"><a href="#标量Scalar：一个数" class="headerlink" title="标量Scalar：一个数"></a>标量Scalar：一个数</h2><h2 id="向量Vector：一列数"><a href="#向量Vector：一列数" class="headerlink" title="向量Vector：一列数"></a>向量Vector：一列数</h2><h2 id="矩阵Matrix：二维数组"><a href="#矩阵Matrix：二维数组" class="headerlink" title="矩阵Matrix：二维数组"></a>矩阵Matrix：二维数组</h2><p>A<sub>m,n</sub>表示一个高度m宽度n的数组，A<sub>i,:</sub> 和A<sub>:,j</sub>分别表示row i和column j。</p>
<h2 id="张量Tensor：超过两维的数组，如Ax-y-z"><a href="#张量Tensor：超过两维的数组，如Ax-y-z" class="headerlink" title="张量Tensor：超过两维的数组，如Ax,y,z"></a>张量Tensor：超过两维的数组，如A<sub>x,y,z</sub></h2><h2 id="转置Transpose-xT"><a href="#转置Transpose-xT" class="headerlink" title="转置Transpose: xT"></a>转置Transpose: x<sup>T</sup></h2><p>对于一个任意形状的矩阵都是可转置的。</p>
<h2 id="矩阵和向量相乘："><a href="#矩阵和向量相乘：" class="headerlink" title="矩阵和向量相乘："></a>矩阵和向量相乘：</h2><p>C=AB,A的#column等于B的#row。</p>
<h2 id="单位矩阵：In-n-n"><a href="#单位矩阵：In-n-n" class="headerlink" title="单位矩阵：In(n*n)"></a>单位矩阵：I<sub>n</sub>(n*n)</h2><p>任意向量和单位矩阵相乘都不会改变。</p>
<h2 id="逆矩阵：A-1"><a href="#逆矩阵：A-1" class="headerlink" title="逆矩阵：A-1"></a>逆矩阵：A<sup>-1</sup></h2><p>A<sup>-1</sup>A=I<sub>n</sub></p>
<h2 id="可逆矩阵"><a href="#可逆矩阵" class="headerlink" title="可逆矩阵"></a>可逆矩阵</h2><p>一个可逆矩阵必须是一个方阵，即m=n，且所有的列向量都是线性无关的。一个列向量线性相关的矩阵为<strong>奇异矩阵（singular）</strong>。</p>
<h2 id="范数"><a href="#范数" class="headerlink" title="范数"></a>范数</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/2.png">
<p>用于衡量一个向量的大小，p belongs to R and p &gt;=1。</p>
<p>p=2:欧几里得范数</p>
<p>p=1:Lasso Regularzation</p>
<h2 id="对角矩阵：diagonal-matrix"><a href="#对角矩阵：diagonal-matrix" class="headerlink" title="对角矩阵：diagonal matrix"></a>对角矩阵：diagonal matrix</h2><h2 id="对称矩阵：AT-A"><a href="#对称矩阵：AT-A" class="headerlink" title="对称矩阵：AT=A"></a>对称矩阵：A<sup>T</sup>=A</h2><h2 id="单位向量-x-2-1"><a href="#单位向量-x-2-1" class="headerlink" title="单位向量: ||x||2=1"></a>单位向量: ||x||<sub>2</sub>=1</h2><h2 id="正交矩阵：orthogonal-matrix-AT-A-1"><a href="#正交矩阵：orthogonal-matrix-AT-A-1" class="headerlink" title="正交矩阵：orthogonal matrix AT=A-1"></a>正交矩阵：orthogonal matrix A<sup>T</sup>=A<sup>-1</sup></h2><h2 id="特征分解"><a href="#特征分解" class="headerlink" title="特征分解"></a>特征分解</h2><p>特征向量，指与矩阵 A 相乘后相当于对该向量进行缩放的非零向量 v</p>
<p>Av=lv</p>
<p>（l为特征值）</p>
<p>所有特征值都是正数的矩阵被称为 正定(positive definite);所有特征值都是非 负数的矩阵被称为 半正定(positive semidefinite)。同样地，所有特征值都是负数的 矩阵被称为 负定(negative definite);所有特征值都是非正数的矩阵被称为 半负定(negative semidefinite)。</p>
<h2 id="奇异值分解"><a href="#奇异值分解" class="headerlink" title="奇异值分解"></a>奇异值分解</h2><p>A=UDV<sup>T</sup></p>
<h2 id="Moore-Penrose伪逆A"><a href="#Moore-Penrose伪逆A" class="headerlink" title="Moore-Penrose伪逆A+"></a>Moore-Penrose伪逆A<sup>+</sup></h2><p>对于非方阵而言，其逆矩阵没有定义。</p>
<p>A<sup>+</sup>=VD<sup>+</sup>U<sup>T</sup></p>
<h2 id="迹Tr-A-Sum-Ai-i"><a href="#迹Tr-A-Sum-Ai-i" class="headerlink" title="迹Tr(A)=Sum Ai,i"></a>迹Tr(A)=Sum A<sub>i,i</sub></h2><h2 id="行列式：det-A"><a href="#行列式：det-A" class="headerlink" title="行列式：det(A)"></a>行列式：det(A)</h2><p>将方阵A映射到实数的函数</p>
<h1 id="Probability"><a href="#Probability" class="headerlink" title="Probability"></a>Probability</h1><h2 id="随机变量-Random-Variable"><a href="#随机变量-Random-Variable" class="headerlink" title="随机变量 Random Variable"></a>随机变量 Random Variable</h2><h2 id="概率分布-Probability-Distribution"><a href="#概率分布-Probability-Distribution" class="headerlink" title="概率分布 Probability Distribution"></a>概率分布 Probability Distribution</h2><h3 id="联合概率分布-P-X-x-Y-y"><a href="#联合概率分布-P-X-x-Y-y" class="headerlink" title="联合概率分布 P(X=x,Y=y)"></a>联合概率分布 P(X=x,Y=y)</h3><h3 id="概率密度函数-Probability-Density-Function-pdf"><a href="#概率密度函数-Probability-Density-Function-pdf" class="headerlink" title="概率密度函数 Probability Density Function/pdf"></a>概率密度函数 Probability Density Function/pdf</h3><h2 id="边缘概率分布"><a href="#边缘概率分布" class="headerlink" title="边缘概率分布"></a>边缘概率分布</h2><h2 id="条件概率-P-Y-y-X-x-P-Y-y-X-x-P-X-x"><a href="#条件概率-P-Y-y-X-x-P-Y-y-X-x-P-X-x" class="headerlink" title="条件概率: P(Y=y|X=x)=P(Y=y,X=x)/P(X=x)"></a>条件概率: P(Y=y|X=x)=P(Y=y,X=x)/P(X=x)</h2><h2 id="链式法则"><a href="#链式法则" class="headerlink" title="链式法则"></a>链式法则</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/3.png">
<h2 id="独立性-条件独立性"><a href="#独立性-条件独立性" class="headerlink" title="独立性/条件独立性"></a>独立性/条件独立性</h2><h2 id="期望Expectation"><a href="#期望Expectation" class="headerlink" title="期望Expectation"></a>期望Expectation</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/4.png">
<img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/5.png">
<h2 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/6.png">
<h2 id="协方差"><a href="#协方差" class="headerlink" title="协方差"></a>协方差</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/7.png">
<h2 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><h2 id="logistic-sigmoid函数"><a href="#logistic-sigmoid函数" class="headerlink" title="logistic sigmoid函数"></a>logistic sigmoid函数</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/8.png">
<h2 id="softplus函数"><a href="#softplus函数" class="headerlink" title="softplus函数"></a>softplus函数</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/9.png">
<h2 id="Bayes-Rules"><a href="#Bayes-Rules" class="headerlink" title="Bayes Rules"></a>Bayes Rules</h2><p>P(x|y)=P(x)P(y|x)/P(y)</p>
<h2 id="信息论"><a href="#信息论" class="headerlink" title="信息论"></a>信息论</h2><h2 id="KL散度"><a href="#KL散度" class="headerlink" title="KL散度"></a>KL散度</h2><img src="/2018/04/07/Deep-Learning-I-Introduction-Symbols/10.png">
]]></content>
      
        
        <tags>
            
            <tag> Deep Learning </tag>
            
            <tag> Probability </tag>
            
            <tag> Algebra </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Machine Learning Algorithm]]></title>
      <url>/2018/03/29/Machine-Learning-Algorithm/</url>
      <content type="html"><![CDATA[<h1 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h1><p><a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm" target="_blank" rel="noopener">WIKIPEDIA</a></p>
<p><a href="https://coolshell.cn/articles/8052.html" target="_blank" rel="noopener">COOLSHELL</a></p>
<h2 id="Basic-idea"><a href="#Basic-idea" class="headerlink" title="Basic idea"></a>Basic idea</h2><p>The basic idea of KNN is to classify a certain sample into a categrory based on K nearest neighbors. </p>
<p>Different K could have a different influence on the result</p>
<p>To find the K nearest sample points, Max Heap could be a suitable solution</p>
<h2 id="Heap-and-Tree"><a href="#Heap-and-Tree" class="headerlink" title="Heap and Tree"></a>Heap and Tree</h2><p>Here since we involve the idea of Heap, I think it’s necessary to record some ideas about the Heap and Tree.</p>
<p>Heap is a special tree. As is know to us all, <strong>TREE</strong> is a data structure based on a <strong>value</strong>, that the left son is always smaller than its father while the right son is always greater than its father.</p>
<p>While <strong>HEAP</strong> is built based on a <strong>weight</strong>, that the father nodes’ weight is always greater or smaller than its sons.</p>
<p><strong>TREAP</strong> has both <strong>value</strong> and <strong>weight</strong>.</p>
<p>In KNN, it is possible to build min-max heap. The max heap is a heap that the node with the greatest weight as a root. So when we try to find the neighbors of a new k value, it has great performance.</p>
<h1 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h1><p><a href="https://www.zhihu.com/question/21094489" target="_blank" rel="noopener">ZHIHU</a></p>
<p><a href="https://www.youtube.com/watch?v=3liCbRZPrZA" target="_blank" rel="noopener">YOUTUBE</a></p>
<p><a href="https://www.zhihu.com/question/24627666" target="_blank" rel="noopener">KERNEL METHOD</a></p>
<h1 id="Decision-Tree"><a href="#Decision-Tree" class="headerlink" title="Decision Tree"></a>Decision Tree</h1><p><a href="https://blog.csdn.net/xbinworld/article/details/44660339" target="_blank" rel="noopener">CSDN</a></p>
<p><a href="http://www.cnblogs.com/leoo2sk/archive/2010/09/19/decision-tree.html" target="_blank" rel="noopener">CNBLOG</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/26703300" target="_blank" rel="noopener">ZHIHU</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/26760551" target="_blank" rel="noopener">ZHIHU</a></p>
]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> KNN </tag>
            
            <tag> SVM </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[NP Complete Problems]]></title>
      <url>/2018/03/24/NP-Complete-Problems/</url>
      <content type="html"><![CDATA[<h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>迄今为止，几乎大部分算法都是多项式时间算法，也就是对于规模为n的输入，在最坏情况下的运行时间为O（n^k），其中k为某个常数，然而并不是所有的问题都能在多项式时间内解决，如著名的“停机问题”。</p>
<p>“NP完全”（NP-complete）问题的状态是未知的，既没有人找到这类问题的多项式时间算法，也没有人证明这类问题的多项式时间算法不存在。</p>
<blockquote>
<p>一个NPC不一定是无法解决的，但是他的算法可能复杂度是O（2^n）等等，总之是无法在多项式时间内解决。</p>
</blockquote>
<p>在本文档中介绍三类问题</p>
<ul>
<li><p>P：在多项式时间内可以解决的问题</p>
</li>
<li><p>NP：在多项式时间内可以验证的问题，在问题输入的规模的多项式时间内，可以验证某一个结果是否是正确的（不难看出，P⊆NP）</p>
</li>
<li><p>NPC：如果一个问题属于NP，并且与NP中的任何一个问题是一样难的，那么这个问题属于NPC，也就是说他是NP完全的</p>
</li>
</ul>
<blockquote>
<p>如果任何NPC问题可以在多项式时间内解决，那么每一个NPC问题都有一个多项式时间算法</p>
</blockquote>
<p>在证明一个问题是NPC问题的时候，我们需要的证明方式往往是去陈述它是一个多么困难的问题，而不是去证明存在某个算法与否。</p>
<h1 id="关键概念"><a href="#关键概念" class="headerlink" title="关键概念"></a>关键概念</h1><h2 id="判定问题与最优化问题"><a href="#判定问题与最优化问题" class="headerlink" title="判定问题与最优化问题"></a>判定问题与最优化问题</h2><p>NPC并不适用于最优化问题，但适用于判定问题，尽管证明一个问题是NPC问题会将我们的目光局限于判定问题，但是在最优化问题和判定问题之间有很方便的联系。</p>
<p>当我们在证明某一个最优化问题是一个困难的问题的时候，我们可以利用这个问题所对应的判定问题，<strong>因为从某种意义上来讲，判定问题会容易一些，或者至少不会更难。</strong></p>
<p>因此，加入我们能够提供证据表明某个判定问题是个困难问题的话，我们也提供了证据表明其相关的最优化问题也是困难的。</p>
<h2 id="归约"><a href="#归约" class="headerlink" title="归约"></a>归约</h2><p>对于一个判定问题A，我们希望在多项式时间内解决该问题，称这个问题的输入为该问题的一个实例，假设我们有另一个不同的判定问题B，我们知道如何在多项式时间内解决它，并且假设有一个过程，可以将A的任何实例转化成B的实例，并且这个转化的过程具有如下的性质：</p>
<ul>
<li><p>转换操作需要多项式时间</p>
</li>
<li><p>两个实例的答案是相同的</p>
</li>
</ul>
<p>那么我们称这个转化的过程为多项式时间的归约算法。因此可以将问题A的求解归约为B的求解（<strong>因为如果B的算法是多项式时间，转换过程为多项式时间，那么A也可以在多项式时间内解决</strong>）。</p>
<blockquote>
<p>第一个NPC问题，<strong>电路可满足性问题</strong>，已知一个布尔组合电路，由AND，OR和NOT组成，我们希望知道这个电路是否存在一组布尔输入，使得电路的输出为1，检查这个电路是否是可满足的，除了尝试去测试每一组输入输出之外，没有别的好办法，而这样的办法的复杂度为O（2^n）</p>
</blockquote>
<h1 id="多项式时间"><a href="#多项式时间" class="headerlink" title="多项式时间"></a>多项式时间</h1><p>我们形式化的定义一下多项式时间可解问题，这些问题通常都被看作是容易处理的。</p>
<h2 id="抽象问题"><a href="#抽象问题" class="headerlink" title="抽象问题"></a>抽象问题</h2><p>问了理解多项式时间可解问题，我们形式化定义“问题”这个概念：</p>
<ul>
<li>定义抽象问题Q为在问题实例集合I和问题解法集合S上的一个二元关系</li>
</ul>
<p>而为了简单起见，因为我们只讨论NPC问题中的判定问题，我们可以把抽象的判定问题看作是实例集I映射到解集{0，1}上的一个函数。如在一个最短路径问题中，我们的输入是一个实例i=<g,u,v,k>，那么如果从u到v最短路径长度为k，则PATH（i）=1，否则PATH（i）=0</g,u,v,k></p>
<h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>使用计算机解决问题，任何多边形，图，函数，有序对都可以编码成二进制串。</p>
<p>我们把实例集为二进制串的集合的问题成为<strong>具体问题</strong>，如果一个问题实例的长度为n=|i|，算法可以在O（T（n））内产生问题的解，那么我们说算法在这个时间内解决了该问题。</p>
<p>因此，如果给定一个抽象判定问题Q，其映射为实例集合I到{0,1}，通过某种编码e：I-&gt;{0,1}可以导出与问题相关的具体判定问题。</p>
<blockquote>
<p>通常情况下，编码的方式并不会影响问题的计算难度，然而在实践中并不是这样，我们需要假设采用标准编码的二进制串。</p>
</blockquote>
<h2 id="形式语言体系"><a href="#形式语言体系" class="headerlink" title="形式语言体系"></a>形式语言体系</h2><p>形式语言体系可以表述判定问题和求解算法之间的联系，如果给定输入x，算法输出A（x）=1，我们说算法A<strong>接受</strong>串x，如果A（x）=0，我们说算法A<strong>拒绝</strong>串x。<strong>被算法A接受的语言L={x belongs to {0,1}*: A(x)=1}</strong></p>
<p>如果对于L中每个x，要么被A接受要么被拒绝（不存在拒绝该x但是永远循环下去的情况，这种情况说A<strong>接受</strong>L），我们说L由A<strong>判定</strong>。</p>
<h1 id="多项式时间的验证"><a href="#多项式时间的验证" class="headerlink" title="多项式时间的验证"></a>多项式时间的验证</h1><h2 id="Hamilton-Cycle"><a href="#Hamilton-Cycle" class="headerlink" title="Hamilton Cycle"></a>Hamilton Cycle</h2><p>我们先使用形式语言来定义Hamilton Cycle问题</p>
<p>HAM-CYCLE={<g>:G is a Hamilton Cycle}</g></p>
<p>如何使用算法来判定Hamilton Cycle问题，已知一个问题实例<g>，一种办法就是列出G定点的全部排列，然后对于每一种排列进行检查，那么这个算法的运行时间为<strong>Omega（2^(n^1/2)）</strong></g></p>
<p>不难看出，如果有一个人说对于一个问题实例<g>,他说这个图是一个Hamilton Cycle并给出了一个回路排列来证明，我们很容易来验证这个答案是否是正确的。</g></p>
<h2 id="NP问题"><a href="#NP问题" class="headerlink" title="NP问题"></a>NP问题</h2><p>从上面的问题可以看出，HAM-CYCLE属于NP，因为他能在多项式时间内被验证。</p>
<h1 id="NP完全性与可归约性"><a href="#NP完全性与可归约性" class="headerlink" title="NP完全性与可归约性"></a>NP完全性与可归约性</h1><blockquote>
<p>HAM-CYCLE就是一个NPC问题</p>
</blockquote>
<h2 id="可归约性"><a href="#可归约性" class="headerlink" title="可归约性"></a>可归约性</h2><p>一个问题Q可以被归约为另一个问题Q‘，如果Q的任何实例都可以被容易的（<strong>在多项式时间内</strong>）表述为Q’的实例，并且Q‘实例的解也是Q的实例的解，<strong>因此，如果一个问题Q可以归约成Q’，则从某种意义上来说Q不比Q‘更难解决</strong></p>
<p>回归到形式语言体系中，也可也表述为L1可以在多项式时间内归约为语言L2，记作L1&lt;=pL2。</p>
<blockquote>
<p>如果L1&lt;=pL2，则L2属于P蕴含着L1属于P</p>
</blockquote>
<h2 id="NP完全性"><a href="#NP完全性" class="headerlink" title="NP完全性"></a>NP完全性</h2><p>通过以上对于可归约性的定义，我们可以定义NPC的集合</p>
<p>语言L属于NPC，如果：</p>
<ol>
<li><p>L属于NP</p>
</li>
<li><p>对于每个L‘属于NP，有L’&lt;=pL</p>
</li>
</ol>
<p>如果一种语言满足2，但不一定满足1，我们称这种语言是NP-Hard</p>
<blockquote>
<p>如果任何NP问题是多项式时间可以求解的，那么P=NP，等价的，如果NP中的任何问题不是多项式时间可以求解的，那么任何NP完全问题都不是多项式时间可以求解的。</p>
</blockquote>
<h1 id="NPC完全性的证明"><a href="#NPC完全性的证明" class="headerlink" title="NPC完全性的证明"></a>NPC完全性的证明</h1><h2 id="引理"><a href="#引理" class="headerlink" title="引理"></a>引理</h2><p>如果L是一种对于某个L‘属于NPC，有L’&lt;=pL的语言，则L是NP难度的，此外如果L属于NP，则L属于NPC。</p>
]]></content>
      
        
        <tags>
            
            <tag> NP Complete </tag>
            
            <tag> Algorithms Analysis </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Computer Infrastructures Basic Parameters]]></title>
      <url>/2018/03/20/Computer-Infrastructures-Basic-Parameters/</url>
      <content type="html"><![CDATA[<h1 id="BASIC-PARAMETERS"><a href="#BASIC-PARAMETERS" class="headerlink" title="BASIC PARAMETERS"></a>BASIC PARAMETERS</h1><p><strong>T</strong> the length of time we observed the system</p>
<p><strong>A</strong> the number of request arrivals we observed</p>
<p><strong>C</strong> the number of request completions we observed</p>
<p><strong>Workload intensity/arrival rate Lamda</strong> the rate at which the customers arrive (eg 0.5 customers/second)  Lamda = A/T</p>
<p><strong>Throughput X</strong> the rate at which customers pass through the service center (0.5 customers/second) X = C/T</p>
<p><strong>N</strong> the average number of requests in the system (customer population) N = W/T</p>
<p><strong>Residence time R</strong> the average time spent at the service center by a customer, both queueing and receiving service R=W/C</p>
<p><strong>Queue length</strong> the average number of customers at the service center both waiting and receiving service (1.67 customers)</p>
<p><strong>B</strong> the length of time that the resource was obeserved to be busy</p>
<p><strong>Utilization U</strong> the proportion of time the server is busy (eg 0.625/62.5%)   U = B/T</p>
<p><strong>S</strong> the average service requirement of a customer (eg 1.25 seconds) S = B/C</p>
<p><strong>Z</strong> think time of a terminal user</p>
<p><strong>Dk</strong> Service demand at resource k Dk=VkSk</p>
<h1 id="BASIC-LAWS"><a href="#BASIC-LAWS" class="headerlink" title="BASIC LAWS"></a>BASIC LAWS</h1><p><strong>The Utilization Law</strong> U=X*S</p>
<p><strong>Little’s Law</strong> N=X*R</p>
<p><strong>The Response Time Law</strong> R=N/X-Z </p>
<p><strong>The Forced Flow Law</strong> Xi=Vi*X</p>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Computer Infrastructures </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part IV]]></title>
      <url>/2018/03/19/Cryptography-Part-IV/</url>
      <content type="html"><![CDATA[<h1 id="Mar-19-Block-Cipher-Cryptanalyses-Linear-Cryptanalysis"><a href="#Mar-19-Block-Cipher-Cryptanalyses-Linear-Cryptanalysis" class="headerlink" title="Mar 19 Block Cipher Cryptanalyses: Linear Cryptanalysis"></a>Mar 19 Block Cipher Cryptanalyses: Linear Cryptanalysis</h1><h1 id="Block-Cipher-Cryptanalysis"><a href="#Block-Cipher-Cryptanalysis" class="headerlink" title="Block Cipher Cryptanalysis"></a>Block Cipher Cryptanalysis</h1><p>Modern block cipher cryptanalysis aims at either recovering the key with an effort smaller than bruteforce</p>
<p>Block cipher cryptanalyses are usually split into two families: </p>
<ul>
<li><p>algebraic </p>
</li>
<li><p>statistical</p>
</li>
</ul>
<h1 id="Algebraic-Analysis"><a href="#Algebraic-Analysis" class="headerlink" title="Algebraic Analysis"></a>Algebraic Analysis</h1><h1 id="Statistical-Analysis"><a href="#Statistical-Analysis" class="headerlink" title="Statistical Analysis"></a>Statistical Analysis</h1><p>All the computationally secure ones produce a ctx where the probability that a bit is either one or zero is biased (= 1 ± ε) by the 2 ptx value</p>
<p><strong>Goal</strong>: find such relations between ptx and ctx, and exploit the statistical biases to extract a portion of the key</p>
<h1 id="The-“TRIVIAL”-Cipher"><a href="#The-“TRIVIAL”-Cipher" class="headerlink" title="The “TRIVIAL” Cipher"></a>The “TRIVIAL” Cipher</h1><h1 id="S-Boxes"><a href="#S-Boxes" class="headerlink" title="S-Boxes"></a>S-Boxes</h1><p>Without S-Boxes, the linear relations between ptx and ctx bits are always hold( i.e. with probability = 1)</p>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part III]]></title>
      <url>/2018/03/16/Cryptography-Part-III/</url>
      <content type="html"><![CDATA[<h1 id="Mar-12-SPN-amp-AES"><a href="#Mar-12-SPN-amp-AES" class="headerlink" title="Mar 12 SPN &amp; AES"></a>Mar 12 SPN &amp; AES</h1><h2 id="SPN"><a href="#SPN" class="headerlink" title="SPN"></a><a href="https://en.wikipedia.org/wiki/Substitution%E2%80%93permutation_network" target="_blank" rel="noopener">SPN</a></h2><p>SPN are built along <a href="https://en.wikipedia.org/wiki/Confusion_and_diffusion" target="_blank" rel="noopener">Shannon’s criteria of confusion and diffusion</a></p>
<ul>
<li><p>Confusion: obtained from the key mixing and substitution phase</p>
<blockquote>
<p>make the relationship between the key and cipher text as complicated as possible. Which means given cipher text it is hard to derive the key</p>
</blockquote>
</li>
<li><p>Diffusion: obtained through the permutation of linear diffusion phase</p>
<blockquote>
<p>dissipating the statistical structure of plaintext over the bulk of ciphertext. Which means the attacker could not break the system by statistic methods</p>
</blockquote>
</li>
</ul>
<h2 id="AES"><a href="#AES" class="headerlink" title="AES"></a><a href="https://en.wikipedia.org/wiki/Advanced_Encryption_Standard" target="_blank" rel="noopener">AES</a></h2><ul>
<li>128-bit block size (thought as a 4×4 byte matrix)</li>
<li><p>3 key sizes (128/192/256-bits)</p>
<blockquote>
<p>Round Structure: Given a 4*4 byte matrix as input</p>
<ol>
<li><p>A Substitution layer in the form of 16 S-boxes, 8-to-8 bit</p>
</li>
<li><p>A Permutation layer implemented via a bytewise rotation (ShiftRows) and a xor-linear operation among state bytes (MixColumn)</p>
</li>
<li><p>A key addition: bitwise ⊕, with 128 bits of expanded key material</p>
</li>
</ol>
</blockquote>
</li>
</ul>
<h2 id="Steam-Ciphers"><a href="#Steam-Ciphers" class="headerlink" title="Steam Ciphers"></a>Steam Ciphers</h2><p>In a Stream Cipher, we would like to </p>
<ol>
<li><p>use short keys k ∈ K to encrypt long messages </p>
</li>
<li><p>use algorithmically generated pseudo-random values for the keystream instead of truly random ones </p>
</li>
<li><p>be sure that the same keystream sequence is repeated only after a very long sequence of messages has been encrypted (. . . a practical value for infinity)</p>
</li>
</ol>
<blockquote>
<p>Synchronous Stream Ciphers</p>
<p>The keystream is generated as a function of the cipher key and of the memory elements, independently of any previous ptx or ctx digit, i.e. ki=f(k,s0,s1,…)</p>
<p>Asynchronous Stream Ciphers</p>
<p>The keystream is generated as a function of the cipher key and a finite number of previous ctxs. </p>
<p>Given a key k and an initial state S0 = ⟨sL−1, . . . , s0⟩ the keystream is composedas: ki =f(k,Si,Si−1,…)with Si =⟨ci+L−1,ci+L−2,…,ci+1,ci⟩</p>
</blockquote>
<h2 id="LFSR-Linear-Feedback-Shift-Registers"><a href="#LFSR-Linear-Feedback-Shift-Registers" class="headerlink" title="LFSR/Linear Feedback Shift Registers"></a>LFSR/Linear Feedback Shift Registers</h2><p><a href="https://www.youtube.com/watch?v=sKUhFpVxNWc" target="_blank" rel="noopener">https://www.youtube.com/watch?v=sKUhFpVxNWc</a></p>
<h1 id="Mar-15-Hybrid-Cryptosystems"><a href="#Mar-15-Hybrid-Cryptosystems" class="headerlink" title="Mar 15 Hybrid Cryptosystems"></a>Mar 15 Hybrid Cryptosystems</h1><h2 id="Hybrid-cryptosystems"><a href="#Hybrid-cryptosystems" class="headerlink" title="Hybrid cryptosystems"></a>Hybrid cryptosystems</h2><p>Encryption: Alice generates a random symmetric key k, encrypts the message with it, and encrypts k with kB<sub>pub</sub></p>
<p>Decryption: Bob decrypts k using kB<sub>pri</sub>, and uses it to decrypt the message, after which he may discards k.</p>
<p>Signature: Alice should sign something smaller than the whole message, although uniquely bound to it in some way</p>
<blockquote>
<p>Solving the efficient signature problem requires a new cryptographic primitive, the cryptographic hash</p>
</blockquote>
<h2 id="Cryptographic-Hash"><a href="#Cryptographic-Hash" class="headerlink" title="Cryptographic Hash"></a>Cryptographic Hash</h2><p>A hash is a deterministic function from arbitrary length message m, to fixed length output h = H(m) (Practically used to obtain a fixed-length “label” h for a digital object)</p>
<blockquote>
<p>The same value of h may be the hash of different messages (no such thing as bijective arbitrary size → fixed size compression)</p>
<p>Property</p>
<ol>
<li><p>Given h, hard to find m such that H(m)=h</p>
</li>
<li><p>Given m, hard to find m’ such that H(m)=H(m’)</p>
</li>
<li><p>Hard to find m’ and m’’ such that H(m’)=H(m’’)</p>
</li>
</ol>
</blockquote>
<h2 id="Public-Key-Authentication-证明公钥匙是谁的"><a href="#Public-Key-Authentication-证明公钥匙是谁的" class="headerlink" title="Public Key Authentication[证明公钥匙是谁的]"></a>Public Key Authentication[证明公钥匙是谁的]</h2><p>To prevent impersonation attack on publich key cryptosystems.(Pretend to be someone you are not and steal the information). Here rises the need of <strong>DIGITAL CERTIFICATE of authenticity of public keys</strong></p>
<h2 id="Digital-Certificate"><a href="#Digital-Certificate" class="headerlink" title="Digital Certificate"></a>Digital Certificate</h2><p>Our purpose is to authenticate the binding of a public key to the identity of someone/some company</p>
<p>举个例子方便大家理解，假设我们公司”ABC Company”花了1000块钱，向一个证书发布机构”SecureTrust CA”为我们自己的公司”ABC Company”申请了一张证书，注意，这个证书发布机构”SecureTrust CA”是一个大家公认并被一些权威机构接受的证书发布机构，我们的操作系统里面已经安装了”SecureTrust CA”的证书。”SecureTrust CA”在给我们发布证书时，把Issuer,Public key,Subject,Valid from,Valid to等信息以明文的形式写到证书里面，然后用一个指纹算法计算出这些数字证书内容的一个指纹，并把指纹和指纹算法用自己的私钥进行加密，然后和证书的内容一起发布，同时”SecureTrust CA”还会给一个我们公司”ABC Company”的私钥给到我们。我们花了1000块钱买的这个证书的内容如下：</p>
<p>×××××××××××××××证书内容开始×××××××××××××××××</p>
<p>Issuer : SecureTrust CA</p>
<p>Subject : ABC Company</p>
<p>Valid from ： 某个日期</p>
<p>Valid to： 某个日期</p>
<p>Public Key : 一串很长的数字</p>
<p>…… 其它的一些证书内容……</p>
<p>{证书的指纹和计算指纹所使用的指纹算法}[SecureTrust CA的私钥|RSA]</p>
<p>//这个部分验证了消息的完整性，确定这个消息没有被人中途修改过      </p>
<p>//这个就是”SecureTrust CA”对这个证书的一个数字签名，表示这个证书确实是他发布的，有什么问题他会负责(收了我们1000块，出了问题肯定要负责任的)</p>
<p>×××××××××××××××证书内容结束×××××××××××××××××</p>
<p>//{} 表示RSA加密后的内容，[ | ]表示用什么密钥和算法进行加密</p>
<blockquote>
<ol>
<li><p>首先当用户收到了来自一个服务器的一个安全证书，他会检查是否CA是这个用户信任的CA</p>
</li>
<li><p>其次用户会检查这个安全证书是否是权威的，也就是通过CA公布的公钥来验证CA的数字签名</p>
</li>
<li><p>如果用户确认了这一消息（该证书由一个可信赖的CA颁发并且内容没有修改过），那么这份安全证书就可以被信任</p>
</li>
</ol>
</blockquote>
<p>A keypair can be compromised (e.g. by theft, blackmail)。 Revocation of a certificate could be done by CRLs, or OCSP.</p>
<h2 id="Who-Signs-The-Certificate"><a href="#Who-Signs-The-Certificate" class="headerlink" title="Who Signs The Certificate"></a>Who Signs The Certificate</h2><p><strong>PKI/Public Key Infrastructure</strong>: A centralized, tree structured<br>architecture of entities which sign certificates of their subsiders. The root authorities are implicitly trusted</p>
<pre><code>Root CAs are a single point of failure for the whole infrastructure: if a Root CA gets its key compromised, all the certificates issued from offspring CAs become forgeable.
</code></pre><blockquote>
<p>ACME Control</p>
</blockquote>
<p><strong>WoT/Web-of-Trust</strong>: A distributed architecture relying on the “small world assumption” where everyone can sign certificates. The trust on the authenticity of a certificate is established depending on the trust on the authenticity of its signers</p>
<ul>
<li><p><strong>Users</strong>: The only actor of the scheme are users, they : </p>
<p>  Encrypt/sign/verify a digital object (file/mail message)</p>
<p>  Acts as a CA signing someone else’s key/id pair</p>
<p>  Keep a local key/id keyring where all the certificates are kept </p>
<p>  Choose which users they trust to be acting as a CA</p>
</li>
<li><p><strong>Keyservers</strong>: Provide a globally synchronized, trusted archive of public certificates.</p>
<p>  Public lookup is provided via either key ID or user ID</p>
<p>  The archive is append only, no practical removal is possible </p>
<p>  Anyone can run a keyserver, provided he has enough resources.</p>
</li>
<li><p><strong>Trust Levels</strong>:</p>
<p>  The default trust levels in the WoT scheme are :</p>
<ul>
<li><p>ultimate: It’s the user’s own key trust level. Every key you sign with an “ultimate” trusted key becomes authentic.</p>
</li>
<li><p>complete: One signature by a key with this level of trust makes the key/id pair authentic.</p>
</li>
<li><p>marginal: At least 2 keys with marginal trust have to sign a key/id pair to make it authentic.</p>
</li>
<li><p>untrusted: Untrusted key signatures do not contribute to mark a key/id pair as authentic</p>
<blockquote>
<p>This based on the assuming that before a certificate is signed, each user would be careful enough to verify the corresponding identity.</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Certification Authority (CA): An entity (typically a firm) which takes care of signing the certificates, and distributes its public key to all the users in a trusted manner</p>
<blockquote>
<ol>
<li><p>The CA creates its own keypair and fills in the fields of its certificate</p>
</li>
<li><p>We assume, for the sake of clarity, that we are describing a root CA, i.e. one sitting at the top of the PKI hierarchy The CA self-signs its own certificate, and stores its own private key in a tightly guarded place (at least,hopefully)</p>
</li>
<li><p>The CA takes care to distribute its self-signed public key certificate in a safe manner to the largest possible user-base</p>
</li>
</ol>
</blockquote>
</li>
<li><p>Registration Authority (RA): An entity (again, usually a firm) which takes care of verifying the actual authenticity of a certificate, gathering data on the user (physically checking his/her identity and certificate hash). Very often, it coincides with the CA</p>
</li>
<li><p>User: Asks the CA to sign his certificate, or employs the CA public keys to verify the authenticity of the certificates for another user.</p>
</li>
</ul>
<h2 id="Mail-Protocol-PGP-GPG"><a href="#Mail-Protocol-PGP-GPG" class="headerlink" title="Mail Protocol PGP/GPG"></a>Mail Protocol PGP/GPG</h2><p>Possible to encrypt and sign any file, the most typical use is to encrypt and sign e-mail messages</p>
<p>PGP/GPG messages encrypted and signed with an hybrid symmetric+asymmetric scheme for efficiency</p>
<blockquote>
<p>This method is the typical hybrid system. Sender generates a symmetric key to encrypt files and send the symmetric key encrypted in the reciever’s public key.</p>
</blockquote>
<h1 id="Useful-Links"><a href="#Useful-Links" class="headerlink" title="Useful Links"></a>Useful Links</h1><ol>
<li><p><a href="https://www.zhihu.com/question/52493697" target="_blank" rel="noopener">https://www.zhihu.com/question/52493697</a></p>
</li>
<li><p><a href="http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html" target="_blank" rel="noopener">http://www.cnblogs.com/JeffreySun/archive/2010/06/24/1627247.html</a></p>
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part II]]></title>
      <url>/2018/03/16/Cryptography-Part-II/</url>
      <content type="html"><![CDATA[<h1 id="Mar-5-Block-Ciphers-amp-Modes-of-Operation"><a href="#Mar-5-Block-Ciphers-amp-Modes-of-Operation" class="headerlink" title="Mar 5 Block Ciphers &amp; Modes of Operation"></a>Mar 5 Block Ciphers &amp; Modes of Operation</h1><h2 id="Design-of-Symmetric-key-Ciphers-Confusion-amp-Diffusion"><a href="#Design-of-Symmetric-key-Ciphers-Confusion-amp-Diffusion" class="headerlink" title="Design of Symmetric-key Ciphers: Confusion &amp; Diffusion"></a>Design of Symmetric-key Ciphers: Confusion &amp; Diffusion</h2><ul>
<li><p>Confusion<br>  make the relation between the key, plaintext and ciphertext as complex as possible. Ideally, each digit of the key influences the correspondence between pxt and cxt letters in a non-predictable way</p>
<blockquote>
<p>Ciphers that do not offer effective confusion are vulnerable to frequency analysis</p>
</blockquote>
</li>
<li><p>Diffusion<br>  Refers to the property that the statistical distribution of “groups of pxt letters” frequencies (due to the redundancy of the ptx language) should be dissipated, as much as possible, into flat distribution statistics, i.e. the ctx should appear as random data.</p>
<blockquote>
<p>Diffusion spreads (diffuse) the influence of a single plaintext letter over many (or every) cxt letters</p>
<p>Ciphers suffering from poor diffusion can usually be broken by means of Known Plaintext Attacks (e.g., simple permutation ciphers) </p>
</blockquote>
</li>
</ul>
<h2 id="Block-Ciphers"><a href="#Block-Ciphers" class="headerlink" title="Block Ciphers"></a>Block Ciphers</h2><p>Block ciphers operate on a block of plaintext m∈M (m = <m1, .="" ,="" mn="">, with m<sub>i</sub>∈{0, 1}), to produce a block of ciphertext (c = <c1, .="" ,="" cn=""> ∈ C, with c<sub>i</sub>∈{0, 1}) through a key-parametric transformation (either E<sub>k</sub> () or D<sub>k</sub> ())</c1,></m1,></p>
<blockquote>
<p>The block size n is in the [64, 256] bit range</p>
<p>ptx size might not be multiple a of block size → PADDING</p>
<p>For ptxs longer than a single block, the scheme used to apply E<sub>k</sub> () (or D<sub>k</sub> ()) is called mode of operation</p>
</blockquote>
<h2 id="Basic-Terminologies"><a href="#Basic-Terminologies" class="headerlink" title="Basic Terminologies"></a>Basic Terminologies</h2><p><strong>Cipher State</strong>: The result of each operation performed by the cipher (Initialized with the ptx; contains the ctx at the end of the computation)</p>
<p><strong>Round</strong>: basic sequence of operations applied to the cipher state, a number of times (involves blending the key into the state)</p>
<p><strong>Key Schedule</strong>: procedure expanding the original user key into key material to be used in each round</p>
<h2 id="Modern-Block-Ciphers"><a href="#Modern-Block-Ciphers" class="headerlink" title="Modern Block Ciphers"></a>Modern Block Ciphers</h2><ul>
<li><p>Feistel Networks</p>
<p>  Invented by Horst Feistel (in ’50-’60), it splits the cipher state in two parts and acts on one of them per round</p>
<p>  A Feistel network transforms an n-bit ptx block m=<l0, r0="">, into an n-bit ctx block c=<rr, lr=""> through an r-round process (r≥1); where the sub-blocks Li , Ri are n/2-bit long.</rr,></l0,></p>
<pre><code>  Feistel(&lt;L, R&gt;, k)
      1 for i ← 0 to r − 1
      2   temp ← L
      3   L ← R
      4   R ← temp ⊕ F(ki, R) // Li = Ri−1, Ri = Li−1 ⊕ F(ki, Ri−1)
      5 R ← R ⊕ F(kr, L)
      6 return &lt;R, L&gt; // Note: the last round block halves are swapped
</code></pre><blockquote>
<p>Properties</p>
<p>L<sub>i</sub> = R<sub>i-1</sub>, R<sub>i</sub> = L<sub>i-1</sub> ⊕ F(k<sub>i</sub> , R<sub>i-1</sub>)</p>
<p>R<sub>i-1</sub> = L<sub>i</sub> , L<sub>i-1</sub> = R<sub>i</sub> ⊕ F(k<sub>i</sub>, L<sub>i</sub>)</p>
</blockquote>
  <img src="/2018/03/16/Cryptography-Part-II/Crypto.png">
<blockquote>
<p>Ciphers based on a Feistel Network</p>
<p>DES, Blowfish, Twofish, CAST5</p>
</blockquote>
</li>
<li><p>DES</p>
<p>  16-round Feistel cryptosystem with 64-bit wide cipher state</p>
  <img src="/2018/03/16/Cryptography-Part-II/Crypto2.png">
<p>  <strong>DES round</strong>: F(ki, Ri−1) = P-box(S-box(ki ⊕ E-box(Ri−1))</p>
<ol>
<li><p>E-box(Ri−1) expands Ri−1 from 32 (4 <em> 8) into 48 (6 </em> 8) bits </p>
</li>
<li><p>Adds (XOR) the 48-bit round key ki </p>
</li>
<li><p>Map the 48-bit word into a 32-bit one via applying 8 fixed S-boxes. Each S-box map a 6 bit word to a 4 bit one</p>
</li>
<li><p>Apply a fixed bitwise permutation specified by the P-box</p>
<p><strong>Weak Keys</strong>: Encrypting a ptx twice with a weak key k, yields the original ptx. DES(k, DES(k, m)) = m, ∀ m ∈ M</p>
<p><strong>Semi-Weak Keys</strong>: Also a Semi-Weak key pair <k, k0=""> causes the composition of two DES encryptions employing k and k0 to compute the original ptx DES(k, DES(k 0, m)) = m, ∀ m ∈ M</k,></p>
<p><strong>Not Closed</strong>: ∀m not exists k3 s.t. DES(k3, m) = DES(k2, DES(k1, m))</p>
<blockquote>
<p>The composition of two DES with distinct keys is still a permutation Sn, but in general it cannot be thought as computed by a DES with another key.</p>
</blockquote>
<p><a href="https://zh.wikipedia.org/wiki/資料加密標準" target="_blank" rel="noopener">DES in wiki</a></p>
<p><a href="https://zh.wikipedia.org/wiki/DES%E8%A1%A5%E5%85%85%E6%9D%90%E6%96%99#%E6%89%A9%E5%BC%A0%E5%87%BD%E6%95%B0_(E%E5%87%BD%E6%95%B0" target="_blank" rel="noopener">DES support material</a>)</p>
</li>
</ol>
</li>
<li><p>2DES</p>
<p>  Double DES cipher consists of applying the DES primitive twice: c = 2DES(k1, k2, m) def as DES(k1, DES(k2, m))</p>
</li>
<li><p>Triple DES/TDES</p>
<p>  c = 3DES(k1, k2, k3, m) def as = DES(k1, DES−1 (k2, DES(k3, m)))</p>
<p>  m = 3DES−1(k1, k2, k3, m) def. = DES−1(k3, DES(k2, DES−1(k1, c)))</p>
</li>
<li><p>Substitution Permutation Networks (SPNs)</p>
<blockquote>
<p>The round of a SPN acts on the whole cipher state with:</p>
<p>A “non-linear” function providing Confusion represented as a lookup table, a.k.a.: Substitution-Box (S-box)</p>
<p>A “linear” function providing Diffusion, i.e., a bitwise permutation, or pairs of rotate &amp; xor operations The addition of a part of the key schedule</p>
</blockquote>
</li>
</ul>
<h2 id="Modes-of-Operation"><a href="#Modes-of-Operation" class="headerlink" title="Modes of Operation"></a>Modes of Operation</h2><p>A Mode of operation specifies the way to encrypt a message m∈M of arbitrary length through employing a block cipher</p>
<p>Currently, there are modes of operations to guarantee </p>
<ul>
<li><p>Confidentiality of messages:</p>
<p>  Electronic CodeBook mode (ECB)</p>
<p>  Cipher Block Chaining mode (CBC)–most popular–not entirely secure</p>
<p>  Output FeedBack mode (OFB)</p>
<p>  Cipher FeedBack mode (CFB)</p>
<p>  Counter mode (CTR)</p>
</li>
<li><p>Authentication of messages:<br>  CMAC</p>
</li>
<li><p>Both confidentiality and authentication:<br>  CCM and GCM</p>
</li>
</ul>
<h2 id="CBC"><a href="#CBC" class="headerlink" title="CBC"></a>CBC</h2><p><strong>Encryption</strong></p>
<p>c<sub>0</sub> = IV<br>c<sub>i</sub> = E<sub>k</sub> (m<sub>i</sub> ⊕ c<sub>i-1</sub>), for i ≥ 1</p>
<blockquote>
<p>The Initialization Vector (IV) ensures that two encryptions of the same ptx produce different ctxs</p>
</blockquote>
<p><strong>Decryption</strong></p>
<p>m<sub>i</sub> = D<sub>k</sub> (c<sub>i</sub>) ⊕ c<sub>i-1</sub>, for i ≥ 1</p>
<h2 id="Stream-Based-Models"><a href="#Stream-Based-Models" class="headerlink" title="Stream Based Models"></a>Stream Based Models</h2><p>Given a plaintext message m∈M as a sequence of blocks m=<m1, m2,="" .="" ,=""> the CFB, OFB and CTR modes of operation generate a key stream k1, k2, k3 . . . (each key has the size of a block) to mask the ptx m: ci = mi ⊕ ki , for i ≥ 1</m1,></p>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Cryptography Part I]]></title>
      <url>/2018/03/15/Cryptography-Part-I/</url>
      <content type="html"><![CDATA[<h1 id="Feb-26-Introduction-to-Cryptography"><a href="#Feb-26-Introduction-to-Cryptography" class="headerlink" title="Feb 26 Introduction to Cryptography"></a>Feb 26 Introduction to Cryptography</h1><h2 id="Instructor-Information"><a href="#Instructor-Information" class="headerlink" title="Instructor Information"></a>Instructor Information</h2><p>gerardo.pelosi@polimi.it</p>
<p>alessandro.barenghi@polimi.it</p>
<h2 id="Introduction-to-cryptography"><a href="#Introduction-to-cryptography" class="headerlink" title="Introduction to cryptography"></a>Introduction to cryptography</h2><p><strong>cryptography</strong>: how to design and implement cryptographic algorithms</p>
<p><strong>cryptanalysis</strong>: how to break a cipher (recover key/message), analyzing weak mathematical assumptions or advancements, bad implementations</p>
<h2 id="Modern-Cryptography"><a href="#Modern-Cryptography" class="headerlink" title="Modern Cryptography"></a>Modern Cryptography</h2><p><strong>Kerckhoff’s Principle</strong> A cryptosystem should be secure even if everything about the system is publicly known, except a single parameter (a.k.a., the cryptographic key)</p>
<h2 id="Security-Models"><a href="#Security-Models" class="headerlink" title="Security Models"></a>Security Models</h2><p><strong>Unconditional Security (Perfect Secrecy)</strong>: assumes an adversary with unlimited computing power and proves that she does not have enough information to infer either the cryptographic key or the original message </p>
<p><strong>Computational Security</strong>: assumes that any adversary is computationally limited (. . .as all adversaries are in practice). It gives a lower-bound on the computational complexity of the best methods available to break the cipher</p>
<h2 id="Security-Properties"><a href="#Security-Properties" class="headerlink" title="Security Properties"></a>Security Properties</h2><ol>
<li><p>Confidentiality[保密性]</p>
<p> Confidentiality provides encrypted information, thus making it unreadable to anyone except for the intended receivers, who are able to reverse the encryption</p>
</li>
<li><p>Authenticity[真实性]</p>
<p> Authenticity indicate that systems use to identify their users. It answers the questions of <em>Who is the user/counterpart?</em> and <em>is the user/counterpart really who she claims herself to be?</em></p>
<blockquote>
<p>When a system includes a communication protocol:</p>
<ul>
<li><p>The parties may need to identify themselves (<strong>entity authentication</strong>)</p>
</li>
<li><p>The parties want to make sure that data is really exchanged between the intended endpoints (i.e., No-one in middle is masquerading as one of them) (<strong>data origin authentication</strong>)</p>
</li>
</ul>
</blockquote>
</li>
<li><p>Data integrity[完整性]</p>
<p> Data integrity guarantees that data has not been tampered with.(Insertion/Replacement/Deletion)</p>
<blockquote>
<p>Data Authentication (data origin authentication + data integrity)</p>
<ul>
<li><p>data origin authentication (the fact that you know who the sender is)</p>
</li>
<li><p>data integrity (the fact that data has not been modified)</p>
</li>
</ul>
</blockquote>
</li>
<li><p>Non-repudiation[不可否认性]</p>
<p> Non-repudiation prevents an entity from denying previous commitments or actions later on.</p>
</li>
</ol>
<h2 id="Basic-Terminology-and-Concepts"><a href="#Basic-Terminology-and-Concepts" class="headerlink" title="Basic Terminology and Concepts"></a>Basic Terminology and Concepts</h2><ol>
<li><p><strong>Alphabet A</strong>: a finite set of symbols</p>
<p> The binary alphabet, A={0, 1}, is the most common choice as any other alphabet can be encoded over it</p>
</li>
<li><p><strong>Message Space M</strong>: consists of set of strings over an alphabet</p>
</li>
<li><p><strong>Plain Text</strong>: an element of M</p>
</li>
<li><p><strong>Ciphertext Space C</strong>: consists of a set of strings over an alphabet (which may differ from the alphabet for M).</p>
</li>
<li><p><strong>iphertext</strong>: an element of C </p>
</li>
<li><p><strong>KeySpace K</strong>: a set of elements called keys.(a set of keys)</p>
</li>
<li><p><strong>Encryption Transformation</strong>: Given an element e∈K, the encryption transformation E<sub>e</sub> : M→C, uniquely determines a bijective map from M to C.</p>
</li>
<li><p><strong>Decryption transformation</strong>: Given an element d∈K, the decryption transformation E<sub>d</sub> : C→M, uniquely determines a bijective map from C to M.</p>
</li>
<li><p><strong>Cryptoscheme</strong>: <a, m,="" c,="" k,="" {e<sub="">e : e ∈ K}, {D<sub>d</sub> : d ∈ K}&gt;</a,></p>
</li>
</ol>
<h2 id="Cryptographic-Paradigms"><a href="#Cryptographic-Paradigms" class="headerlink" title="Cryptographic Paradigms"></a>Cryptographic Paradigms</h2><ol>
<li><p>Symmetric (or Secret-Key) Cryptosystem</p>
<p> Every user is bound to a single secret key, with fixed length, i.e. encryption E<sub>e</sub> and decryption D<sub>d</sub> algorithms use the same key: e = d</p>
<blockquote>
<p>There are two main strategies for defining E and D, which lead to</p>
<ul>
<li><p>Block ciphers: act on a fixed length plain/ciphertext (e.g., AES, 3DES2, CAST5, Camellia, Gost, BlowFish)</p>
</li>
<li><p>Stream ciphers: act on an arbitrary length plain/ciphertext (e.g., RC4, Trivium, A5/1, A5/2, A5/3)</p>
</li>
</ul>
</blockquote>
</li>
<li><p>Asymmetric (or Public-Key) Cryptosystem</p>
<p> Every user is bound to a key pair:</p>
<ul>
<li><p>Public Key e ∈ K: is employed to encrypt plaintexts (E<sub>e</sub> (m), m ∈ M). Can be known to everybody</p>
</li>
<li><p>Private Key d ∈ K: is employed to decrypt ciphertexts (D<sub>d</sub> (c), c ∈ D). Must be known to the recipient only (and rigorously kept secret from everybody else)</p>
<blockquote>
<p>The public key needs authentication to avoid identity theft. Which guarantee do we have that the public key is really bound to the intended user?</p>
</blockquote>
</li>
</ul>
</li>
<li><p>Digital Signatures and Certification Authorities (CAs)</p>
<p> To provide the Non-Repudiation service we need: Digital Signatures and Certification Authorities (CAs)</p>
<ul>
<li><p><strong>Digital Signature</strong></p>
<p>  A tool to authenticate the public key. It allows to verify the unambiguous association of a user to her public-key</p>
<ul>
<li><p>A digital signature can be obtained applying the decryption transformation(using his/her private key d) to the message m, which should be authenticated: s = D<sub>d</sub> (m)</p>
</li>
<li><p>Everyone can check the validity of the signed message <m,s> (by the public key e) through checking whether E<sub>e</sub> (s) = m or not, as e is a publicly known value</m,s></p>
<blockquote>
<p>非对称加密的原理就好像有一把锁，每个人都可以用一把钥匙（公钥e）锁上，但是要想开这把锁，必须用一把特殊的钥匙（私钥d）开锁，而数字签名的原理刚好相反，一个用户需要向所有的用户展示自己的身份，最好的办法就是他举起他的钥匙大喊，“看！这唯一的一把私钥在我手上”。而在计算机科学的领域，他的做法就是将一条消息解密（这是只有拥有私钥的人才能办得到的事情！）然后向每个人公布解密后的消息，每个人都可以拿到他解密后的消息s和原来的消息m，通过公钥加密s后可以得到m，就证明了这个私钥用户的身份。</p>
</blockquote>
</li>
</ul>
</li>
<li><p><strong>Certification Authority (CA)</strong></p>
<p>  An independent third party (that all users trust) certifies the binding of a public-key to the identity of the corresponding user。</p>
<p>  The CA digitally signs a document (<strong>Digital Certificate</strong>) saving in public repositories, containing</p>
<ul>
<li><p>The identity of the user</p>
</li>
<li><p>The public-key of the user</p>
</li>
<li><p>Metadata (e.g., expiration date, CA name, etc…)</p>
<p>The assumption is that everybody knows the public keys of the CAs, thus every certificate can be checked through verifying a CA signature</p>
</li>
</ul>
</li>
<li><p><strong>Identity Based Cryptosystem</strong></p>
<p>  A Public-Key system where the User Identity is employed to uniquely derive the public key.</p>
<ul>
<li><p>Identity: any previously recognized and publicly known piece of information bound to a specified user (e.g., a SSN, an email address, passport No., driving licence No., position in a company)</p>
</li>
<li><p>Public Key: is uniquely derived from the Identity chosen by the user. May be known to everybody</p>
</li>
<li><p>Private Key: is released to each user by a Trusted Authority (TA) who combines the user Identity and a master secret parameter to compute it</p>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="Attacks-on-Cryptoscheme"><a href="#Attacks-on-Cryptoscheme" class="headerlink" title="Attacks on Cryptoscheme"></a>Attacks on Cryptoscheme</h2><p><strong>Basic assumptions: Kerckhoff’s principle</strong></p>
<p>The alphabet A, the structure of the plaintexts (i.e., the form of M) and the details of the encryption/decryption algorithms are known</p>
<p><strong>Brute force attack (Exhaustive key search)</strong></p>
<p>Given a ciphertext, it checks <strong>all possible keys</strong> until the correct one is found. The attacker must be able to distinguish the correct plaintext from a valid but incorrect one</p>
<p><strong>Categrories</strong></p>
<ul>
<li><p>Ciphertext-only attack (COA)</p>
<p>  The attacker knows the ciphertext of a number of messages encrypted with same key (he doesn’t known any plaintext)</p>
</li>
<li><p>Known-plaintext attack (KPA)</p>
<p>  The attacker knowns plain-ciphertext pairs, encrypted with same key</p>
</li>
<li><p>Chosen-plaintext attack (CPA)</p>
<p>  The attacker chooses a number of plaintexts to be encrypted (all with the same unknown key) and obtains the corresponding ciphertexts</p>
</li>
</ul>
<h1 id="Mar-1-Historical-Ciphers"><a href="#Mar-1-Historical-Ciphers" class="headerlink" title="Mar 1 Historical Ciphers"></a>Mar 1 Historical Ciphers</h1><h2 id="Substitution-Ciphers"><a href="#Substitution-Ciphers" class="headerlink" title="Substitution Ciphers"></a>Substitution Ciphers</h2><ul>
<li><p>Monoalphabetic Substitution Cipher(eg: Shift Cipher, The Gold Bug Cryptogram):</p>
<p>  There is a 1-to-1 correspondence between plaintext (ptx) and ciphertext (ctx) letters (also digrams, trigrams, etc). Thus, assuming the Kerchoff’s principle holds, a Ciphertext-Only attack (COA) easily reveals the key(Based on the statistic of frequency of each letter).</p>
<blockquote>
<p>The statistics of the plaintext language (frequency distribution of the symbols of Am in M) is known</p>
<p>The statistics of the ciphertext space, i.e., the frequency distribution of the symbols of Ac in C, can be computed over the available ciphertexts.</p>
<p>The substitution map (i.e., the key) can be inferred easily by matching the symbols occurring with similar frequencies</p>
<p>Most common letters: E,A,T,O,N,I…</p>
<p>Most common bigrams: TH,HE,IN,ER…</p>
<p>Most common trigrams:THE,ING,AND…</p>
</blockquote>
</li>
<li><p>Polyalphabetic Cipher(eg: Vigenere Cipher):</p>
<p>  The plaintext and ciphertext spaces include finite sequence of letters (words) from the alphabets A<sub>m</sub> and A<sub>c</sub> , respectively.</p>
<p>  The encryption transformation is defined as the application of “L &gt; 1 bijective maps”(L is the length of the key, may be reused and reused) between the two alphabets: µ0, µ1,… here each µ means a mapping from A<sub>m</sub> to A<sub>c</sub>.</p>
<blockquote>
<p>here it means that one µ is a crypto-system that mapping A to C, B to D … so the keyspace is (|A<sub>m</sub>|!)^L</p>
</blockquote>
<p>  The key k = (µ0, µ1, . . . , µL−1) is constituted by the L maps employed to encrypt the ciphertext</p>
<ul>
<li><p>Vigenere Cipher</p>
<p>  If the plain text is <strong>ATTACKATDAWN</strong></p>
<p>  Choose the key as LEMON and get the length same with plain text <strong>LEMONLEMONLE</strong></p>
<p>  Here each letter in the key noted as a sequence, for example, </p>
<p>  K1 = L, and the M1 is A, so the C1 is L(the 1st one noted by L).</p>
<p>  K2 = E, and the M2 is T, so the C2 is X(the 20st one noted by E).</p>
<p>  … …</p>
<p>  And get the final cipher text LXFOPVEFRNHR</p>
<blockquote>
<p>The cipher is still easy to break with a Ciphertext Only Attack using Kasisky Test</p>
<p>It bases on the fact that two identical segments of 2 ≤ l ≤ L plaintext letters (l-gram), will be encrypted to the same sequence of l ciphertext letters (when properly aligned with the keyword)</p>
<p>Deduction: The distance d between two repeated sequences of l chars in the ciphertext may suggest a multiple of the key length L (find the GCD)</p>
</blockquote>
</li>
<li><p>Beale’s Cipher/Book Cipher</p>
</li>
</ul>
</li>
</ul>
<h2 id="Permutation-Ciphers-Transposition-Cipher"><a href="#Permutation-Ciphers-Transposition-Cipher" class="headerlink" title="Permutation Ciphers/Transposition Cipher"></a>Permutation Ciphers/Transposition Cipher</h2><p>The encryption transformation of this cipher consists of a permutation of the positions of the plaintext letters</p>
<blockquote>
<p>a permutation cipher is not equivalent to a substitution map as each plaintext letter may corresponds to multiple ciphertext letters depending on the position</p>
<p>COA may not effective, but KPA/CPA still work</p>
</blockquote>
<h2 id="Affine-Ciphers"><a href="#Affine-Ciphers" class="headerlink" title="Affine Ciphers"></a>Affine Ciphers</h2><ul>
<li>The Hill Cipher</li>
</ul>
<h2 id="Perfect-Secrecy"><a href="#Perfect-Secrecy" class="headerlink" title="Perfect Secrecy"></a>Perfect Secrecy</h2><p>A perfectly secret cipher should be unbreakable regardless of the (computational) effort thrown at it This implies that the ciphertext alone provides no information (no clue) to an attacker</p>
<p>A perfectly secure cipher is proven to be resistant to COAs, KPAs, and CCA(2)s.</p>
<blockquote>
<p>Definition</p>
<p>A symmetric-key cryptosystem is Perfectly Secure if the ciphertext does not reveal any information about the plaintext</p>
<p>Pr(P = m|C = c) = Pr(P = m), ∀m ∈ M, c ∈ C</p>
<p>LEMMA1: Pr(C = c|P = m) = Pr(C = c), ∀m ∈ M, c ∈ C</p>
<p>LEMMA2: Given a Perfectly Secure symmetric key cryptosystem, the followingconditions hold |K| ≥ |C| ≥ |M|</p>
</blockquote>
<h2 id="Theorem-C-Shannon"><a href="#Theorem-C-Shannon" class="headerlink" title="Theorem (C. Shannon)"></a>Theorem (C. Shannon)</h2><p>Let <a, m,="" k,="" c,="" {e<sub="">k (), k ∈ K}, {D<sub>k</sub> (), k ∈ K}&gt; denote a symmetric key cryptosystem where the keys are picked independently of plaintexts values and |K| = |C| = |M|, The cryptosystem is perfectly secure iff </a,></p>
<p>(i) every key is used with probability 1/|K| </p>
<p>(ii) ∀ (m, c)∈M×C there is a unique key k∈K s.t. E<sub>k</sub> (m)=c</p>
<h2 id="Vernam-Cipher-One-Time-Pad-OTP-一次性密码本"><a href="#Vernam-Cipher-One-Time-Pad-OTP-一次性密码本" class="headerlink" title="Vernam Cipher/One-Time-Pad (OTP)[一次性密码本]"></a>Vernam Cipher/One-Time-Pad (OTP)[一次性密码本]</h2><ul>
<li><p>Modified Shift Cipher</p>
<p>  To encrypt plain text [This is an example]</p>
<p>  Using the OTP of [MASKL NSFLD FKJPQ]</p>
<p>  First transform two strings into numbers</p>
<p>  This is an example → 19 7 8 18 8 18 0 13 4 23 0 12 15 11 4</p>
<p>  MASKL NSFLD FKJPQ → 12 0 18 10 11 13 18 5 11 3 5 10 9 15 16</p>
<p>  Sum them up and get</p>
<p>  31 7 26 28 19 31 18 18 15 26 5 22 24 26 20</p>
<p>  Mod 26 get</p>
<p>  5 7 0 2 19 5 18 18 11 0 5 22 24 0 20</p>
<p>  Transform back to English and get</p>
<p>  FHACTFSSLAFWYAU</p>
<blockquote>
<p>The aformentioned OTP system employed with binary keys and messages is the most effective implementation of a perfectly secure cryptoscheme</p>
<p>This system is perfectly secure (M=C=K={0, . . . , 25}^5; ptxs and keys are independent):</p>
<p>each key is chosen with uniform probability ⇒ Pr(K = k) = 1/26^5</p>
<p>for each ptx-ctx pair <m, c=""> there is a unique key: k<sub>i</sub>=(c<sub>i</sub>−m<sub>i</sub>) mod 26, ∀ i</m,></p>
</blockquote>
</li>
</ul>
<h2 id="Computationally-secure-ciphers"><a href="#Computationally-secure-ciphers" class="headerlink" title="Computationally secure ciphers"></a>Computationally secure ciphers</h2><h2 id="Entropy"><a href="#Entropy" class="headerlink" title="Entropy"></a>Entropy</h2><p>Definition</p>
<p>Let X be a random variable (generally means an alphabet) which takes values in {x1, x2, . . . xn} with probability distribution p<sub>i</sub>=Pr(X = x<sub>i</sub>), ∀ 1≤i≤n. The Entropy of X is defined as:</p>
<p>H(X) = −Sigma(i from 1 to n) p<sub>i</sub>log<sub>2</sub>p<sub>i</sub></p>
<p>assuming conventionally that p<sub>i</sub>log<sub>2</sub>p<sub>i</sub>=0, if p<sub>i</sub>=0.</p>
<blockquote>
<p>H(X, Y )≤H(X)+H(Y ), the equality holds if X, Y are independent</p>
<p>H(X, Y )=H(Y )+H(X|Y );</p>
<p>H(X|Y )≤H(X), the equality holds if X, Y are independent</p>
<p>H(P|K, C)=0: if you know the ctx and the key you do not have any uncertainty in deriving the ptx</p>
<p>H(C|P,K)=0: if you know the ptx and the key you do not have any uncertainty in deriving the ctx</p>
<p>H(C, P,K)=H(P,K)+H(C|P,K)=H(P,K)=H(P)+H(K)</p>
<p>H(C, P,K)=H(K, C)+H(P|K, C)=H(K, C)</p>
</blockquote>
<ul>
<li><p>Key Equivocation</p>
<p>  It defines the amount of information (uncertainty) about the key, that you got by the knowledge of a ctx: H(K|C)</p>
<p>  H(K|C) = H(K, C) − H(C) = H(P) + H(K) − H(C)</p>
</li>
<li><p>Definition of Language Redundancy</p>
<p>  R<sub>L</sub> = 1 − H<sub>L</sub>/log<sub>2</sub>|M|</p>
</li>
<li><p>Unicity Distance</p>
<p>  It is the length of ciphertext words (i.e., the number of ctx) n=n0 such that the number of spurious keys is equal to zero,</p>
<p>  n0 ≈ log<sub>2</sub>|K|/(R<sub>L</sub>log<sub>2</sub>|M|)</p>
</li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> Cryptography </tag>
            
            <tag> Computer Security </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Algorithm and Complexity Analysis]]></title>
      <url>/2018/03/14/Algorithm-and-Complexity-Analysis/</url>
      <content type="html"><![CDATA[<p>EG: The Problem of sorting</p>
<p>Input: sequence (a1, a2, …, an) of numbers. </p>
<p>Output: permutation (a’1, a’2, …, a’n) such<br>    that a’1 &lt;= a’2 &lt;= … &lt;= a’n.</p>
<pre><code>///ONE SOLUTION: INSERTION SORT///

void insertion_sort(std::vector&lt;int&gt; &amp;A)
{
    int i;
    int j;
    int value;
    for(i=1; i&lt;A.size(); i++)
    {
       value = A[i];
       j = i-1;
       while(j&gt;=0 &amp;&amp; A[j]&gt;value)
       {
            A[j+1] = A[j];
            j = j-1; 
        }
       A[j+1] = value;
    }
}
</code></pre><ul>
<li>Running Time</li>
</ul>
<p>The running time depends on the input: an already sorted sequence is easier to sort.</p>
<p>Parameterize the running time by the size of the input, since short sequences are easier to sort than long ones.</p>
<p>Generally, we seek upper bounds on the running time, because everybody likes a guarantee.</p>
<ul>
<li>Kinds of Analysis</li>
</ul>
<p>Worst-case: (usually)</p>
<p>T(n) = maximum time of algorithm on any input of size n. </p>
<p>Average-case: (sometimes)</p>
<p>T(n) = expected time of algorithm over all inputs of size n.</p>
<p>Need assumption of statistical distribution of inputs.</p>
<p>Best-case: (bogus)</p>
<p>Cheat with a slow algorithm that works fast on some input.</p>
<ul>
<li>Machine-Independent Time</li>
</ul>
<p>What is insertion sort’s worst-case time?</p>
<p>It depends on the speed of our computer: </p>
<p>relative speed (on the same machine),</p>
<p>absolute speed (on different machines).</p>
<p>BIG IDEA:</p>
<p> Ignore machine-dependent constants. </p>
<p> Look at growth of T(n) as n → ∞ .</p>
<ul>
<li>Q-notation</li>
</ul>
<p>MATH: Q(g(n)) = { f (n) :there exist positive constants c1, c2, and   n0 such that 0 &lt;= c1g(n) &lt;= f (n) &lt;= c2g(n) for all n &gt;= n0 }</p>
<p>ENGINEERING: Drop low-order terms; ignore leading constants.Example: 3n^3 + 90n^2 – 5n + 6046 = Q(n^3)</p>
<p>Here get back to the example of insertion analysis:<br>• Worst case: Input reverse sorted.<br>T(n)=Σ(j=2…n)Q(j)=Q(n^2</p>
<p>While in the Merge-Sort</p>
<p>MERGE-SORT A[1 . . n] 1. </p>
<ol>
<li><p>If n = 1, done.</p>
</li>
<li><p>Recursively sort A[ 1,…,[n/2] ] and A[ [n/2]+1,…,n ]</p>
</li>
<li><p>“Merge” the 2 sorted lists.</p>
</li>
</ol>
<pre><code>void merge_sort(std::vector&lt;int&gt; &amp;A)
{
    std::vector&lt;int&gt; A1;
    std::vector&lt;int&gt; A2;
    if (A.size()==1) return;
    for(int i=0; i&lt;A.size()/2; i++)
            A1.push_back(A[i]);
    for(int i=A.size()/2; i&lt;A.size(); i++)
            A2.push_back(A[i]);
    merge_sort(A1); 
    merge_sort(A2);
    A = merge(A1,A2);
}
</code></pre><p>The complexity of merge sort is</p>
<p>if n=1: T(n)=Q(1)</p>
<p>if n&gt;1: T(n)=2T(n/2) + Q(n)</p>
<p>Since there is lg(n) levels, and for eahc level the cost of merge is n so the total cost is nlg(n).</p>
<ul>
<li>O-Notation(Upper Bounds)</li>
</ul>
<p>We write f(n) = O(g(n)) if there exist constants c &gt; 0, n0 &gt; 0 such that 0 &lt;= f(n) &lt;= cg(n) for all n &gt;= n0.</p>
<p>O(g(n)) = { f(n) : there exist constants c &gt; 0, n0 &gt; 0 such that 0 &lt;= f(n) &lt;= cg(n) for all n &gt;= n0 }</p>
<p>[O(g(n)) noted a whole class of algorithms whos upper bound complexity  is O(g(n))]</p>
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/Algorithms.jpg" title="This is an example for time complexity in O">
<ul>
<li>Marco Substitution</li>
</ul>
<p>Convention: A set in a formula represents an anonymous function in the set.</p>
<pre><code>    EXAMPLE1:
        f(n)=n^3+O(n^2)
        MEANS
        f(n)=n^3+h(n)
        FOR SOME h(n) belongs to O(n^2)
</code></pre><pre><code>    EXAMPLE2:
        n^2+O(n)=O(n^2)
        MEANS
        FOR ANY f(n) belongs to O(n)
            n^2+f(n)=h(n)
            FOR SOME h(n) belongs to O(n^2)
</code></pre><ul>
<li>Omega-Notation</li>
</ul>
<p>Omega(g(n)) = { f(n) : there exist constants c &gt; 0, n0 &gt; 0 such that 0 &lt;= cg(n) &lt;= f(n) for all n &gt;= n0 }</p>
<ul>
<li>Boundary Conditions</li>
</ul>
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/BoundaryConditions.png">
<ul>
<li>Common Cases</li>
</ul>
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/CommonCase1.png">
<img src="/2018/03/14/Algorithm-and-Complexity-Analysis/CommonCase2.png">
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Algorithm </tag>
            
            <tag> Parallel Programming </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Jupyter Notebook of Machine Learning]]></title>
      <url>/2018/03/12/Jupyter-Notebook-of-Machine-Learning/</url>
      <content type="html"><![CDATA[<p>This is a studying ntoe in the process of the application of Jupyter Notebook in Machine Learning.</p>
<p>Starting from a basic example of the Iris-Analysis</p>
<pre><code>    # dataframe management
    import pandas as pd

    # numerical computation
    import numpy as np

    # visualization library
    import seaborn as sns
    sns.set(style=&quot;white&quot;, color_codes=True)
    sns.set_context(rc={&quot;font.family&quot;:&#39;sans&#39;,&quot;font.size&quot;:24,&quot;axes.titlesize&quot;:24,&quot;axes.labelsize&quot;:24})


    # import matplotlib and allow it to plot inline
    import matplotlib.pyplot as plt
    %matplotlib inline

    # seaborn can generate several warnings, we ignore them
    import warnings
    warnings.filterwarnings(&quot;ignore&quot;)

    # sklearn is a python library including a lot of machine learning models
    import sklearn

    # opencv is a tool to import image and do image analysis
    import cv2

    # Scipy is a tool to practice some scientific mathematical calculation
    import scipy

    # skimage is a tool to do image analysis
   import skimage
</code></pre><ul>
<li><p><a href="https://pandas.pydata.org/" target="_blank" rel="noopener">Pandas</a> is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.</p>
<p>Generally speaking, the basic load of information could be done by pandas function</p>
</li>
<li><p><a href="http://www.numpy.org/" target="_blank" rel="noopener">NumPy</a>’s main object is the homogeneous multidimensional array. It is a table of elements (usually numbers), all of the same type, indexed by a tuple of positive integers. In NumPy dimensions are called axes. The number of axes is rank.</p>
<p>For example NumPy could be used to return the max/min values of one column of values</p>
</li>
<li><p><a href="https://seaborn.pydata.org/" target="_blank" rel="noopener">Seaborn</a> is a Python visualization library based on matplotlib. It provides a high-level interface for drawing attractive statistical graphics.</p>
</li>
<li><p><a href="https://matplotlib.org/" target="_blank" rel="noopener">Matplotlib</a> is a Python 2D plotting library which produces publication quality figures in a variety of hardcopy formats and interactive environments across platforms. Matplotlib can be used in Python scripts, the Python and IPython shells, the Jupyter notebook, web application servers, and four graphical user interface toolkits.</p>
</li>
<li><p><a href="http://scikit-learn.org/stable/" target="_blank" rel="noopener">Sklearn</a> is a free software machine learning library for the Python programming language.[3] It features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.</p>
</li>
<li><p><a href="http://opencv-python-tutroals.readthedocs.io/en/latest/index.html" target="_blank" rel="noopener">OpenCV</a> (Open Source Computer Vision) is a library of programming functions mainly aimed at real-time computer vision.[1] Originally developed by Intel, it was later supported by Willow Garage then Itseez (which was later acquired by Intel). The library is cross-platform and free for use under the open-source BSD license.</p>
</li>
<li><p><a href="https://www.scipy.org/" target="_blank" rel="noopener">Scipy</a> is a Python-based ecosystem of open-source software for mathematics, science, and engineering.</p>
</li>
<li><p><a href="http://scikit-image.org/" target="_blank" rel="noopener">skimage</a> is a collection of algorithms for image processing. It is available free of charge and free of restriction. We pride ourselves on high-quality, peer-reviewed code, written by an active community of volunteers. </p>
</li>
</ul>
]]></content>
      
        
        <tags>
            
            <tag> Machine Learning </tag>
            
            <tag> Python </tag>
            
            <tag> Jupyter Notebook </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Game Concept Art Design]]></title>
      <url>/2018/01/31/Game-Concept-Art-Design/</url>
      <content type="html"><![CDATA[<p>This is a general gallery for the art design I made, as a raw material for future use.</p>
<ul>
<li>Photoshop Art Design</li>
</ul>
<ol>
<li><img src="/2018/01/31/Game-Concept-Art-Design/ArtDesign1.jpg" title="practice on PS">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/ArtDesign2.jpg" title="logo od Scarlet Games">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/ArtDesign3.png" title="Date Masamune">
</li>
</ol>
<ul>
<li>Paper Art Design</li>
</ul>
<ol>
<li><img src="/2018/01/31/Game-Concept-Art-Design/1.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/2.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/3.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/4.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/5.jpg">
</li>
<li><img src="/2018/01/31/Game-Concept-Art-Design/6.jpg">
</li>
</ol>
]]></content>
      
        
        <tags>
            
            <tag> Game Development </tag>
            
            <tag> Art Design </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Wechat Game Development]]></title>
      <url>/2018/01/25/Wechat-Game-Development/</url>
      <content type="html"><![CDATA[<p>This is a development journal for a simple wechat game.</p>
<p>Outside Link <a href="https://mp.weixin.qq.com/debug/wxagame/dev/" target="_blank" rel="noopener">WECHAT HELPER DOCUMENT</a></p>
]]></content>
      
        
        <tags>
            
            <tag> Game Development </tag>
            
            <tag> Wechat </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Linear Programming]]></title>
      <url>/2018/01/10/Linear-Programming/</url>
      <content type="html"><![CDATA[<h1 id="Linear-Progarmming"><a href="#Linear-Progarmming" class="headerlink" title="Linear Progarmming"></a>Linear Progarmming</h1><p>Algorithm in Primal Dual Simplex</p>
<pre><code>Procedure Simplex_Primal_Dual(A,b,c,x,unbounded,y) 
    {A:input matrix // b:known term vector}
    {c: cost vector // x: feasible solution}
    {y: optimal solution of D}
    //////////
    begin
    optimal:=false; unbounded:=false;
    I:={i: Aix=bi};
    {Select the active constraints}
    if I==None then grow_along(c,x,I,unbounded); 
    while not optimal or not unbounded do 
        begin
        {g means yita and e means yipxilun}
        if {gAI=c} has no solution then 
            begin compute e&lt;: AIe=0, ce=1; grow_along(e,x,I,unbounded); end;
        else if {gAI=c} has a solution and exists h: gh&lt;0 then 
            begin compute e: AIe=uh; grow_along(e,x,I,unbounded); end;
        else optimal:=true; 
        {the dual system has a solution: gAI=c, g&gt;=0} 
        end;
    end.
</code></pre>]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Foundations of Operations Research </tag>
            
            <tag> Linear Programming </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Graphs and Network Flows]]></title>
      <url>/2018/01/09/Graphs-and-Network-Flows/</url>
      <content type="html"><![CDATA[<h1 id="Defination"><a href="#Defination" class="headerlink" title="Defination"></a>Defination</h1><ul>
<li>G=(N,A)</li>
<li>Path</li>
<li>Closed Path</li>
<li>Simple Path: path with no repeated arcs</li>
<li>Elementary path: a path with no repeated nodes</li>
<li>Cycle</li>
<li>Hamilton Cycle: a cycle having all nodes in the G(N,A)</li>
<li>Eulerian Cycle: a cycle having all arcs in the G(N,A)</li>
</ul>
<h1 id="Undirected-graphs-spanning-tree-and-Hamiltonian-circuit"><a href="#Undirected-graphs-spanning-tree-and-Hamiltonian-circuit" class="headerlink" title="Undirected graphs: spanning tree and Hamiltonian circuit"></a>Undirected graphs: spanning tree and Hamiltonian circuit</h1><ul>
<li><p>Spanning tree: formulation and a solution algorithm</p>
<blockquote>
<p>  The algorithm we are considering iteratively builds a solution starting from the empty one, and at each new step adds a new arc to the set of those that had been chosen. Two criteria must be established to guarantee the correct functioning of the algorithm: <em>i) the order according to which we should select the arcs to be put in the solution;</em> <em>ii) the criterion according to which we decide to add an arc to those already existing.</em></p>
<p>  i) Considering the order, we are guided by arc weights. So we begin by considering the arcs with lighter weight and end with the heavier ones.</p>
<p>  ii) An arc is added to the current solution only if the set of arcs, so augmented, can be part of a feasible solution. In the considered case this means that the arc added to the solution must not form cycles with the chosen arcs. Otherwise, we would come to a redundant solution.</p>
</blockquote>
</li>
<li><p>Minimum cost Hamiltonian circuit</p>
<blockquote>
<p>  Traveling Salesperson Problem</p>
</blockquote>
</li>
</ul>
<h1 id="Graph-connection-search-algorithm"><a href="#Graph-connection-search-algorithm" class="headerlink" title="Graph connection: search algorithm"></a>Graph connection: search algorithm</h1><p>Property: path or cut</p>
<p>Let there be a digraph G=(N,A) with s and t∈N. Only one of the following statements is valid:</p>
<p><em>i) there exists a path directed from s to t</em></p>
<p><em>ii) there exists a cut (Ns, Nt) such that s∈Ns and t∈Nt, and there exist no arcs being in accordance with the cut, that is to say all arcs (i,j)∈A crossing the cut have i∈Nt and j∈Ns</em></p>
<p>A simple but extremely important algorithm is the one performing the search of digraph G starting from a root node s. The algorithm restores a vector of predecessors. The predecessor P[i] of a node i provides the immediately preceding node i in the path directed from s to i. If at the end of the algorithm a node has predecessor equal to zero, this means that the node is not reachable from r.</p>
<p>Algorithms</p>
<pre><code>Procedure Search (G=(N,A),s,P): 
    begin
        for i := 1 to n do P[i] :=0; P[s] := s; Q := {s}; 
        {initialization, s is the start point} 
        repeat
            select i from Q; Q:=Q\{i};     
            {selection and removal of a node from Q} 
            for each (i,j) ∈ FS(i) do
                if P[j]=0
                    then 
                        begin P[j]:=i; 
                        Q:=Q∪{j}
                    end; 
        until Q = ø
    end
</code></pre><h1 id="Shortest-Paths"><a href="#Shortest-Paths" class="headerlink" title="Shortest Paths"></a>Shortest Paths</h1><ul>
<li>Shortest-path tree algorithm on acyclic graphs<blockquote>
<p>  Let there be an acyclic weighted digraph G=(N,A). Note that both application examples seen above give rise to a graph of this type. In order to verify whether a graph is acyclic, we just need to check if it is possible to renumber the graph nodes so that <em>if (i,j)∈A then i&lt;j</em>.</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>Procedure Topological_numbering(N,A,φ,x) 
    begin
        if ∃ i∈N: BS(i)=ø 
            {i is the root node, with no BS}
            then φ(i)=x; 
            Topological_numbering(N\{i}, A\FS(i),x+1)
        else if N≠ø 
            then return(&quot;Non-acyclic graph&quot;) 
    end.
</code></pre><blockquote>
<p>  From now on we assume G to be topologically numbered. Wishing to find the shortest-path tree with root 1, we can proceed by induction. We associate with each node i a label d[i] providing the length of the shortest path from 1 to i. A possible algorithm proceeds according to the following inductive rule:</p>
<p>  d[1] = 0;</p>
<p>  d[k] = min {d[i] + c_ik, i=1,…,k-1}, k=2,…,n.</p>
</blockquote>
<ul>
<li>Shortest-path tree algorithm on acyclic graphs (II)<blockquote>
<p>  A further and equivalent method visits the forward stars of each node. In this case, node labels are gradually updated as a better route is found. At the beginning, except for node 1 whose label is definitively fixed at value 0, labels are set equal to a very high value, such that any path from 1 to the node in question is shorter than that value.</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>    Procedure SPT_Acyclic (P,d) 
        begin
            P[1]:=1; d[1]:=0; 
            {P note the BS ndoe and d note the cost from root to this node}
            for i:=2 to n 
                do 
                    begin 
                        P[i]:=1; 
                        d[i]:=M 
                    end; 
            {Initialization}

            for i:=1 to n-1 do
                for each (i,j)∈FS(i) 
                    do
                        if d[i]+cij &lt; d[j] 
                            then 
                                begin 
                                    P[j]:=i; 
                                    d[j]:=d[i]+cij 
                                end
        end
</code></pre><ul>
<li>Dijkstra’s algorithm<blockquote>
<p>  We are now going to present an algorithm which, under appropriate hypotheses, behaves like SPT_Acyclic on non-acyclic graphs as well. The algorithm uses a set Q into which are introduced nodes whose forward star must be explored. <strong>Initially Q contains only the root node. Every time a node label is updated, the node, if not already there, is introduced into Q. The key instruction of the algorithm is the selection from Q of the node from which the graph search is to be continued. In the case of the SPT_Acyclic algorithm nodes were examined according to the topological ordering given by the numbering. In order to have the certainty of a similar behavior, and in particular the certainty that an examined node will never be introduced into Q again, the algorithm examines each time the node i having the smallest d[i] label.</strong></p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>    Procedure SPT_Dijkstra (r,P,d) 
        begin
            for i:=1 to n 
                do 
                    begin 
                        P[i]:=r; 
                        d[i]:=M;
                        {P note the BS node and d note the distance to this node}
                        {M is a relative big value, to be more specific, infinite}
                    end; 
            d[r]:=0; Q:={r}; 
            {initialization} 
        repeat
            select i from Q such that d[i]=min{d[h]: h∈Q}; 
            {smallest label node is selected} 
            Q:=Q\{i};
            for each (i,j)∈FS(i) 
                do
                    if d[i]+cij &lt; d[j] 
                        then
                            begin 
                                P[j]:=i; 
                                d[j]:=d[i]+cij; 
                                if j∈Q 
                                    then Q:=Q∪{j} 
                                end 
        until Q=∅
end.
</code></pre><ul>
<li>SPT_L (label correcting) algorithm<blockquote>
<p>  If the graph is not acyclic and some of the lengths associated with arcs are negative, the properties seen above do not hold any more. In particular, it is not necessarily true that a node, once selected from  Q, cannot enter it again.</p>
</blockquote>
</li>
</ul>
<blockquote>
<p>  Algorithms</p>
</blockquote>
<pre><code>    Procedure SPT_L (r,P,d) 
        begin
            for i:=1 to n 
                do begin P[i]:=r; d[i]:=M end; d[r]:=0; 
            {Initialization}
            repeat
                select i from Q; Q:=Q\{i}; 
                {insertions into and selections from Q are performed according to a FIFO policy} 
                {(Q is a queue)}
                for each (i,j)∈FS(i) do
                    if d[i]+cij &lt; d[j] then
                        begin
                            P[j]:=i; d[j]:=d[i]+cij; 
                            Q:=Q∪{j} 
                        end
            until Q=∅ end.
</code></pre><h1 id="Maximum-Flow"><a href="#Maximum-Flow" class="headerlink" title="Maximum Flow"></a>Maximum Flow</h1><p>Properties of flows and cuts</p>
<p>A partition of the nodes into two subsets (Ns,Nt) such that s∈Ns, and t∈Nt, is called s-t cut. The arcs crossing the cut (having one endpoint in Ns and the other in Nt) are themselves partitioned into two subsets: the set of direct arcs A+(Ns,Nt)={(i,j)∈A: i∈Ns,j∈Nt}, and the set of inverse arcs A- (Ns,Nt)={(i j)∈A: i∈Nt,j∈Ns}.</p>
<p>x(Ns,Nt)= ∑ xij((i,j)belongs to A+)– ∑ xij((i,j)belongs to A-).</p>
<ul>
<li>Augmenting path algorithm<br>We try to solve the problem incrementally: given a feasible flow, we test if it is improvable, i.e., if there exists a way of routing more flow from s to t. In order to discover if such flow augmentation is practicable, we introduce the residual graph of a flow x’. Given a graph G=(N,A) with capacity on the arcs u and a feasible flow x’, we define the residual graph GR(x’) = (N,A(x’)), where arcs are defined as follows:</li>
</ul>
<blockquote>
<p>  A(x’) = A+(x’) ∪ A-(x’),</p>
<p>  A+(x’) = {(i,j): (i,j)∈A, xij’&lt;uij}     // could increased</p>
<p>  A-(x’) = {(i,j): (j,i)∈A, xji’&gt;0}.      // could decreased</p>
</blockquote>
<p>Given a feasible flow x’, consider the residual graph GR(x’). Searching for a path from s to t, corresponding to a possible flow augmentation, two exclusive cases may occur:</p>
<p><em>i) there exists a path from s to t in GR(x’);</em></p>
<p><em>ii) there exists a cut (Ns,Nt) in GR(x’) such that A-(x’)(Ns,Nt) = ∅.</em></p>
<p>In the first case the flow x’ is not optimal and it can be increased by a strictly positive quantity, whereas in the second case x’ is optimal.</p>
<p>In the first case we found an augmenting path (on which the flow can be varied without violating the capacity constraints). Let Pst be such path. Now we define the maximum quantity of flow θ that can be sent on the detected path and that is defined by the minimum of residual capacities of the corresponding arcs on the original graph:</p>
<blockquote>
<p>  θ is the minimum value of the uij-x’ij : (i,j)∈A + (x’) intersect with Pst and x’ij: (i,j)∈A-(x’) intersect with Pst</p>
</blockquote>
<h1 id="Minimum-Cost-Flow"><a href="#Minimum-Cost-Flow" class="headerlink" title="Minimum Cost Flow"></a>Minimum Cost Flow</h1><p>The minimum cost flow problem is a problem of optimization on networks of a more general kind: both the maximum flow problem and the shortest-path tree problem may be viewed as particular cases of the minimum cost flow problem. A network flow is specified by a digraph G=(N,A); with each node i∈N we associate a value bi (called balance of the node); with each arc (i,j) we associate the unit cost cij and a capacity uij limiting the maximum quantity of flow that can transit. Balances at nodes regulate the flow on the network.</p>
]]></content>
      
        
        <tags>
            
            <tag> POLIMI </tag>
            
            <tag> Graphs </tag>
            
            <tag> Network Flows </tag>
            
            <tag> Algorithms </tag>
            
            <tag> Foundations of Operations Research </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Hexo Writing Formulation]]></title>
      <url>/2017/12/28/Hexo-Writing-Formulation/</url>
      <content type="html"><![CDATA[<p>This is a writing test for HEXO under the theme of material</p>
<h1 id="Block-Quote"><a href="#Block-Quote" class="headerlink" title="Block Quote"></a>Block Quote</h1><ul>
<li>Block without source<pre><code>{% blockquote %}
    Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.
    {% endblockquote %}
</code></pre><blockquote><p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque hendrerit lacus ut purus iaculis feugiat. Sed nec tempor elit, quis aliquam neque. Curabitur sed diam eget dolor fermentum semper at eu lorem.</p>
</blockquote>
</li>
</ul>
<ul>
<li>Block with source<pre><code>{% blockquote David Levithan, Wide Awake %}
    Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy.
    {% endblockquote %}
</code></pre><blockquote><p>Do not just seek happiness for yourself. Seek happiness for all. Through kindness. Through mercy.</p>
<footer><strong>David Levithan</strong><cite>Wide Awake</cite></footer></blockquote>
</li>
</ul>
<h1 id="Quote-from-Twitter"><a href="#Quote-from-Twitter" class="headerlink" title="Quote from Twitter"></a>Quote from Twitter</h1><pre><code>    {% blockquote @DevDocs https://twitter.com/devdocs/status/356095192085962752 %}
    NEW: DevDocs now comes with syntax highlighting. http://devdocs.io
    {% endblockquote %}
</code></pre><blockquote><p>NEW: DevDocs now comes with syntax highlighting. <a href="http://devdocs.io" target="_blank" rel="noopener">http://devdocs.io</a></p>
<footer><strong>@DevDocs</strong><cite><a href="https://twitter.com/devdocs/status/356095192085962752" target="_blank" rel="noopener">twitter.com/devdocs/status/356095192085962752</a></cite></footer></blockquote>
<h1 id="Quote-from-other-resource"><a href="#Quote-from-other-resource" class="headerlink" title="Quote from other resource"></a>Quote from other resource</h1><pre><code>    {% blockquote Seth Godin http://sethgodin.typepad.com/seths_blog/2009/07/welcome-to-island-marketing.html Welcome to Island Marketing %}
    Every interaction is both precious and an opportunity to delight.
    {% endblockquote %}
</code></pre><blockquote><p>Every interaction is both precious and an opportunity to delight.</p>
<footer><strong>Seth Godin</strong><cite><a href="http://sethgodin.typepad.com/seths_blog/2009/07/welcome-to-island-marketing.html" target="_blank" rel="noopener">Welcome to Island Marketing</a></cite></footer></blockquote>
<h1 id="Quote-an-Image-from-default-path"><a href="#Quote-an-Image-from-default-path" class="headerlink" title="Quote an Image from default path"></a>Quote an Image from default path</h1><pre><code>{% asset_img example.png This is an example image %}
</code></pre><img src="/2017/12/28/Hexo-Writing-Formulation/example.png" title="This is an example image">
<h1 id="Paragraph"><a href="#Paragraph" class="headerlink" title="Paragraph"></a>Paragraph</h1><pre><code>&gt; This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,
&gt; consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.
&gt;
&gt; &gt; And Here is a nested quote block.
&gt;
&gt; Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.
&gt; 
&gt; Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse
&gt; id sem consectetuer libero luctus adipiscing.
</code></pre><blockquote>
<p>This is a blockquote with two paragraphs. Lorem ipsum dolor sit amet,<br>consectetuer adipiscing elit. Aliquam hendrerit mi posuere lectus.</p>
<blockquote>
<p>And Here is a nested quote block.</p>
</blockquote>
<p>Vestibulum enim wisi, viverra nec, fringilla in, laoreet vitae, risus.</p>
<p>Donec sit amet nisl. Aliquam semper ipsum sit amet velit. Suspendisse<br>id sem consectetuer libero luctus adipiscing.</p>
</blockquote>
<h1 id="Unorder-List-Item"><a href="#Unorder-List-Item" class="headerlink" title="Unorder List Item"></a>Unorder List Item</h1><pre><code>*   This is a list item with two paragraphs.

    This is the second paragraph in the list item. You&#39;re
only required to indent the first line. Lorem ipsum dolor
sit amet, consectetuer adipiscing elit.

*   Another item in the same list.

    &gt; This is a quote.
</code></pre><ul>
<li><p>This is a list item with two paragraphs.</p>
<p>This is the second paragraph in the list item. You’re<br>only required to indent the first line. Lorem ipsum dolor<br>sit amet, consectetuer adipiscing elit.</p>
</li>
<li><p>Another item in the same list.</p>
<blockquote>
<p>This is a quote.</p>
</blockquote>
</li>
</ul>
<h1 id="Strongthen-text"><a href="#Strongthen-text" class="headerlink" title="Strongthen text"></a>Strongthen text</h1><pre><code>*single asterisks*

_single underscores_

**double asterisks**

__double underscores__
</code></pre><p><em>single asterisks</em></p>
<p><em>single underscores</em></p>
<p><strong>double asterisks</strong></p>
<p><strong>double underscores</strong></p>
<h1 id="Attach-a-link"><a href="#Attach-a-link" class="headerlink" title="Attach a link"></a>Attach a link</h1><pre><code>[Cesare&#39;s Homepage](https://cesaremjli.github.io/)
</code></pre><p><a href="https://cesaremjli.github.io/" target="_blank" rel="noopener">Cesare’s Homepage</a></p>
]]></content>
      
        
        <tags>
            
            <tag> Markdown Language </tag>
            
            <tag> HEXO </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Binary Trees]]></title>
      <url>/2017/12/19/Binary-Trees/</url>
      <content type="html"><![CDATA[<p>A short introduction of binary trees and its use in Python.</p>
<h1 id="Description-of-the-binary-tree-problems"><a href="#Description-of-the-binary-tree-problems" class="headerlink" title="Description of the binary tree problems"></a>Description of the binary tree problems</h1><p><strong>Preorder Traversals</strong></p>
<p>Count the node whenever it is the first time you reach it</p>
<p><strong>Inorder Traversals</strong></p>
<p>Count the node in the order just like spanning all the nodes in the horizontal plane</p>
<blockquote>
<p><a href="https://leetcode.com/problems/binary-tree-inorder-traversal/description/" target="_blank" rel="noopener">Description of one situation</a>:</p>
<blockquote>
<p>Given a binary tree, return the inorder traversal of its nodes’ values.</p>
<ul>
<li>algorithm</li>
</ul>
</blockquote>
</blockquote>
<pre><code>class TreeNode(object):
    def __init__(self, x):
        self.val = x
        self.left = None
        self.right = None

class Solution(object):
    def inorderTraversal(self, root):
        &quot;&quot;&quot;
        :type root: TreeNode
        :rtype: List[int]
        &quot;&quot;&quot;
        # curNode=root
        res=[1]
        curNode=root
        while curNode!=None:
            if curNode.left==None:
                res.append(curNode.val)
                print curNode.val
                curNode=curNode.right
            else:
                thisNode=curNode
                curNode=curNode.left
                nextNode=curNode
                while nextNode.right!=None:
                    nextNode=nextNode.right
                nextNode.right=thisNode
                thisNode.left=None
        return res[1:]
</code></pre><blockquote>
<p><a href="https://leetcode.com/problems/validate-binary-search-tree/description/" target="_blank" rel="noopener">Description of another situation</a>:</p>
<blockquote>
<p>Given a binary tree, determine if it is a valid binary search tree (BST).<br>Assume a BST is defined as follows:</p>
<ul>
<li>The left subtree of a node contains only nodes with keys less than the node’s key.</li>
<li>The right subtree of a node contains only nodes with keys greater than the node’s key.</li>
<li>Both the left and right subtrees must also be binary search trees.</li>
<li>algorithm</li>
</ul>
</blockquote>
</blockquote>
<pre><code>class TreeNode(object):
    def __init__(self, x):
        self.val = x
        self.left = None
        self.right = None

class Solution(object):
    def isValidBST(self, root):
        &quot;&quot;&quot;
        :type root: TreeNode
        :rtype: bool
        &quot;&quot;&quot;
        stack=[]
        pre=None
        cur=root
        while stack or cur:
            while cur:
                stack.append(cur)
                cur=cur.left
            top=stack.pop()
            if pre is not None and pre&gt;=top.val:
                return False
            pre=top.val
            cur=top.right
        return True
</code></pre><p><strong>Postorder Traversals</strong></p>
<p>Count the node whenever it is the last time  you leave it</p>
]]></content>
      
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> Binary Trees </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Python List]]></title>
      <url>/2017/12/09/Python-List/</url>
      <content type="html"><![CDATA[<p>This journal aims to describe a problem of PYTHON LIST. </p>
<p>The decription of the problem could be found <a href="https://leetcode.com/problems/remove-duplicates-from-sorted-list-ii/description/" target="_blank" rel="noopener">here</a> from LEETCODE.</p>
<h1 id="Description"><a href="#Description" class="headerlink" title="Description"></a>Description</h1><p>Given a sorted linked list, delete all nodes that have duplicate numbers, leaving only distinct numbers from the original list.</p>
<p>For example,<br>Given 1-&gt;2-&gt;3-&gt;3-&gt;4-&gt;4-&gt;5, return 1-&gt;2-&gt;5.<br>Given 1-&gt;1-&gt;1-&gt;2-&gt;3, return 2-&gt;3.</p>
<h1 id="CODE"><a href="#CODE" class="headerlink" title="CODE"></a>CODE</h1><pre><code># Definition for singly-linked list.
# class ListNode(object):
#     def __init__(self, x):
#         self.val = x
#         self.next = None

class Solution(object):
    def deleteDuplicates(self, head):
        &quot;&quot;&quot;
        :type head: ListNode
        :rtype: ListNode
        &quot;&quot;&quot;
        dummyHead=ListNode(0)
        dummyHead.next=head
        curNode=dummyHead

        while curNode!=None:
            nextNode=curNode.next
            if nextNode!=None and nextNode.next!=None and nextNode.val==nextNode.next.val:
                while nextNode!=None and nextNode.next!=None and nextNode.val==nextNode.next.val:
                    nextNode=nextNode.next
                # lastNode.next=nextNode.next
                curNode.next=nextNode.next;
            else:
                curNode=curNode.next

        return dummyHead.next
</code></pre>]]></content>
      
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> List </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[Unity Development Journal]]></title>
      <url>/2017/12/03/Unity-Development-Journal/</url>
      <content type="html"><![CDATA[<p>This journal aims to record the interesting methods and functions used in the <strong>Unity Game Development</strong>.</p>
<h1 id="Useful-External-Links"><a href="#Useful-External-Links" class="headerlink" title="Useful External Links"></a>Useful External Links</h1><p><a href="https://docs.unity3d.com/ScriptReference/index.html" target="_blank" rel="noopener">Unity Scripting API</a>: Unity official programmer API</p>
<p><a href="https://docs.unity3d.com/Manual/index.html" target="_blank" rel="noopener">Unity User Manual</a>: Unity official user manual</p>
<p><a href="https://cowlevel.net/feed" target="_blank" rel="noopener">Cow Level</a>: Game news and evaluations</p>
<p><a href="https://www.indienova.com/" target="_blank" rel="noopener">Indie Nova</a>: Game developments</p>
<h1 id="Unity-Development-Process"><a href="#Unity-Development-Process" class="headerlink" title="Unity Development Process"></a>Unity Development Process</h1><blockquote>
<p><em>Player</em></p>
<ul>
<li>Player Tranforms</li>
</ul>
</blockquote>
<pre class=" language-css"><code class="language-css">    <span class="token selector">void Start () 
    </span><span class="token punctuation">{</span>
        // Debug<span class="token number">.</span>Log <span class="token punctuation">(</span><span class="token string">"I AM "</span> + gameObject<span class="token number">.</span>name<span class="token punctuation">)</span><span class="token punctuation">;</span>

        _transform = GetComponent&lt;Transform><span class="token punctuation">(</span><span class="token punctuation">)</span> as Transform<span class="token punctuation">;</span>
        _animator = GetComponent&lt;Animator><span class="token punctuation">(</span><span class="token punctuation">)</span> as Animator<span class="token punctuation">;</span>
        _rigidbody = GetComponent&lt;Rigidbody<span class="token number">2</span>D><span class="token punctuation">(</span><span class="token punctuation">)</span> as Rigidbody<span class="token number">2</span>D<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token selector">void Update () 
    </span><span class="token punctuation">{</span>    
        <span class="token selector">m_horizontal = Math<span class="token class">.Sign</span>(Input<span class="token class">.GetAxis</span> ("Horizontal"));
        m_vertical = Math<span class="token class">.Sign</span>(Input<span class="token class">.GetAxis</span> ("Vertical"));    

        _transform<span class="token class">.position</span> = _transform<span class="token class">.position</span> +
            _transform<span class="token class">.right</span> * m_horizontal * m_speed * Time<span class="token class">.deltaTime</span> +
            _transform<span class="token class">.up</span> * m_vertical * m_speed * Time<span class="token class">.deltaTime</span>;

        if (Input<span class="token class">.GetKeyDown</span>(KeyCode<span class="token class">.J</span>))
        </span><span class="token punctuation">{</span>
            <span class="token comment" spellcheck="true">/* Whenever it detects some key on the keyboard, do Something */</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
</code></pre>
<blockquote>
<p><em>Animation</em> </p>
</blockquote>
<pre><code>Firstly, add an animation controller in the object to be attached with an animation.
Then drag the animation controller on to the game object
</code></pre><ul>
<li>Transition Control<pre class=" language-css"><code class="language-css">_animator<span class="token number">.</span><span class="token function">SetInteger</span><span class="token punctuation">(</span><span class="token string">"ParameterName"</span>,n<span class="token punctuation">)</span><span class="token punctuation">;</span>
_animator<span class="token number">.</span><span class="token function">SetBoolean</span><span class="token punctuation">(</span><span class="token string">"ParameterName"</span>,true/false<span class="token punctuation">)</span><span class="token punctuation">;</span>
_animator<span class="token number">.</span><span class="token function">SetTrigger</span><span class="token punctuation">(</span><span class="token string">"ParameterName"</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
</li>
</ul>
<blockquote>
<p><em>Game Object</em></p>
<ul>
<li>Instantiate Prefabs</li>
</ul>
</blockquote>
<pre><code>We could create game objects according to the predefined game objects. 
First create an empty game object, and then attach this scripts into this
game object.
</code></pre><pre class=" language-css"><code class="language-css">    <span class="token selector">public class InstantiateObj : MonoBehaviour </span><span class="token punctuation">{</span>

    <span class="token selector">public Transform prefab;

    public float timeDif=0<span class="token class">.5f</span>;
    private float nextTime;

    void Start () </span><span class="token punctuation">{</span>
        nextTime=<span class="token number">0.0</span>f<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token selector">void Update () </span><span class="token punctuation">{</span>
        <span class="token selector">if(Time<span class="token class">.time</span>>nextTime)</span><span class="token punctuation">{</span>
            <span class="token function">Instantiate</span><span class="token punctuation">(</span>prefab<span class="token punctuation">)</span><span class="token punctuation">;</span>
            nextTime=nextTime+timeDif<span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<blockquote>
<p><em>Sound Manager</em></p>
</blockquote>
<pre><code>Create an empty game object, and then add the sound scripts into the inspector, 
and then add different sound source and sound clips into the object. Meanwhile
we always put the audio listener onto the main camera.
</code></pre><ul>
<li><p>Sound Manager Scripts</p>
<pre class=" language-css"><code class="language-css"><span class="token selector">public class SoundManager : MonoBehaviour </span><span class="token punctuation">{</span>

<span class="token selector">public static SoundManager Instance;

<span class="token attribute">[Header("Sound Source")]</span>
public AudioSource as;
public AudioClip ac;
public AudioClip ac2;

<span class="token attribute">[Header("Soundtrack")]</span>
public AudioSource as_bgm_future;
public AudioClip ac_bgm_future;

<span class="token attribute">[Header("Soundtrack")]</span>
public AudioSource as_bgm_past;
public AudioClip ac_bgm_past;

float timeStamp;

// Use this for initialization
void Awake () </span><span class="token punctuation">{</span>
    <span class="token selector">if (Instance == null)
    </span><span class="token punctuation">{</span>
        Instance = this<span class="token punctuation">;</span>
        <span class="token function">DontDestroyOnLoad</span><span class="token punctuation">(</span>gameObject<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
    <span class="token selector">else
    </span><span class="token punctuation">{</span>
        <span class="token function">Destroy</span><span class="token punctuation">(</span>gameObject<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>

<span class="token selector">void Start()</span><span class="token punctuation">{</span>
    as_bgm_future<span class="token number">.</span>clip = ac_bgm_future<span class="token punctuation">;</span>
    as_bgm_past<span class="token number">.</span>clip = ac_bgm_past<span class="token punctuation">;</span>
    as_bgm_future<span class="token number">.</span><span class="token function">Play</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token selector">public void PlayeOneTime()</span><span class="token punctuation">{</span>
    as<span class="token number">.</span><span class="token function">PlayOneShot</span><span class="token punctuation">(</span>ac<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">}</span>

<span class="token selector">public void SwitchBGMandPitch(bool flag)</span><span class="token punctuation">{</span>
    <span class="token selector">as_bgm_past<span class="token class">.pitch</span>=1<span class="token class">.0f</span>;
    as_bgm_future<span class="token class">.pitch</span>=1<span class="token class">.0f</span>;
    if (flag)</span><span class="token punctuation">{</span>
        as_bgm_past<span class="token number">.</span><span class="token function">Pause</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        as_bgm_future<span class="token number">.</span><span class="token function">Play</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span><span class="token selector">else</span><span class="token punctuation">{</span>
        as_bgm_future<span class="token number">.</span><span class="token function">Pause</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        as_bgm_past<span class="token number">.</span><span class="token function">Play</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>    
<span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
</li>
<li>Whenever it is used in another scripts<pre class=" language-css"><code class="language-css">SoundManager<span class="token number">.</span>Instance<span class="token number">.</span><span class="token function">FutureTravelToPast</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
</li>
</ul>
<blockquote>
<p><em>Camera</em></p>
<ul>
<li>Camera Following</li>
</ul>
</blockquote>
<pre class=" language-css"><code class="language-css"><span class="token selector">public class CameraFollow : MonoBehaviour </span><span class="token punctuation">{</span>
    <span class="token selector">public GameObject player;
    private Vector3 offset;

    void Start () </span><span class="token punctuation">{</span>
        // offset = transform<span class="token number">.</span>position - player<span class="token number">.</span>transform<span class="token number">.</span>position<span class="token punctuation">;</span>
    <span class="token punctuation">}</span>

    <span class="token selector">void Update () </span><span class="token punctuation">{</span>
        Vector<span class="token number">3</span> playerPosition =player<span class="token number">.</span>transform<span class="token number">.</span>position<span class="token punctuation">;</span>
        // transform<span class="token number">.</span>position = player<span class="token number">.</span>transform<span class="token number">.</span>position + offset<span class="token punctuation">;</span>
        // if <span class="token punctuation">(</span>playerPosition<span class="token number">.</span>x&lt;-<span class="token number">2.3</span><span class="token punctuation">)</span>
        //     return<span class="token punctuation">;</span>
        transform<span class="token number">.</span>position = new Vector<span class="token number">3</span><span class="token punctuation">(</span>playerPosition<span class="token number">.</span>x,<span class="token number">0</span>,-<span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre>
<h1 id="Some-Tricks"><a href="#Some-Tricks" class="headerlink" title="Some Tricks"></a>Some Tricks</h1><blockquote>
<ol>
<li>The image size of the animation must by unified. Or some effects terrible would happen. All the images must by saved in .png with a tranparent background</li>
<li>Generally speaking, it is always a good idea to put <em>Player</em>, <em>Camera</em>, <em>Sound Manager</em> in a empty game object to manage them.</li>
</ol>
</blockquote>
<h2 id="Cesare-Dec-3-2017"><a href="#Cesare-Dec-3-2017" class="headerlink" title="Cesare Dec 3 2017"></a>Cesare Dec 3 2017</h2>]]></content>
      
        
        <tags>
            
            <tag> Unity </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[A Simple Python Depth First Search]]></title>
      <url>/2017/11/30/A-Simple-Python-Depth-First-Search/</url>
      <content type="html"><![CDATA[<p>Depth First Search in some real problems.</p>
<h1 id="Description-of-8-queens-Problem"><a href="#Description-of-8-queens-Problem" class="headerlink" title="Description of 8-queens Problem"></a>Description of 8-queens Problem</h1><p>Here is the description of <a href="https://leetcode.com/problems/n-queens/description/" target="_blank" rel="noopener">8-QUEEN PROBLEM</a>.</p>
<p>The n-queens puzzle is the problem of placing n queens on an n×n chessboard such that no two queens attack each other.</p>
<p>Given an integer n, return all distinct solutions to the n-queens puzzle.</p>
<p>Each solution contains a distinct board configuration of the n-queens’ placement, where ‘Q’ and ‘.’ both indicate a queen and an empty space respectively</p>
<h1 id="Solution-in-python-DFS"><a href="#Solution-in-python-DFS" class="headerlink" title="Solution(in python - DFS)"></a>Solution(in python - DFS)</h1><pre><code>    class Solution(object):
        def solveNQueens(self, n):
            &quot;&quot;&quot;
            :type n: int
            :rtype: List[List[str]]
            &quot;&quot;&quot;
            def DFS(queens, xy_dif,xy_sum):
                l=len(queens)
                if l==n:
                    result.append(queens)
                    return None
                for p in range(n):
                    if p not in queens and l-p not in xy_dif and l+p not in xy_sum:
                        DFS(queens+[p],xy_dif+[l-p],xy_sum+[l+p])
            result=[]
            DFS([],[],[])
            print result
            return [[&#39;.&#39;*i+&#39;Q&#39;+&#39;.&#39;*(n-i-1) for i in sol]for sol in result]
</code></pre>]]></content>
      
        
        <tags>
            
            <tag> Python </tag>
            
            <tag> Depth First Search </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
