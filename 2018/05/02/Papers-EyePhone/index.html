<!DOCTYPE html>
<html style="display: none;" lang="en">
    <head>
    <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
    <!--
        © Material Theme
        https://github.com/viosey/hexo-theme-material
        Version: 1.5.2 -->
    <script>
        window.materialVersion = "1.5.2"
        // Delete localstorage with these tags
        window.oldVersion = [
            'codestartv1',
            '1.3.4',
            '1.4.0',
            '1.4.0b1',
            '1.5.0'
        ]
    </script>

    <!-- dns prefetch -->
    <meta http-equiv="x-dns-prefetch-control" content="on">














    <!-- Meta & Info -->
    <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
    <meta name="renderer" content="webkit">
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

    <!-- Title -->
    
    <title>
        
            EyePhone | 
        
        Cesare&#39;s Workshop
    </title>

    <!-- Favicons -->
    <link rel="icon shortcut" type="image/ico" href="/img/star.png">
    <link rel="icon" href="/img/star.png">

    <meta name="format-detection" content="telephone=no"/>
    <meta name="description" itemprop="description" content="Graduate with double degrees of Tongji University and Polytechnic of Milan. Now doing master in Europe.:)">
    <meta name="keywords" content=",Machine Learning,CNN,EyePhone">
    <meta name="theme-color" content="#0097A7">

    <!-- Disable Fucking Bloody Baidu Tranformation -->
    <meta http-equiv="Cache-Control" content="no-transform" />
    <meta http-equiv="Cache-Control" content="no-siteapp" />

    <!--[if lte IE 9]>
        <link rel="stylesheet" href="/css/ie-blocker.css">

        
            <script src="/js/ie-blocker.en.js"></script>
        
    <![endif]-->

    <!-- Import lsloader -->
    <script>(function(){window.lsloader={jsRunSequence:[],jsnamemap:{},cssnamemap:{}};lsloader.removeLS=function(a){try{localStorage.removeItem(a)}catch(b){}};lsloader.setLS=function(a,c){try{localStorage.setItem(a,c)}catch(b){}};lsloader.getLS=function(a){var c="";try{c=localStorage.getItem(a)}catch(b){c=""}return c};versionString="/*"+(window.materialVersion||"unknownVersion")+"*/";lsloader.clean=function(){try{var b=[];for(var a=0;a<localStorage.length;a++){b.push(localStorage.key(a))}b.forEach(function(e){var f=lsloader.getLS(e);if(window.oldVersion){var d=window.oldVersion.reduce(function(g,h){return g||f.indexOf("/*"+h+"*/")!==-1},false);if(d){lsloader.removeLS(e)}}})}catch(c){}};lsloader.clean();lsloader.load=function(f,a,b,d){if(typeof b==="boolean"){d=b;b=undefined}d=d||false;b=b||function(){};var e;e=this.getLS(f);if(e&&e.indexOf(versionString)===-1){this.removeLS(f);this.requestResource(f,a,b,d);return}if(e){var c=e.split(versionString)[0];if(c!=a){console.log("reload:"+a);this.removeLS(f);this.requestResource(f,a,b,d);return}e=e.split(versionString)[1];if(d){this.jsRunSequence.push({name:f,code:e});this.runjs(a,f,e)}else{document.getElementById(f).appendChild(document.createTextNode(e));b()}}else{this.requestResource(f,a,b,d)}};lsloader.requestResource=function(b,e,a,c){var d=this;if(c){this.iojs(e,b,function(h,f,g){d.setLS(f,h+versionString+g);d.runjs(h,f,g)})}else{this.iocss(e,b,function(f){document.getElementById(b).appendChild(document.createTextNode(f));d.setLS(b,e+versionString+f)},a)}};lsloader.iojs=function(d,b,g){var a=this;a.jsRunSequence.push({name:b,code:""});try{var f=new XMLHttpRequest();f.open("get",d,true);f.onreadystatechange=function(){if(f.readyState==4){if((f.status>=200&&f.status<300)||f.status==304){if(f.response!=""){g(d,b,f.response);return}}a.jsfallback(d,b)}};f.send(null)}catch(c){a.jsfallback(d,b)}};lsloader.iocss=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.iofonts=function(f,c,h,a){var b=this;try{var g=new XMLHttpRequest();g.open("get",f,true);g.onreadystatechange=function(){if(g.readyState==4){if((g.status>=200&&g.status<300)||g.status==304){if(g.response!=""){h(g.response);a();return}}b.cssfallback(f,c,a)}};g.send(null)}catch(d){b.cssfallback(f,c,a)}};lsloader.runjs=function(f,c,e){if(!!c&&!!e){for(var b in this.jsRunSequence){if(this.jsRunSequence[b].name==c){this.jsRunSequence[b].code=e}}}if(!!this.jsRunSequence[0]&&!!this.jsRunSequence[0].code&&this.jsRunSequence[0].status!="failed"){var a=document.createElement("script");a.appendChild(document.createTextNode(this.jsRunSequence[0].code));a.type="text/javascript";document.getElementsByTagName("head")[0].appendChild(a);this.jsRunSequence.shift();if(this.jsRunSequence.length>0){this.runjs()}}else{if(!!this.jsRunSequence[0]&&this.jsRunSequence[0].status=="failed"){var d=this;var a=document.createElement("script");a.src=this.jsRunSequence[0].path;a.type="text/javascript";this.jsRunSequence[0].status="loading";a.onload=function(){d.jsRunSequence.shift();if(d.jsRunSequence.length>0){d.runjs()}};document.body.appendChild(a)}}};lsloader.tagLoad=function(b,a){this.jsRunSequence.push({name:a,code:"",path:b,status:"failed"});this.runjs()};lsloader.jsfallback=function(c,b){if(!!this.jsnamemap[b]){return}else{this.jsnamemap[b]=b}for(var a in this.jsRunSequence){if(this.jsRunSequence[a].name==b){this.jsRunSequence[a].code="";this.jsRunSequence[a].status="failed";this.jsRunSequence[a].path=c}}this.runjs()};lsloader.cssfallback=function(e,c,b){if(!!this.cssnamemap[c]){return}else{this.cssnamemap[c]=1}var d=document.createElement("link");d.type="text/css";d.href=e;d.rel="stylesheet";d.onload=d.onerror=b;var a=document.getElementsByTagName("script")[0];a.parentNode.insertBefore(d,a)};lsloader.runInlineScript=function(c,b){var a=document.getElementById(b).innerText;this.jsRunSequence.push({name:c,code:a});this.runjs()}})();</script>

    <!-- Import queue -->
    <script>function Queue(){this.dataStore=[];this.offer=b;this.poll=d;this.execNext=a;this.debug=false;this.startDebug=c;function b(e){if(this.debug){console.log("Offered a Queued Function.")}if(typeof e==="function"){this.dataStore.push(e)}else{console.log("You must offer a function.")}}function d(){if(this.debug){console.log("Polled a Queued Function.")}return this.dataStore.shift()}function a(){var e=this.poll();if(e!==undefined){if(this.debug){console.log("Run a Queued Function.")}e()}}function c(){this.debug=true}}var queue=new Queue();</script>

    <!-- Import CSS -->
    
        <style id="material_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_css","/css/material.min.css?Z7a72R1E4SxzBKR/WGctOA==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
        <style id="style_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("style_css","/css/style.min.css?MKetZV3cUTfDxvMffaOezg==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>

        
            
                <style id="prettify_css"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_css","/css/prettify.min.css?zp8STOU9v89XWFEnN+6YmQ==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
                <style id="prettify_theme"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("prettify_theme","/css/prettify/vibrant-ink.min.css?e5E/qqGcGveS7VTH4M896w==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>
            
        

    

    

    <!-- Config CSS -->

<!-- Other Styles -->
<style>
  body, html {
    font-family: Roboto, "Helvetica Neue", Helvetica, "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei", "微软雅黑", Arial, sans-serif;
    overflow-x: hidden !important;
  }
  
  code {
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
  }

  a {
    color: #00838F;
  }

  .mdl-card__media,
  #search-label,
  #search-form-label:after,
  #scheme-Paradox .hot_tags-count,
  #scheme-Paradox .sidebar_archives-count,
  #scheme-Paradox .sidebar-colored .sidebar-header,
  #scheme-Paradox .sidebar-colored .sidebar-badge{
    background-color: #0097A7 !important;
  }

  /* Sidebar User Drop Down Menu Text Color */
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:hover,
  #scheme-Paradox .sidebar-colored .sidebar-nav>.dropdown>.dropdown-menu>li>a:focus {
    color: #0097A7 !important;
  }

  #post_entry-right-info,
  .sidebar-colored .sidebar-nav li:hover > a,
  .sidebar-colored .sidebar-nav li:hover > a i,
  .sidebar-colored .sidebar-nav li > a:hover,
  .sidebar-colored .sidebar-nav li > a:hover i,
  .sidebar-colored .sidebar-nav li > a:focus i,
  .sidebar-colored .sidebar-nav > .open > a,
  .sidebar-colored .sidebar-nav > .open > a:hover,
  .sidebar-colored .sidebar-nav > .open > a:focus,
  #ds-reset #ds-ctx .ds-ctx-entry .ds-ctx-head a {
    color: #0097A7 !important;
  }

  .toTop {
    background: #757575 !important;
  }

  .material-layout .material-post>.material-nav,
  .material-layout .material-index>.material-nav,
  .material-nav a {
    color: #757575;
  }

  #scheme-Paradox .MD-burger-layer {
    background-color: #757575;
  }

  #scheme-Paradox #post-toc-trigger-btn {
    color: #757575;
  }

  .post-toc a:hover {
    color: #00838F;
    text-decoration: underline;
  }

</style>


<!-- Theme Background Related-->

    <style>
      body{
        background-color: #F5F5F5;
      }

      /* blog_info bottom background */
      #scheme-Paradox .material-layout .something-else .mdl-card__supporting-text{
        background-color: #fff;
      }
    </style>




<!-- Fade Effect -->

    <style>
      .fade {
        transition: all 800ms linear;
        -webkit-transform: translate3d(0,0,0);
        -moz-transform: translate3d(0,0,0);
        -ms-transform: translate3d(0,0,0);
        -o-transform: translate3d(0,0,0);
        transform: translate3d(0,0,0);
        opacity: 1;
      }

      .fade.out{
        opacity: 0;
      }
    </style>


<!-- Import Font -->
<!-- Import Roboto -->

    <link href="https://fonts.googleapis.com/css?family=Roboto:300,400,500" rel="stylesheet">


<!-- Import Material Icons -->


    <style id="material_icons"></style><script>if(typeof window.lsLoadCSSMaxNums === "undefined")window.lsLoadCSSMaxNums = 0;window.lsLoadCSSMaxNums++;lsloader.load("material_icons","/css/material-icons.css?pqhB/Rd/ab0H2+kZp0RDmw==",function(){if(typeof window.lsLoadCSSNums === "undefined")window.lsLoadCSSNums = 0;window.lsLoadCSSNums++;if(window.lsLoadCSSNums == window.lsLoadCSSMaxNums)document.documentElement.style.display="";}, false)</script>




    <!-- Import jQuery -->
    
        <script>lsloader.load("jq_js","/js/jquery.min.js?qcusAULNeBksqffqUM2+Ig==", true)</script>
    

    <!-- WebAPP Icons -->
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="application-name" content="Cesare&#39;s Workshop">
    <meta name="msapplication-starturl" content="http://yoursite.com/2018/05/02/Papers-EyePhone/">
    <meta name="msapplication-navbutton-color" content="#0097A7">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-title" content="Cesare&#39;s Workshop">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon" href="/img/star.png">

    <!-- Site Verification -->
    
    

    <!-- RSS -->
    

    <!-- The Open Graph protocol -->
    <meta property="og:url" content="http://yoursite.com/2018/05/02/Papers-EyePhone/">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="EyePhone | Cesare&#39;s Workshop">
    <meta property="og:image" content="/img/star.png">
    <meta property="og:description" content="Graduate with double degrees of Tongji University and Polytechnic of Milan. Now doing master in Europe.:)">
    <meta property="og:article:tag" content="Machine Learning"> <meta property="og:article:tag" content="CNN"> <meta property="og:article:tag" content="EyePhone"> 

    
        <meta property="article:published_time" content="Wed May 02 2018 10:00:53 GMT+0200">
        <meta property="article:modified_time" content="Mon Aug 13 2018 11:25:04 GMT+0200">
    

    <!-- The Twitter Card protocol -->
    <meta name="twitter:card" content="summary_large_image">

    <!-- Add canonical link for SEO -->
    
        <link rel="canonical" href="http://yoursite.com/2018/05/02/Papers-EyePhone/index.html" />
    

    <!-- Structured-data for SEO -->
    
        


<script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "BlogPosting",
    "mainEntityOfPage": "http://yoursite.com/2018/05/02/Papers-EyePhone/index.html",
    "headline": "EyePhone",
    "datePublished": "Wed May 02 2018 10:00:53 GMT+0200",
    "dateModified": "Mon Aug 13 2018 11:25:04 GMT+0200",
    "author": {
        "@type": "Person",
        "name": "Cesare (MINGJU LI)",
        "image": {
            "@type": "ImageObject",
            "url": "/img/cesare.jpg"
        },
        "description": "Each question has an answer.,Or, will have an answer."
    },
    "publisher": {
        "@type": "Organization",
        "name": "Cesare&#39;s Workshop",
        "logo": {
            "@type":"ImageObject",
            "url": "/img/star.png"
        }
    },
    "keywords": ",Machine Learning,CNN,EyePhone",
    "description": "Graduate with double degrees of Tongji University and Polytechnic of Milan. Now doing master in Europe.:)",
}
</script>


    

    <!-- Analytics -->
    
    
    

    <!-- Custom Head -->
    

<link rel="stylesheet" href="/css/prism-duotone-space.css" type="text/css"><script src="/js/prism.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>


    
        <body id="scheme-Paradox" class="lazy">
            <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="material-layout  mdl-js-layout has-drawer is-upgraded">
                

                <!-- Main Container -->
                <main class="material-layout__content" id="main">

                    <!-- Top Anchor -->
                    <div id="top"></div>

                    
                        <!-- Hamburger Button -->
                        <button class="MD-burger-icon sidebar-toggle">
                            <span class="MD-burger-layer"></span>
                        </button>
                    

                    <!-- Post TOC -->

    
    <!-- Back Button -->
    <!--
    <div class="material-back" id="backhome-div" tabindex="0">
        <a class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon"
           href="#" onclick="window.history.back();return false;"
           target="_self"
           role="button"
           data-upgraded=",MaterialButton,MaterialRipple">
            <i class="material-icons" role="presentation">arrow_back</i>
            <span class="mdl-button__ripple-container">
                <span class="mdl-ripple"></span>
            </span>
        </a>
    </div>
    -->


    <!-- Left aligned menu below button -->
    
    
    <button id="post-toc-trigger-btn"
        class="mdl-button mdl-js-button mdl-button--icon">
        <i class="material-icons">format_list_numbered</i>
    </button>

    <ul class="post-toc-wrap mdl-menu mdl-menu--bottom-left mdl-js-menu mdl-js-ripple-effect" for="post-toc-trigger-btn" style="max-height:80vh; overflow-y:scroll;">
        <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#What’s-EyePhone"><span class="post-toc-number">1.</span> <span class="post-toc-text">What’s EyePhone</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Papers"><span class="post-toc-number">2.</span> <span class="post-toc-text">Papers</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Paper-Object-Detection-from-Video-Tubelets-with-Convolutional-Neural-Networks"><span class="post-toc-number">2.1.</span> <span class="post-toc-text">Paper: Object Detection from Video Tubelets with Convolutional Neural Networks</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#INTRO"><span class="post-toc-number">2.1.1.</span> <span class="post-toc-text">INTRO</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#METHOD"><span class="post-toc-number">2.1.2.</span> <span class="post-toc-text">METHOD</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Paper-Object-Detection-in-Videos-with-Tubelet-Proposal-Networks"><span class="post-toc-number">2.2.</span> <span class="post-toc-text">Paper: Object Detection in Videos with Tubelet Proposal Networks</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#INTRO-1"><span class="post-toc-number">2.2.1.</span> <span class="post-toc-text">INTRO</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Tubelet-proposal-networks-TPN"><span class="post-toc-number">2.2.2.</span> <span class="post-toc-text">Tubelet proposal networks TPN</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Paper-Fast-R-CNN"><span class="post-toc-number">2.3.</span> <span class="post-toc-text">Paper: Fast R-CNN</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#INTRO-2"><span class="post-toc-number">2.3.1.</span> <span class="post-toc-text">INTRO</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#R-CNN-Drawback"><span class="post-toc-number">2.3.2.</span> <span class="post-toc-text">R-CNN Drawback</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#FINE-TUNING"><span class="post-toc-number">2.3.3.</span> <span class="post-toc-text">FINE-TUNING</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Faster-R-CNN-advantages"><span class="post-toc-number">2.3.4.</span> <span class="post-toc-text">Faster R-CNN advantages</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Faster-R-CNN-architecture"><span class="post-toc-number">2.3.5.</span> <span class="post-toc-text">Faster R-CNN architecture</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Paper-R-CNN-Object-detection"><span class="post-toc-number">2.4.</span> <span class="post-toc-text">Paper: R-CNN: Object detection</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#INTRO-3"><span class="post-toc-number">2.4.1.</span> <span class="post-toc-text">INTRO</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Objection-Detection"><span class="post-toc-number">2.4.2.</span> <span class="post-toc-text">Objection Detection</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Paper-Selective-Search"><span class="post-toc-number">2.5.</span> <span class="post-toc-text">Paper: Selective Search</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#INTRO-分割与穷举"><span class="post-toc-number">2.5.1.</span> <span class="post-toc-text">INTRO 分割与穷举</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Related-Work"><span class="post-toc-number">2.5.2.</span> <span class="post-toc-text">Related Work</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#Selective-Search"><span class="post-toc-number">2.5.3.</span> <span class="post-toc-text">Selective Search</span></a></li></ol></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#Felzenswalb-Algorithm-in-image-segmentation"><span class="post-toc-number">2.6.</span> <span class="post-toc-text">Felzenswalb Algorithm in image segmentation</span></a></li></ol></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Another-idea-for-EyePhone"><span class="post-toc-number">3.</span> <span class="post-toc-text">Another idea for EyePhone</span></a></li></ol>
    </ul>
    




<!-- Layouts -->

    <!-- Post Module -->
    <div class="material-post_container">

        <div class="material-post mdl-grid">
            <div class="mdl-card mdl-shadow--4dp mdl-cell mdl-cell--12-col">

                <!-- Post Header(Thumbnail & Title) -->
                
    <!-- Paradox Post Header -->
    
        
            <!-- Random Thumbnail -->
            <div class="post_thumbnail-random mdl-card__media mdl-color-text--grey-50">
            <script type="text/ls-javascript" id="post-thumbnail-script">
    var randomNum = Math.floor(Math.random() * 19 + 1);

    $('.post_thumbnail-random').attr('data-original', '/img/random/material-' + randomNum + '.png');
    $('.post_thumbnail-random').addClass('lazy');
</script>

        
    
            <p class="article-headline-p">
                EyePhone
            </p>
        </div>





                
                    <!-- Paradox Post Info -->
                    <div class="mdl-color-text--grey-700 mdl-card__supporting-text meta">

    <!-- Author Avatar -->
    <div id="author-avatar">
        <img src="/img/cesare.jpg" width="44px" height="44px" alt="Author Avatar"/>
    </div>
    <!-- Author Name & Date -->
    <div>
        <strong>Cesare (MINGJU LI)</strong>
        <span>May 02, 2018</span>
    </div>

    <div class="section-spacer"></div>

    <!-- Favorite -->
    <!--
        <button id="article-functions-like-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon btn-like">
            <i class="material-icons" role="presentation">favorite</i>
            <span class="visuallyhidden">favorites</span>
        </button>
    -->

    <!-- Qrcode -->
    

    <!-- Tags (bookmark) -->
    
    <button id="article-functions-viewtags-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
        <i class="material-icons" role="presentation">bookmark</i>
        <span class="visuallyhidden">bookmark</span>
    </button>
    <ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-functions-viewtags-button">
        <li class="mdl-menu__item">
        <a class="post_tag-link" href="/tags/CNN/">CNN</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/EyePhone/">EyePhone</a></li><li class="mdl-menu__item"><a class="post_tag-link" href="/tags/Machine-Learning/">Machine Learning</a>
    </ul>
    

    <!-- Share -->
    
        <button id="article-fuctions-share-button" class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon">
    <i class="material-icons" role="presentation">share</i>
    <span class="visuallyhidden">share</span>
</button>
<ul class="mdl-menu mdl-menu--bottom-right mdl-js-menu mdl-js-ripple-effect" for="article-fuctions-share-button">
    

    

    <!-- Share Weibo -->
    
        <a class="post_share-link" href="http://service.weibo.com/share/share.php?appkey=&title=EyePhone&url=http://yoursite.com/2018/05/02/Papers-EyePhone/index.html&pic=http://yoursite.com/img/star.png&searchPic=false&style=simple" target="_blank">
            <li class="mdl-menu__item">
                Share to Weibo
            </li>
        </a>
    

    <!-- Share Twitter -->
    
        <a class="post_share-link" href="https://twitter.com/intent/tweet?text=EyePhone&url=http://yoursite.com/2018/05/02/Papers-EyePhone/index.html&via=Cesare (MINGJU LI)" target="_blank">
            <li class="mdl-menu__item">
                Share to Twitter
            </li>
        </a>
    

    <!-- Share Facebook -->
    
        <a class="post_share-link" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2018/05/02/Papers-EyePhone/index.html" target="_blank">
            <li class="mdl-menu__item">
                Share to Facebook
            </li>
        </a>
    

    <!-- Share Google+ -->
    
        <a class="post_share-link" href="https://plus.google.com/share?url=http://yoursite.com/2018/05/02/Papers-EyePhone/index.html" target="_blank">
            <li class="mdl-menu__item">
                Share to Google+
            </li>
        </a>
    

    <!-- Share LinkedIn -->
    

    <!-- Share QQ -->
    

    <!-- Share Telegram -->
    
</ul>

    
</div>

                

                <!-- Post Content -->
                <div id="post-content" class="mdl-color-text--grey-700 mdl-card__supporting-text fade out">
    
        <p>This blog aims to record some relative information about EYEPHONE.</p>
<h1 id="What’s-EyePhone"><a href="#What’s-EyePhone" class="headerlink" title="What’s EyePhone"></a>What’s EyePhone</h1><p>EyePhone is a personal built project, aims to help blind people with their cellphone to detect the obstacles on the road. EyePhone focus on the common road scenes in the city. It has a quite simple use - “Hold the phone, whenever there is a obstacle in the road, remind the user.”</p>
<blockquote>
<p>Obstacles could have following categrories: Stairs, Bicycle, Street Lights, Cars, Other People, and other obstacles.</p>
</blockquote>
<p>There are some basic idea of how to build this babe:)</p>
<p>Updated at 2018.5.2</p>
<ol>
<li><p><strong>Pure empirical method of CNN</strong>: We trust our CNN methods, and offer tons of data (input: images output: obstacles detected y/n) to train it, and later given specific input it could make a decision.</p>
</li>
<li><p><strong>Combine Machine Learning with Prior Knowledge</strong>: We have some prior knowledge in the obstacle detection, like when something is far it would be small in our sight, while close make it bigger in the sights. </p>
</li>
<li><p><strong>Combine CNN with RNN</strong>: This is a very promising idea while I have no idea of where to start now. I found one interesting fact occasionally, that in a badly scaled picture, sometimes it is hard even for human to find what’s in the picture. While it all the pictures are played fast, it would be easily found! (Imagine watching a badly scaled .gif picture!). So maybe we could combine CNN and RNN and contribute to a better performance. </p>
</li>
</ol>
<p>Updated at 2018.5.7 - Start from detection, and build the distance measure on the experience of object detection</p>
<ol>
<li><p><strong>Analysis based on the high precision images</strong>: use F R-CNN to analysis the position of the obstalces.</p>
</li>
<li><p><strong>Analysis based on the low precision images</strong>: use TPN for the temporal information.</p>
</li>
</ol>
<p>Generally speaking, according to the previous papers, it takes more or less 40 seconds to detect some obstacles in the picture. While here it is more promising to use the method with a low precision image and continous temporal information. It we could combine the knowledge of the conteinous temporal information into some sharing information, it would require a far more less computation.</p>
<p>Updated at 2018.5.10 - Maybe a detection will be good enought to get the Regions of Interests in the picture, and we could only train it to get the ability of distance detection.</p>
<ol>
<li><strong>Analysis based on SS</strong>: use machine learning methods train the model the ability of distance detection, hence there are two conditions we have to reach first. First, we have to make sure Select Search method is good enough to extract all the important information in the picture. Second, this method would have the advantages that it may need less information to train, this scale is handlable in a personal computer, while we have to make sure that we only analysis the RoI of greater weights. (Could we use a neural method to guide the selective search like we do in the AlphaZero?)</li>
</ol>
<h1 id="Papers"><a href="#Papers" class="headerlink" title="Papers"></a>Papers</h1><p>In this part, I would noted some useful information I found in some papers and their inspiration on this project. </p>
<h2 id="Paper-Object-Detection-from-Video-Tubelets-with-Convolutional-Neural-Networks"><a href="#Paper-Object-Detection-from-Video-Tubelets-with-Convolutional-Neural-Networks" class="headerlink" title="Paper: Object Detection from Video Tubelets with Convolutional Neural Networks"></a>Paper: Object Detection from Video Tubelets with Convolutional Neural Networks</h2><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/app/S04-07.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO"><a href="#INTRO" class="headerlink" title="INTRO"></a>INTRO</h3><p>Method1: Detect obstacles frame by frame</p>
<p>Method2: Combine Method1 with object tracking</p>
<p>The framework consists of two main modules: 1)a tubelet proposal module that combines object detection and object tracking for tubelet object proposal; 2) a tubelet classification and re-scoring module that performs spatial max-pooling for robust box scoring and temporal convolution for incorporating temporal consistency.</p>
<h3 id="METHOD"><a href="#METHOD" class="headerlink" title="METHOD"></a>METHOD</h3><p>Objects in videos show temporal and spatial consistency. The same object in adjacent frames has similar appearances and locations. Using either (object detectors or object trackers) existing object detection methods or object tracking methods alone cannot effectively solve the VID problem.</p>
<p>The combined model has the discriminative ability from object detectors and the temporal consistency from object trackers. It has 2 following </p>
<ul>
<li>The tubelet proposal module has 3 major steps: </li>
</ul>
<blockquote>
<p>1) image object proposal <strong>(每一帧都进行分析，通过一个算法，将总共可能出现的object的种类从一个很大的类缩减到一个小范围)</strong> </p>
<p>2) object proposal scoring <strong>（对于每个proposal进行分析，根据他们的confidence从几百个proposal进一步削减到几十个proposal）</strong></p>
<p>3) high-confidence object tracking <strong>（对于每一个高confidence的proposal，我们以某一帧为anchor，向前和向后进行track，为了防止track的物体漂移到别的物体或者背景上，当confidence低于某个threshold后停止tracking）</strong>.</p>
</blockquote>
<ul>
<li>Tubelet classification and rescoring has 2 steps: </li>
</ul>
<blockquote>
<p>1) Tubelet box perturbation and max-pooling <strong>（使用这种方法将多个tubelet box进行pooling得到某一帧的boxes）</strong></p>
<p>2) Temporal convolution and re-scoring <strong>（建立一个时序的temporal convolution network 每一个输入x为每一个tubelet box在不同时间【连续输入】的一个三维向量（detection score,tracking score,anchor offset）得到该tubelet box的prediction scores）</strong>.</p>
</blockquote>
<h2 id="Paper-Object-Detection-in-Videos-with-Tubelet-Proposal-Networks"><a href="#Paper-Object-Detection-in-Videos-with-Tubelet-Proposal-Networks" class="headerlink" title="Paper: Object Detection in Videos with Tubelet Proposal Networks"></a>Paper: Object Detection in Videos with Tubelet Proposal Networks</h2><p><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Kang_Object_Detection_in_CVPR_2017_paper.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO-1"><a href="#INTRO-1" class="headerlink" title="INTRO"></a>INTRO</h3><p>The contribution of this paper is that it propose a new deep learning framework that combines tubelet proposal generation and temporal classification with visual-temporal features. An efficient tubelet proposal generation algorithm is developed to generate tubelet proposals that capture spatiotemporal locations of objects in videos. A temporal LSTM model is adopted for classifying tubelet proposals with both visual features and temporal features. Such high-level temporal features are generally ignored by existing detection systems but are crucial for object detection in videos.</p>
<h3 id="Tubelet-proposal-networks-TPN"><a href="#Tubelet-proposal-networks-TPN" class="headerlink" title="Tubelet proposal networks TPN"></a>Tubelet proposal networks TPN</h3><ul>
<li>Preliminaries on ROI-pooling for regression</li>
</ul>
<p>FAST R-CNN/ROI POOLING</p>
<p>The object of this part is to use ROI-pooling finding the for a <em>t</em>, the corresponding b<sup>i</sup>=(x<sup>i</sup>,y<sup>i</sup>,w<sup>i</sup>,t<sup>i</sup>) denoting the ith box proposal(what could it be!) at time t, where x, y, w and h represent the two coordinates of the box center, width and height of the box proposal.</p>
<ul>
<li>Static object proposals as spatial anchors</li>
</ul>
<p>Let b<sup>i</sup>1 denote a static proposal of interest at time t =1. Particularly, to generate a tubelet proposal starting at b<sup>i</sup>1, visual features within the w-frame temporal window from frame 1 to w are pooled at the same location b<sup>i</sup>1 as r<sup>i</sup>1,r<sup>i</sup>2,…,r<sup>i</sup>w in order to generate the tubelet proposal. We call b<sup>i</sup>1 a “spatial anchor”.</p>
<p>The reason why we are able to pool multi-frame features from the same spatial location for tubelet proposals is that CNN feature maps at higher layers usually have large receptive fields. Even if visual features are pooled from a small bounding box, its visual context is far greater than the bounding box itself. Pooling at the same box locations across time is therefore capable of capturing large possible movements of objects.</p>
<ul>
<li>Supervisions for tubelet proposal generation</li>
</ul>
<p>Our goal is to generate tubelet proposals that have high object recall rates at each frame and can accurately track objects. Based on the pooled visual features r<sup>i</sup>1,r<sup>i</sup>2,…,r<sup>i</sup>w at box locations b<sup>i</sup>t, we train a regression network R(·) that effectively estimates the relative movements w.r.t. the spatial anchors.</p>
<p>Once we obtain such relative movements, the actual box locations of the tubelet could be easily inferred. Our key assumption is that the tubelet proposals should have consistent movement patterns with the ground-truth objects.</p>
<ul>
<li>Initialization for multi-frame regression layer</li>
</ul>
<h2 id="Paper-Fast-R-CNN"><a href="#Paper-Fast-R-CNN" class="headerlink" title="Paper: Fast R-CNN"></a>Paper: Fast R-CNN</h2><p><a href="https://arxiv.org/pdf/1504.08083.pdf" target="_blank" rel="noopener">Click here for the orginal text</a></p>
<h3 id="INTRO-2"><a href="#INTRO-2" class="headerlink" title="INTRO"></a>INTRO</h3><p>Object detection is a more challenging task compared with image classification. It has 2 primary challenges:</p>
<p>1) numerous candidate object locations (often called “proposals”) must be processed.<br>2) these candidates provide only rough localization that must be refined to achieve precise localization</p>
<p>While in this paper, based on the work of R-CNN, faster R-CNN has a better performance while at the same time decrease the amout of calculation in the whole process.</p>
<h3 id="R-CNN-Drawback"><a href="#R-CNN-Drawback" class="headerlink" title="R-CNN Drawback"></a>R-CNN Drawback</h3><p>1) Training is a multi-stage pipeline<br>2) Training is expensive in space and time<br>3) Object detection is slow</p>
<p>SPPnet(Spatial pyramid pooling networks) soleve the problem that <strong>R-CNN does not have sharing computation</strong>, it accelerates R-CNN.</p>
<h3 id="FINE-TUNING"><a href="#FINE-TUNING" class="headerlink" title="FINE-TUNING"></a>FINE-TUNING</h3><h3 id="Faster-R-CNN-advantages"><a href="#Faster-R-CNN-advantages" class="headerlink" title="Faster R-CNN advantages"></a>Faster R-CNN advantages</h3><p><a href="https://github.com/rbgirshick/fast-rcnn" target="_blank" rel="noopener">github source</a></p>
<ol>
<li>Higher detection quality (mAP) than R-CNN, SPPnet</li>
<li>Training is single-stage, using a multi-task loss</li>
<li>Training can update all network layers</li>
<li>No disk storage is required for feature caching</li>
</ol>
<h3 id="Faster-R-CNN-architecture"><a href="#Faster-R-CNN-architecture" class="headerlink" title="Faster R-CNN architecture"></a>Faster R-CNN architecture</h3><p>A Fast R-CNN network takes as input an entire image and a set of object proposals. The network first processes the whole image with several convolutional (conv) and max pooling layers to produce a conv feature map. Then, for each object proposal a region of interest (RoI) pooling layer extracts a fixed-length feature vector from the feature map. Each feature vector is fed into a sequence of fully connected (fc) layers that finally branch into two sibling output layers: one that produces softmax probability estimates over K object classes plus a catch-all “background” class and another layer that outputs four real-valued numbers for each of the K object classes. Each set of 4 values encodes refined bounding-box positions for one of the K classes</p>
<p>对于一个Faster R-CNN来说，输入为<strong>输入图片</strong>和<strong>相关区域（RoI）</strong>，输入图片通过一个CNN进行处理得到一个<strong>卷积特征图（conv feature map）</strong>，而RoI在这张feature map上找到对应的区域，每个相关区域可以被映射到一个固定长度的<strong>特征向量（feature vector）</strong>，这个feature vector会进入下一步的处理（一个fully connected layer），得到两个output：<br>1) softmax probability： K个object分类以及background class的可能性<br>2) per-class bounding box regression offsets： 对每个object class的bounding box位置预测（一个4维向量）</p>
<p>A Fast R-CNN network has two sibling output layers. The first outputs a discrete probability distribution (per RoI), p = (p<sub>0</sub>, . . . , p<sub>K</sub>), over K + 1 categories. As usual, p is computed by a softmax over the K+1 outputs of a fully connected layer. The second sibling layer outputs bounding-box regression offsets, t<sub>k</sub>(t<sup>k</sup><sub>x</sub>,t<sup>k</sup><sub>y</sub>,t<sup>k</sup><sub>w</sub>,t<sup>k</sup><sub>h</sub>) for each of the K object classes, indexed by k.t<sub>k</sub> specifies a scale-invariant translation and log-space height/width shift relative to an object proposal.</p>
<h2 id="Paper-R-CNN-Object-detection"><a href="#Paper-R-CNN-Object-detection" class="headerlink" title="Paper: R-CNN: Object detection"></a>Paper: R-CNN: Object detection</h2><p><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf?spm=5176.100239.blogcont55892.8.pm8zm1&amp;file=Girshick_Rich_Feature_Hierarchies_2014_CVPR_paper.pdf" target="_blank" rel="noopener">Click here for the orginal text</a><br><a href="https://blog.csdn.net/shenxiaolu1984/article/details/51066975" target="_blank" rel="noopener">CSDN Relative information</a></p>
<h3 id="INTRO-3"><a href="#INTRO-3" class="headerlink" title="INTRO"></a>INTRO</h3><p>TWO KEY INSIGHTS:</p>
<p>1) one can apply high-capacity convolutional neural networks (CNNs) to bottom-up region proposals in order to localize and segment objects<br>2) when labeled training data is scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, yields a significant performance boost.</p>
<p>Since in this thesis region proposals is combined with CNNs, this method is known as method R-CNN: Regions with CNN features. </p>
<p>TWO CHALLENGE AND THE CONTRIBUTIONS:</p>
<p>1) 速度: 经典的目标检测算法使用滑动窗法依次判断所有可能的区域。本文则预先提取一系列较可能是物体的候选区域，之后仅在这些候选区域上提取特征，进行判断。<br>2) 训练集(the labeled data is scarce and the amount currently available is insufficient for training a large CNN.): 经典的目标检测算法在区域中提取人工设定的特征（Haar，HOG）。本文则需要训练深度网络进行特征提取。可供使用的有两个数据库： <strong>一个较大的识别库（ImageNet ILSVC 2012）</strong>：标定每张图片中物体的类别。一千万图像，1000类。       <strong>一个较小的检测库（PASCAL VOC 2007）</strong>：标定每张图片中，物体的类别和位置。一万图像，20类。本文使用识别库进行预训练，而后用检测库调优参数。最后在检测库上评测。</p>
<p>Combine the object detection and image classification together</p>
<blockquote>
<p>Object detection is what is needed in EyePhone</p>
</blockquote>
<h3 id="Objection-Detection"><a href="#Objection-Detection" class="headerlink" title="Objection Detection"></a>Objection Detection</h3><p>Our object detection system consists of three modules. </p>
<blockquote>
<p>The first generates category-independent region proposals. These proposals define the set of candidate detections available to our detector. </p>
<p>The second module is a large convolutional neural network that extracts a fixed-length feature vector from each region. </p>
<p>The third module is a set of classspecific linear SVMs.</p>
</blockquote>
<p>使用Seletive Search找到region proposals，然后对于每一个region，把他转化成一个固定大小的CNN输入。</p>
<p>对于一个test sample，通过Selective Search得到约2000个region proposals，然后每一个region proposal通过forwad propagation通过一个CNN，在得到每一个region的score之后，我们基于贪心算法，当一个region和另一个region重合，并且那个新的region的score高于某一个threshold，那么选择那个新的region代替两个region。</p>
<h2 id="Paper-Selective-Search"><a href="#Paper-Selective-Search" class="headerlink" title="Paper: Selective Search"></a>Paper: Selective Search</h2><p><a href="https://koen.me/research/pub/uijlings-ijcv2013-draft.pdf" target="_blank" rel="noopener">Click here for the orginal text</a><br><a href="https://github.com/CesareMJLi/selectivesearch" target="_blank" rel="noopener">Click here for the project</a></p>
<p>由于该篇文章和本工程的相关性，该篇论文的注释将会用中文进行。</p>
<p><strong>Selective search is a algorithm in object detection! (not recognition)</strong></p>
<h3 id="INTRO-分割与穷举"><a href="#INTRO-分割与穷举" class="headerlink" title="INTRO 分割与穷举"></a>INTRO 分割与穷举</h3><p>在图片的物体识别领域，我们发现很难用一种统一的方法对所有的图片进行分类，我们需要考虑纹理，颜色以及这个物体的真实属性（一个轮子是单独的么？还是说这个轮子属于一辆车？），虽然在一张图片中往往其中一个就可以给出一个分类或者探测，但是在宏观上我们需要将多个元素进行考虑，而且还有一个问题是，往往我们用分割的方法（a unique partitioning of the image through a generic algorithm, where there is one part for all object silhouettes in the image.）很难得到一个正确的结论，在很多图片中，它的结构是intrinsic iherachical的，比如一个桌子上有若干个杯子，杯子里放着乒乓球或者羽毛球，我们需要考虑的是一个hierachical的模型。</p>
<p>通常情况下，我们在考虑object recognition的时候往往需要先进行object detection，然而在这篇论文中使用了另一种思路的方法，<strong>to do localisation through the identification of an object</strong>，比如以下这个情景，<em>在一张图片中出现了一个穿西装上衣的人，模型可以识别在西装上面有一张脸，然而为了识别整体的人的概念，我们需要模型对于这个概念有了解（prior recognition）。</em></p>
<p>一个解决方案是穷举法（对于每一个box boundary，它可能包含人/自行车/航空母舰嘛？），显而易见这种方法几乎是computatianal impossible，在这篇文章中提出的selective search的方法结合了segmentation和exhausive search，通过Bottom up segmentation获取图片的结构和每个object的位置【生成对象位置】，通过exhausive search捕捉每一个可能的object的位置信息【捕捉可能的对象的位置】。</p>
<h3 id="Related-Work"><a href="#Related-Work" class="headerlink" title="Related Work"></a>Related Work</h3><ul>
<li>Exhaustive Search</li>
</ul>
<p>As an object can be located at any position and scale in the image, it is natural to search everywhere [8, 16, 36]. However, the visual search space is huge, making an exhaustive search computationally expensive. This imposes constraints on the evaluation cost per location and/or the number of locations considered. Hence most of these <strong>sliding window techniques</strong> use a coarse search grid and fixed aspect ratios, using weak classifiers and economic image features such as HOG.</p>
<p>While still, HIGH COST! EVEN WITH SOME IMPROVEMENTS, A EXHAUSTIVE SEARCH MAY STILL VISIT OVER 100,000 WINDOWS PER IMAGE.</p>
<p>Instead of a blind exhaustive search or a branch and bound search, we propose selective search. We use the underlying image structure to generate object locations. In contrast to the discussed methods, this yields a completely class-independent set of locations and generating less locations, which means saving a lot of computer power.</p>
<ul>
<li>Segmentation</li>
</ul>
<p>In the previous segmentation research, there are some approaches by segmenting and recognizing objects in parts. They first generate a set of part hypotheses using a grouping method based on Arbelaez. Each part hypothesis is described by both appearance and shape features. Then, an object is recognized and carefully delineated by using its parts, achieving good results for shape recognition.</p>
<p>In their work, the segmentation is hierarchical and yields segments at all scales. However, they use a single grouping strategy whose power of discovering parts or objects is left unevaluated. In this work, we use multiple complementary strategies to deal with as many image conditions as possible.</p>
<h3 id="Selective-Search"><a href="#Selective-Search" class="headerlink" title="Selective Search"></a>Selective Search</h3><blockquote>
<p>the selective search should fulfill 3 considerations</p>
<p><strong>捕获全部scale上的Objects</strong>：因为一个object可能在一张图片上的任意scale出现，甚至有些objects可能会具有模糊的边界。【通过using a hierachical algorithm解决】</p>
<p><strong>多样化</strong>：不存在一种最好的策略将不同的region进行group。每个区域可能通过颜色，纹理等等形成一个object，所以与其采用一种在大部分情况下都行得通的单一的策略，我们想找到一系列策略来对应全部的情形。</p>
<p><strong>易于计算</strong></p>
</blockquote>
<ul>
<li>Selective Search by Hierarchical Grouping</li>
</ul>
<p>Bottom-up grouping is a popular approach to segmentation, hence we adapt it for selective search. This is a hierarchicalmethods, which means that we could naturally generate locations at all scales by continueing the grouping process until the whole image becomes a single region.</p>
<img src="/2018/05/02/Papers-EyePhone/1.png">
<p>Bottom-up grouping is a popular approach to segmentation, we use this to get the initial regions</p>
<p>输入为一张照片，首先通过the fast method of Felzenszwalb and Huttenlocher创建initial regions R，然后我们使用贪心算法迭代的将regions组合起来，具体的过程为首先，【<em>建立一个空集合S，首先对于每一对region pair，我们计算similarity，然后将他们的相似性放在集合S中</em>】，然后【<em>从S中取出最高的相似性的region pair，将两个融合成为新的region，并且移除与久的region有关的相似性并且计算新的region和它的周围的部分的相似性</em>】，重复第二个步直到S成为空集。</p>
<blockquote>
<p>在计算相似性的时候，我们必须保证新的r的特章必须可以通过原来的r计算得到而不需要回到pixel level重新计算。</p>
</blockquote>
<ul>
<li>Diversification Strategies</li>
</ul>
<p>Create <strong>a set of complementary strategies</strong> whose locations are combined afterwards. Some popular strategies are (1) by using a variety of colour spaces with different invariance properties, (2) by using different similarity measures s<sub>ij</sub>, and (3) by varying our starting regions.</p>
<blockquote>
<p>Complementary Colour Spaces</p>
<p>Complementary Similarity Measures(s<sub>colour</sub>,s<sub>texture</sub>,s<sub>size</sub>,s<sub>fill</sub>)</p>
<p>Complemenetart Starting Regions</p>
</blockquote>
<ul>
<li>Combining Locations</li>
</ul>
<h2 id="Felzenswalb-Algorithm-in-image-segmentation"><a href="#Felzenswalb-Algorithm-in-image-segmentation" class="headerlink" title="Felzenswalb Algorithm in image segmentation"></a>Felzenswalb Algorithm in image segmentation</h2><p><a href="http://people.cs.uchicago.edu/~pff/papers/seg-ijcv.pdf" target="_blank" rel="noopener">Click here for the original paper text</a><br><a href="https://blog.csdn.net/ttransposition/article/details/38024557" target="_blank" rel="noopener">Click here for the Chinese comments</a></p>
<p>本质上这种算法提供了图像分割的一种非AI的解决方法，对于图中的每一个像素进行考虑，设定超参数约束分割的granularity，然后得到一个分割后的图像，该算法的核心是图像中的颜色分布，所以就导致在其眼中分布是一块一块的，不能对一个对象进行有效的分割和识别。</p>
<h1 id="Another-idea-for-EyePhone"><a href="#Another-idea-for-EyePhone" class="headerlink" title="Another idea for EyePhone"></a>Another idea for EyePhone</h1><p>Maybe we could choose the result of selective search as the input for the detection of some certain objects like <strong>Bicycle/Stairs/Trees or other Vertical Cylindrical Objects/Horizontal Cylindrical Objects/Box/</strong></p>
<p>Here’s some further information about this modification. Now it could use selective search to output some potential areas for the object detection. We have two things to do:</p>
<blockquote>
<p><strong>Object detection:</strong> We have to detect the objects in the area, so we have two problems to solve here, first thing is that we are going to extract all the usefull information from the image. The SS method works quite well when we are trying to find the objects, and we could use BaiduCloud Recognition API to recognize the objects. </p>
<p><strong>Distance calculation:</strong> The problem left is that we are going to set a set of principles for the model, to calculate the distance of the objects between the user and the objects. In the beginning I put some efforts on help the model to get the idea of building the sense of objects and space. While this requires tons of calculations which is not possible for the individual developers. Hence we have to take the plan B and set the rules by hand (of course this rule could be learned by the model as well. It only depends on whether we have enough trainning sets)</p>
</blockquote>

        
    

    
</div>


                

                <!-- Post Comments -->
                
                    
                
            </div>

            <!-- Post Prev & Next Nav -->
            <nav class="material-nav mdl-color-text--grey-50 mdl-cell mdl-cell--12-col">
    <!-- Prev Nav -->
    
        <a href="/2018/05/06/SVM/" id="post_nav-newer" class="prev-content">
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_back</i>
            </button>
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            Newer
        </a>
    

    <!-- Section Spacer -->
    <div class="section-spacer"></div>

    <!-- Next Nav -->
    
        <a href="/2018/04/22/Deep-Learning-V-Recurrent-Neural-Network-Other-Methods/" id="post_nav-older" class="next-content">
            Older
            &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
            <button class="mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon mdl-color--white mdl-color-text--grey-900" role="presentation">
                <i class="material-icons">arrow_forward</i>
            </button>
        </a>
    
</nav>

        </div>
    </div>



                    
                        <!-- Overlay For Active Sidebar -->
<div class="sidebar-overlay"></div>

<!-- Material sidebar -->
<aside id="sidebar" class="sidebar sidebar-colored sidebar-fixed-left" role="navigation">
    <div id="sidebar-main">
        <!-- Sidebar Header -->
        <div class="sidebar-header header-cover" style="background-image: url(/img/sidebarHeader.jpg);">
    <!-- Top bar -->
    <div class="top-bar"></div>

    <!-- Sidebar toggle button -->
    <button type="button" class="sidebar-toggle mdl-button mdl-js-button mdl-js-ripple-effect mdl-button--icon" style="display: initial;" data-upgraded=",MaterialButton,MaterialRipple">
        <i class="material-icons">clear_all</i>
        <span class="mdl-button__ripple-container">
            <span class="mdl-ripple">
            </span>
        </span>
    </button>

    <!-- Sidebar Avatar -->
    <div class="sidebar-image">
        <img src="/img/cesare.jpg" alt="Cesare (MINGJU LI)'s avatar">
    </div>

    <!-- Sidebar Email -->
    <a data-toggle="dropdown" class="sidebar-brand" href="#settings-dropdown">
        cesareli1995@gmail.com
        <b class="caret"></b>
    </a>
</div>


        <!-- Sidebar Navigation  -->
        <ul class="nav sidebar-nav">
    <!-- User dropdown  -->
    <li class="dropdown">
        <ul id="settings-dropdown" class="dropdown-menu">
            
                <li>
                    <a href="https://www.google.com/gmail/" target="_blank" title="Send Me An Email">
                        
                            <i class="material-icons sidebar-material-icons sidebar-indent-left1pc-element">email</i>
                        
                        Send Me An Email
                    </a>
                </li>
            
        </ul>
    </li>

    <!-- Homepage -->
    
        <li id="sidebar-first-li">
            <a href="/">
                
                    <i class="material-icons sidebar-material-icons">home</i>
                
                Home
            </a>
        </li>
        
    

    <!-- Archives  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">inbox</i>
                
                    Archives
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
            <li>
                <a class="sidebar_archives-link" href="/archives/2020/02/">February 2020<span class="sidebar_archives-count">11</span></a></li><li><a class="sidebar_archives-link" href="/archives/2020/01/">January 2020<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/05/">May 2019<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2019/01/">January 2019<span class="sidebar_archives-count">2</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/12/">December 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/11/">November 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/10/">October 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/06/">June 2018<span class="sidebar_archives-count">1</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/05/">May 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/04/">April 2018<span class="sidebar_archives-count">6</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/03/">March 2018<span class="sidebar_archives-count">7</span></a></li><li><a class="sidebar_archives-link" href="/archives/2018/01/">January 2018<span class="sidebar_archives-count">3</span></a></li><li><a class="sidebar_archives-link" href="/archives/2017/12/">December 2017<span class="sidebar_archives-count">2</span></a>
            </ul>
        </li>
        
    

    <!-- Categories  -->
    
        <li class="dropdown">
            <a href="#" class="ripple-effect dropdown-toggle" data-toggle="dropdown">
                
                    <i class="material-icons sidebar-material-icons">chrome_reader_mode</i>
                
                Categories
                <b class="caret"></b>
            </a>
            <ul class="dropdown-menu">
                <li>
                
            </ul>
        </li>
        
    

    <!-- Pages  -->
    
        <li>
            <a href="/tags" title="Tags">
                
                    <i class="material-icons sidebar-material-icons">done</i>
                
                Tags
            </a>
        </li>
        
    

    <!-- Article Number  -->
    
        <li>
            <a href="/archives">
                Number of articles
                <span class="sidebar-badge">41</span>
            </a>
        </li>
        
    
</ul>


        <!-- Sidebar Footer -->
        <!--
I'm glad you use this theme, the development is no so easy, I hope you can keep the copyright, I will thank you so much.
If you still want to delete the copyrights, could you still retain the first one? Which namely "Theme Material"
It will not impact the appearance and can give developers a lot of support :)

很高兴您使用并喜欢该主题，开发不易 十分谢谢与希望您可以保留一下版权声明。
如果您仍然想删除的话 能否只保留第一项呢？即 "Theme Material"
它不会影响美观并可以给开发者很大的支持和动力。 :)
-->

<!-- Sidebar Divider -->


<!-- Theme Material -->


<!-- Help & Support -->
<!--

-->

<!-- Feedback -->
<!--

-->

<!-- About Theme -->
<!--

-->

    </div>

    <!-- Sidebar Image -->
    

</aside>

                    

                    
                        <!-- Footer Top Button -->
                        <div id="back-to-top" class="toTop-wrap">
    <a href="#top" class="toTop">
        <i class="material-icons footer_top-i">expand_less</i>
    </a>
</div>

                    

                    <!--Footer-->
<footer class="mdl-mini-footer" id="bottom">
    
        <!-- Paradox Footer Left Section -->
        <div class="mdl-mini-footer--left-section sns-list">
    <!-- Twitter -->
    

    <!-- Facebook -->
    
        <a href="https://www.facebook.com/cesare.lee.94" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-facebook">
                <span class="visuallyhidden">Facebook</span>
            </button><!--
     --></a>
    

    <!-- Google + -->
    

    <!-- Weibo -->
    
        <a href="https://www.weibo.com/5646481908/" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-weibo">
                <span class="visuallyhidden">Weibo</span>
            </button><!--
     --></a>
    

    <!-- Instagram -->
    
        <a href="https://www.instagram.com/cesaretiramisu/" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-instagram">
                <span class="visuallyhidden">Instagram</span>
            </button><!--
     --></a>
    

    <!-- Tumblr -->
    

    <!-- Github -->
    
        <a href="https://github.com/CesareMJLi" target="_blank">
            <button class="mdl-mini-footer--social-btn social-btn footer-sns-github">
                <span class="visuallyhidden">Github</span>
            </button><!--
     --></a>
    

    <!-- LinkedIn -->
    

    <!-- Zhihu -->
    

    <!-- Bilibili -->
    

    <!-- Telegram -->
    
    
    <!-- V2EX -->
    
</div>


        <!--Copyright-->
        <div id="copyright">
            Copyright&nbsp;©&nbsp;2017&nbsp;-<script type="text/javascript">var fd = new Date();document.write("&nbsp;" + fd.getFullYear() + "&nbsp;");</script>Cesare's Workshop
            
                <br>
                
                    Any question please contact me.
                
            
        </div>

        <!-- Paradox Footer Right Section -->

        <!--
        I am glad you use this theme, the development is no so easy, I hope you can keep the copyright.
        It will not impact the appearance and can give developers a lot of support :)

        很高兴您使用该主题，开发不易，希望您可以保留一下版权声明。
        它不会影响美观并可以给开发者很大的支持。 :)
        -->

        <div class="mdl-mini-footer--right-section">
            <div>
                <div class="footer-develop-div">Powered by <a href="https://hexo.io" target="_blank" class="footer-develop-a">Hexo</a></div>
                <div class="footer-develop-div">Theme - <a href="https://github.com/viosey/hexo-theme-material" target="_blank" class="footer-develop-a">Material</a></div>
            </div>
        </div>
    
</footer>


                    <!-- Import JS File -->

    <script>lsloader.load("lazyload_js","/js/lazyload.min.js?1BcfzuNXqV+ntF6gq+5X3Q==", true)</script>



    <script>lsloader.load("js_js","/js/js.min.js?V/53wGualMuiPM3xoetD5Q==", true)</script>



    <script>lsloader.load("np_js","/js/nprogress.js?pl3Qhb9lvqR1FlyLUna1Yw==", true)</script>


<script type="text/ls-javascript" id="NProgress-script">
    NProgress.configure({
        showSpinner: true
    });
    NProgress.start();
    $('#nprogress .bar').css({
        'background': '#29d'
    });
    $('#nprogress .peg').css({
        'box-shadow': '0 0 10px #29d, 0 0 15px #29d'
    });
    $('#nprogress .spinner-icon').css({
        'border-top-color': '#29d',
        'border-left-color': '#29d'
    });
    setTimeout(function() {
        NProgress.done();
        $('.fade').removeClass('out');
    }, 800);
</script>













<!-- UC Browser Compatible -->
<script>
	var agent = navigator.userAgent.toLowerCase();
	if(agent.indexOf('ucbrowser')>0) {
		document.write('<link rel="stylesheet" href="/css/uc.css">');
	   alert('由于 UC 浏览器使用极旧的内核，而本网站使用了一些新的特性。\n为了您能更好的浏览，推荐使用 Chrome 或 Firefox 浏览器。');
	}
</script>

<!-- Import prettify js  -->

    
        
            <script>lsloader.load("prettify_js","/js/prettify.min.js?WN07fivHQSMKWy7BmHBB6w==", true)</script>
        
    



<!-- Window Load -->
<!-- add class for prettify -->
<script type="text/ls-javascript" id="window-load">
    $(window).on('load', function() {
        // Post_Toc parent position fixed
        $('.post-toc-wrap').parent('.mdl-menu__container').css('position', 'fixed');
    });

    
        
            $(function() {
                $('pre').addClass('prettyprint linenums').attr('style', 'overflow:auto;');
                prettyPrint();
                })
        
    
    
</script>

<!-- MathJax Load-->


<!-- Bing Background -->


<script type="text/ls-javascript" id="lazy-load">
    // Offer LazyLoad
    queue.offer(function(){
        $('.lazy').lazyload({
            effect : 'show'
        });
    });

    // Start Queue
    $(document).ready(function(){
        setInterval(function(){
            queue.execNext();
        },200);
    });
</script>

<!-- Custom Footer -->



<script>
    (function(){
        var scriptList = document.querySelectorAll('script[type="text/ls-javascript"]')

        for (var i = 0; i < scriptList.length; ++i) {
            var item = scriptList[i];
            lsloader.runInlineScript(item.id,item.id);
        }
    })()
console.log('\n %c © Material Theme | Version: 1.5.2 | https://github.com/viosey/hexo-theme-material %c \n', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-left-radius:5px;border-bottom-left-radius:5px;', 'color:#455a64;background:#e0e0e0;padding:5px 0;border-top-right-radius:5px;border-bottom-right-radius:5px;');
</script>

                </main>
            </div><!-- hexo-inject:begin --><!-- hexo-inject:end -->
        </body>
    
</html>
